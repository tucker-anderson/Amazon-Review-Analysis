{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Yoks35UT5or"
   },
   "source": [
    "# Predicting the Helpfulness of Amazon Reviews\n",
    "### Keane Johnson and Tucker Anderson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook builds multiple models that predict the helpfulness of Amazon reviews. It uses the [2015 Amazon Review dataset](http://jmcauley.ucsd.edu/data/amazon/index.html), compiled by Julian McAuley, associate professor in the Computer Science department at the University of California, San Diego.\n",
    "\n",
    "The dataset contains product reviews from Amazon from May 1996 - July 2014, and includes ratings, text, helpfulness votes, descriptions, category information, price, brand, and image features. It is broken into smaller subsets, organized by product category.\n",
    "\n",
    "This notebook focuses on the Home and Kitchen sub-category, and uses the aforementioned features to predict helpfulness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "- Import Libraries\n",
    "- Load and Prepare Dataset\n",
    "- Exploratory Data Analysis\n",
    "- Model 1: Every review is 100% helpful\n",
    "- Model 2: Naive Bayes Bag of Words with Binary Helpfulness Labels\n",
    "- Model 3: TFIDF and Logistic Regression\n",
    "- Model 4: BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9t_9MV2_UO1O"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WXeTT4GwA9bN"
   },
   "outputs": [],
   "source": [
    "# load packages\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import wget\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset - download directly from source, save to data directory\n",
    "\n",
    "file_name = \"data/reviews_Home_and_Kitchen_5.json.gz\"\n",
    "output_dir = \"data\"\n",
    "url = \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Home_and_Kitchen_5.json.gz\"\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "if not os.path.isfile(file_name):\n",
    "    file_name = wget.download(url, out=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions to parse data from compressed json into pandas DF\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def get_dataframe(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "\n",
    "# helper function to pull out total helpful votes\n",
    "def get_helpful_votes(helpful):\n",
    "    [helpful, total] = helpful\n",
    "    return helpful\n",
    "\n",
    "\n",
    "# helper function to pull out total votes (helpful and unhelpful)\n",
    "def get_total_votes(helpful):\n",
    "    [helpful, total] = helpful\n",
    "    return total\n",
    "    \n",
    "    \n",
    "# helper function to calculate helpfulness percentage \n",
    "def calculate_helpful_perc(helpful):\n",
    "    [helpful, total] = helpful\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (helpful/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wHEe5MIfBIsL"
   },
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df = get_dataframe(file_name)\n",
    "\n",
    "# parse helpful column into new columns of helpful_votes, total_votes, helpful_perc\n",
    "df['helpful_votes'] = df['helpful'].apply(get_helpful_votes)\n",
    "df['total_votes'] = df['helpful'].apply(get_total_votes)\n",
    "df['helpful_perc'] = df['helpful'].apply(calculate_helpful_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCDusLkwUHJr"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(551682, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 551,682 rows and twelve columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25771</th>\n",
       "      <td>A2F93QMTF8CC50</td>\n",
       "      <td>B00005B8K5</td>\n",
       "      <td>DenisBaldwin</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Excellent pyrex storage option for the money. ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Excellent pyrex storage option</td>\n",
       "      <td>1384819200</td>\n",
       "      <td>11 19, 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458306</th>\n",
       "      <td>A3LXB8SQ4NJ72I</td>\n",
       "      <td>B00635VODS</td>\n",
       "      <td>Hip teacher</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I love this as an alternative to a feather dow...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Nice alternative down</td>\n",
       "      <td>1383696000</td>\n",
       "      <td>11 6, 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293414</th>\n",
       "      <td>A1AT43M0AL5UCM</td>\n",
       "      <td>B0023RT9VE</td>\n",
       "      <td>Shannon M Bond</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>My boys love this bed!  It was relatively easy...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I can't say enough</td>\n",
       "      <td>1358812800</td>\n",
       "      <td>01 22, 2013</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30244</th>\n",
       "      <td>A7S2ZQ1PMXKPY</td>\n",
       "      <td>B00005MF9C</td>\n",
       "      <td>Scumpy6</td>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>This coffee maker is just kind of crappy, but ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Kinda crappy...</td>\n",
       "      <td>1323043200</td>\n",
       "      <td>12 5, 2011</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489975</th>\n",
       "      <td>A15UU969VDADJT</td>\n",
       "      <td>B008C9UFDI</td>\n",
       "      <td>JH CT</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I am very impressed with this toaster oven, it...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Awesome Toaster Oven!</td>\n",
       "      <td>1380672000</td>\n",
       "      <td>10 2, 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin    reviewerName helpful  \\\n",
       "25771   A2F93QMTF8CC50  B00005B8K5    DenisBaldwin  [0, 0]   \n",
       "458306  A3LXB8SQ4NJ72I  B00635VODS     Hip teacher  [0, 0]   \n",
       "293414  A1AT43M0AL5UCM  B0023RT9VE  Shannon M Bond  [2, 2]   \n",
       "30244    A7S2ZQ1PMXKPY  B00005MF9C         Scumpy6  [0, 3]   \n",
       "489975  A15UU969VDADJT  B008C9UFDI           JH CT  [0, 0]   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "25771   Excellent pyrex storage option for the money. ...      5.0   \n",
       "458306  I love this as an alternative to a feather dow...      5.0   \n",
       "293414  My boys love this bed!  It was relatively easy...      5.0   \n",
       "30244   This coffee maker is just kind of crappy, but ...      2.0   \n",
       "489975  I am very impressed with this toaster oven, it...      5.0   \n",
       "\n",
       "                               summary  unixReviewTime   reviewTime  \\\n",
       "25771   Excellent pyrex storage option      1384819200  11 19, 2013   \n",
       "458306           Nice alternative down      1383696000   11 6, 2013   \n",
       "293414              I can't say enough      1358812800  01 22, 2013   \n",
       "30244                  Kinda crappy...      1323043200   12 5, 2011   \n",
       "489975           Awesome Toaster Oven!      1380672000   10 2, 2013   \n",
       "\n",
       "        helpful_votes  total_votes  helpful_perc  \n",
       "25771               0            0           0.0  \n",
       "458306              0            0           0.0  \n",
       "293414              2            2           1.0  \n",
       "30244               0            3           0.0  \n",
       "489975              0            0           0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The twelve columns contain data including the reviewer name and review time, in addition to more applicable data to our models, like review text, summary, and helpful scores. The helpful column is a list of two numbers. The first number is the number of individuals who found that review helpful. The second number is the total number of individuals who scored that review.\n",
    "\n",
    "We parse out these two numbers in helpful_votes and total_votes. We calculate the helpfulness percentage as well in helpful_perc. This is simply the number of helpful_votes divided by the number of total_votes. Helpful_perc will be our target variable in our models.\n",
    "\n",
    "There are two sources of natural language in the dataset - reviewText and summary. We assume the reviewText will be more robust and impactful in determining whether a review is helpful or not. However, summary is a good resource for our models as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to examine the completeness of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x166ed7f1c18>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAE4CAYAAAD4sSBeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),cbar=False,yticklabels=False,cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This heatmap shows that there are missing values for some observations of reviewerName. However, with such a large dataset, we could be missing some values for other features that just do not appear on this chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerName</th>\n",
       "      <td>4953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewText</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unixReviewTime</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewTime</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful_votes</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_votes</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful_perc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "reviewerID         0\n",
       "asin               0\n",
       "reviewerName    4953\n",
       "helpful            0\n",
       "reviewText         0\n",
       "overall            0\n",
       "summary            0\n",
       "unixReviewTime     0\n",
       "reviewTime         0\n",
       "helpful_votes      0\n",
       "total_votes        0\n",
       "helpful_perc       0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = pd.DataFrame(df.isnull().sum())\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We confirm that we are only missing values for reviewerName. We reason that this does not have an impact on our analysis because we will be using primarily the reviewText, and possibly the summary, to determine a review's helpfulness. Additionally, we argue that individuals do not consistently use a reviewer's name when determining a review's helpfulness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reviewing some sample data, and examining missing values, we next look at some summary statistics of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>551682.000000</td>\n",
       "      <td>5.516820e+05</td>\n",
       "      <td>551682.000000</td>\n",
       "      <td>551682.000000</td>\n",
       "      <td>551682.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.316655</td>\n",
       "      <td>1.348687e+09</td>\n",
       "      <td>3.497348</td>\n",
       "      <td>3.939469</td>\n",
       "      <td>0.367910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.110749</td>\n",
       "      <td>6.120238e+07</td>\n",
       "      <td>76.539142</td>\n",
       "      <td>77.801556</td>\n",
       "      <td>0.456931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.572256e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.331770e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.367626e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.388880e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.406074e+09</td>\n",
       "      <td>52176.000000</td>\n",
       "      <td>52861.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             overall  unixReviewTime  helpful_votes    total_votes  \\\n",
       "count  551682.000000    5.516820e+05  551682.000000  551682.000000   \n",
       "mean        4.316655    1.348687e+09       3.497348       3.939469   \n",
       "std         1.110749    6.120238e+07      76.539142      77.801556   \n",
       "min         1.000000    9.572256e+08       0.000000       0.000000   \n",
       "25%         4.000000    1.331770e+09       0.000000       0.000000   \n",
       "50%         5.000000    1.367626e+09       0.000000       0.000000   \n",
       "75%         5.000000    1.388880e+09       1.000000       2.000000   \n",
       "max         5.000000    1.406074e+09   52176.000000   52861.000000   \n",
       "\n",
       "        helpful_perc  \n",
       "count  551682.000000  \n",
       "mean        0.367910  \n",
       "std         0.456931  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These summary statistics show that over half of our observations have a 0% helpfulness. In addition, these observations have zero total votes. This means that the reviews simply haven't been voted upon. We should remove these observations from our dataset because our model could misinterpret the 0% helpful_perc to mean that the review was not helpful when in fact the review just hasn't been voted upon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a histogram to visualize the distribution of helpful percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram of Helpful Percentages')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAETCAYAAADzrOu5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSSpmmEiSiv1/HU0ffzX7rWIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "n, bins, patches = ax1.hist(x=df['helpful_perc'], bins='auto')\n",
    "                                 \n",
    "ax1.set_xlabel('Helpful Perc')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Histogram of Helpful Percentages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram shows that the majority of reviews have a 0% helpful percentage, with the second most prevalent percentage being 100%. However, our dataset needs to be cleaned to remove observations that may add noise, but do not add meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be purposeful with the data that we are supplying to our model. We want to only analyze reviews where there are at least three total votes, or reviews where there are two total votes, but both votes are in agreement.\n",
    "\n",
    "Our rationale is that two total votes that are split does not tell us much. However, if both are an agreeement, that could tell us something about a reviews helpfulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139470, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset df of reviews that have at least three votes\n",
    "df_three = df[df.total_votes >= 3]\n",
    "\n",
    "# subset df of reviews that have two both and both are in agreeement\n",
    "df_two = df[((df.total_votes == 2) & (df.helpful_perc == 1)) | ((df.total_votes == 2) & (df.helpful_perc == 0))]\n",
    "\n",
    "# combine the dfs back together\n",
    "df = df_three.append(df_two, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of our dataset is now 139,470 rows. Next we can examine the new distribution of helpful_perc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>139470.000000</td>\n",
       "      <td>1.394700e+05</td>\n",
       "      <td>139470.000000</td>\n",
       "      <td>139470.000000</td>\n",
       "      <td>139470.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.988270</td>\n",
       "      <td>1.301792e+09</td>\n",
       "      <td>13.178676</td>\n",
       "      <td>14.704022</td>\n",
       "      <td>0.848035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.356746</td>\n",
       "      <td>8.137408e+07</td>\n",
       "      <td>151.811710</td>\n",
       "      <td>154.232187</td>\n",
       "      <td>0.242654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.572256e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.261181e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.324080e+09</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.362874e+09</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.405728e+09</td>\n",
       "      <td>52176.000000</td>\n",
       "      <td>52861.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             overall  unixReviewTime  helpful_votes    total_votes  \\\n",
       "count  139470.000000    1.394700e+05  139470.000000  139470.000000   \n",
       "mean        3.988270    1.301792e+09      13.178676      14.704022   \n",
       "std         1.356746    8.137408e+07     151.811710     154.232187   \n",
       "min         1.000000    9.572256e+08       0.000000       2.000000   \n",
       "25%         3.000000    1.261181e+09       2.000000       3.000000   \n",
       "50%         5.000000    1.324080e+09       4.000000       5.000000   \n",
       "75%         5.000000    1.362874e+09       9.000000      10.000000   \n",
       "max         5.000000    1.405728e+09   52176.000000   52861.000000   \n",
       "\n",
       "        helpful_perc  \n",
       "count  139470.000000  \n",
       "mean        0.848035  \n",
       "std         0.242654  \n",
       "min         0.000000  \n",
       "25%         0.750000  \n",
       "50%         1.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median helpful_perc is 100%. We could be at risk of not having a good distribution of data to train on. This could result in our model being overly optimistic and inflating the helpfulness scores of reviews. We can visualize this skew with another histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram of Helpful Percentages')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAETCAYAAADKy1riAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0DAzs2wODTMzy+bQMDOzbP8f1+OFvF+EcOgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(1, 1, 1)\n",
    "n, bins, patches = ax2.hist(x=df['helpful_perc'], bins='auto')\n",
    "                                 \n",
    "ax2.set_xlabel('Helpful Perc')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Histogram of Helpful Percentages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Subsetting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to resource constraints, we'll subset our data to roughly half the original size. This is still more than enough data to build and test our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled = df.sample(80000)\n",
    "df_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram of Helpful Percentages of Subsetted Data')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAETCAYAAADKy1riAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVkxJw0zMyv2/wE9JRgWTf0IEwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig3 = plt.figure()\n",
    "ax3 = fig3.add_subplot(1, 1, 1)\n",
    "n, bins, patches = ax3.hist(x=df['helpful_perc'], bins='auto')\n",
    "                                 \n",
    "ax3.set_xlabel('Helpful Perc')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('Histogram of Helpful Percentages of Subsetted Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the sampled data visually matches the distribution of the original dataset. We can confirm the distributions are identical with the Kolmogorov-Smirnov statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.0024419220979422507, pvalue=0.922221353930985)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "df_sampled_helpful_prec = df_sampled['helpful_perc']\n",
    "df_helpful_perc = df['helpful_perc']\n",
    "\n",
    "ks_2samp(df_sampled_helpful_prec, df_helpful_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_sampled becomes our df\n",
    "df = df_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Every Review is Helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic model we can produce is to label each review as being helpful if it meets a certain helpful_perc threshold. We choose 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every Review is Helpful Accuracy Score ->  79.21125\n"
     ]
    }
   ],
   "source": [
    "# calculate total number of reviews\n",
    "total_reviews = len(df)\n",
    "\n",
    "# calculate total number of reviews that are at least 75% helpful\n",
    "helpful_reviews = len(df[df.helpful_perc >= 0.75])\n",
    "\n",
    "# calculate accuracy if we predicted each review is at least 75% helpful\n",
    "accuracy_1 = 100*(helpful_reviews/total_reviews)\n",
    "\n",
    "print(\"Every Review is Helpful Accuracy Score -> \", accuracy_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model would produce an accuracy score of 79.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Naive Bayes Bag of Words with Binary Helpfulness Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more sophisticated model is one where we estimate the hepfulness of a review using its text. We use a Bag of Words model to determine whether a review is helpful or not. We again define a helpful review as one whose helpfulness percentage is at least 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# this nltk download may be needed. download stopwords, punkt\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure there are no missing values in the review or summary text or the overall helpullness percentage\n",
    "len(df) == len(df.dropna(subset=['reviewText', 'summary', 'helpful_perc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our bag of words model, we will combine the reviewText and summary text fields to combine into a single \"document\" with which to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize(text):\n",
    "    return [word for word in word_tokenize(text) if not word in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We should then tokenize and stem the review data before ingesting into our NLP models\n",
    "df['combinedText'] = df['summary'].str.lower() + \". \" +  df['reviewText'].str.lower()\n",
    "\n",
    "# Now tokenize these and remove stop words\n",
    "df['processedText'] = df['combinedText'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new column for helpful reviews (reviews with at least a 75% helpfulness rating)\n",
    "\n",
    "df[\"isHelpful\"] = df[\"helpful_perc\"] > .75\n",
    "df[\"isHelpful\"] = df[\"isHelpful\"].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "      <th>combinedText</th>\n",
       "      <th>processedText</th>\n",
       "      <th>isHelpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106615</th>\n",
       "      <td>A1FNLY02ZH11MW</td>\n",
       "      <td>B00E58P7ME</td>\n",
       "      <td>J. VanGoethem</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>Yes, it costs too much for a $.25 worth of met...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Does the job</td>\n",
       "      <td>1315699200</td>\n",
       "      <td>09 11, 2011</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>does the job. yes, it costs too much for a $.2...</td>\n",
       "      <td>[job, ., yes, ,, costs, much, $, .25, worth, m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61951</th>\n",
       "      <td>A22MANL4US4RMY</td>\n",
       "      <td>B001V4VMRO</td>\n",
       "      <td>Book Carpenter</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>This cover is a nice, tight fit, and it seems ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Good Fit, Good Construction</td>\n",
       "      <td>1314144000</td>\n",
       "      <td>08 24, 2011</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>good fit, good construction. this cover is a n...</td>\n",
       "      <td>[good, fit, ,, good, construction, ., cover, n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119108</th>\n",
       "      <td>A3NT7RAITJZXXT</td>\n",
       "      <td>B000GX4CKA</td>\n",
       "      <td>Linda \"cooking enthusiast\"</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>While this is a good shelf for the price it wo...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No instructions included</td>\n",
       "      <td>1279929600</td>\n",
       "      <td>07 24, 2010</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no instructions included. while this is a good...</td>\n",
       "      <td>[instructions, included, ., good, shelf, price...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15628</th>\n",
       "      <td>A1VB2KE2PR4J4W</td>\n",
       "      <td>B0000CFNQX</td>\n",
       "      <td>J. J. Emmel</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>It's made in China, a tad small, but not bad f...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>not bad for made in China</td>\n",
       "      <td>1329177600</td>\n",
       "      <td>02 14, 2012</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>not bad for made in china. it's made in china,...</td>\n",
       "      <td>[bad, made, china, ., 's, made, china, ,, tad,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99353</th>\n",
       "      <td>A2QFO64UAU5N18</td>\n",
       "      <td>B008R3ER0Q</td>\n",
       "      <td>W. Lucas \"wvl\"</td>\n",
       "      <td>[2, 4]</td>\n",
       "      <td>This thing is very weak on the suction. I read...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Must have gotten a bad one, because</td>\n",
       "      <td>1388361600</td>\n",
       "      <td>12 30, 2013</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>must have gotten a bad one, because. this thin...</td>\n",
       "      <td>[must, gotten, bad, one, ,, ., thing, weak, su...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin                reviewerName helpful  \\\n",
       "106615  A1FNLY02ZH11MW  B00E58P7ME               J. VanGoethem  [3, 4]   \n",
       "61951   A22MANL4US4RMY  B001V4VMRO              Book Carpenter  [2, 3]   \n",
       "119108  A3NT7RAITJZXXT  B000GX4CKA  Linda \"cooking enthusiast\"  [2, 2]   \n",
       "15628   A1VB2KE2PR4J4W  B0000CFNQX                 J. J. Emmel  [3, 4]   \n",
       "99353   A2QFO64UAU5N18  B008R3ER0Q              W. Lucas \"wvl\"  [2, 4]   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "106615  Yes, it costs too much for a $.25 worth of met...      4.0   \n",
       "61951   This cover is a nice, tight fit, and it seems ...      5.0   \n",
       "119108  While this is a good shelf for the price it wo...      3.0   \n",
       "15628   It's made in China, a tad small, but not bad f...      3.0   \n",
       "99353   This thing is very weak on the suction. I read...      1.0   \n",
       "\n",
       "                                    summary  unixReviewTime   reviewTime  \\\n",
       "106615                         Does the job      1315699200  09 11, 2011   \n",
       "61951           Good Fit, Good Construction      1314144000  08 24, 2011   \n",
       "119108             No instructions included      1279929600  07 24, 2010   \n",
       "15628             not bad for made in China      1329177600  02 14, 2012   \n",
       "99353   Must have gotten a bad one, because      1388361600  12 30, 2013   \n",
       "\n",
       "        helpful_votes  total_votes  helpful_perc  \\\n",
       "106615              3            4      0.750000   \n",
       "61951               2            3      0.666667   \n",
       "119108              2            2      1.000000   \n",
       "15628               3            4      0.750000   \n",
       "99353               2            4      0.500000   \n",
       "\n",
       "                                             combinedText  \\\n",
       "106615  does the job. yes, it costs too much for a $.2...   \n",
       "61951   good fit, good construction. this cover is a n...   \n",
       "119108  no instructions included. while this is a good...   \n",
       "15628   not bad for made in china. it's made in china,...   \n",
       "99353   must have gotten a bad one, because. this thin...   \n",
       "\n",
       "                                            processedText  isHelpful  \n",
       "106615  [job, ., yes, ,, costs, much, $, .25, worth, m...          0  \n",
       "61951   [good, fit, ,, good, construction, ., cover, n...          0  \n",
       "119108  [instructions, included, ., good, shelf, price...          1  \n",
       "15628   [bad, made, china, ., 's, made, china, ,, tad,...          0  \n",
       "99353   [must, gotten, bad, one, ,, ., thing, weak, su...          0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's make sure everything looks ok\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram of Helpful/Not Helpful Reviews')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAETCAYAAADKy1riAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCQVMzQkScUMDUlSMUNDklTM0JAkFfv/S/1T7Rt/GsAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take a look at distribution of Helpful/Not Helpful\n",
    "\n",
    "fig4 = plt.figure()\n",
    "ax4 = fig4.add_subplot(1, 1, 1)\n",
    "n, bins, patches = ax4.hist(x=df['isHelpful'], bins=2)\n",
    "                                 \n",
    "ax4.set_xlabel('Helpful')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title('Histogram of Helpful/Not Helpful Reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "data = df[['combinedText', 'isHelpful']]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "preprocessed_data = data.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(preprocessed_data['combinedText'], \n",
    "                                                    preprocessed_data['isHelpful'],\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Accuracy Score ->  74.76875\n"
     ]
    }
   ],
   "source": [
    "# and train our classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "g_classifier = GaussianNB().fit(np.array(Train_X.values.tolist()).reshape(-1, 1), Train_Y)\n",
    "accuracy_2 = accuracy_score(Test_Y, g_classifier.predict(np.array(Test_X.values.tolist()).reshape(-1, 1)))*100\n",
    "\n",
    "print(\"Gaussian Naive Bayes Accuracy Score -> \", accuracy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Naive Bayes Bag of Words model performs worse than our previous \"every review is helpful\" baseline model. It produces an accuracy score of 75.3%, down from 79.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: TF-IDF and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import sklearn\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into train/validation/test sets\n",
    "data = df[['combinedText', 'isHelpful']]\n",
    "\n",
    "df_train, df_test = train_test_split(data, test_size = 0.2)\n",
    "df_train, df_val = train_test_split(df_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stem combinedText to reduce size of corpus\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter=PorterStemmer()\n",
    "\n",
    "def stem_text(df):\n",
    "    text_list = df['combinedText'].tolist()\n",
    "    text_list_stem = [None] * len(text_list)\n",
    "\n",
    "    for i in range(len(text_list)):\n",
    "        text_list_stem[i] = ' '.join([porter.stem(w) for w in text_list[i].split()])\n",
    "    \n",
    "    return text_list_stem\n",
    "\n",
    "text_list_stem = stem_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03389221, 0.07340804, 0.03054271, ..., 0.03196743, 0.099017  ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.19454242, 0.        , 0.        , ..., 0.        , 0.14209024,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.26798256,\n",
       "        0.        ],\n",
       "       [0.03311168, 0.07171747, 0.08951795, ..., 0.        , 0.145105  ,\n",
       "        0.14716066],\n",
       "       [0.        , 0.        , 0.18267261, ..., 0.        , 0.14805248,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "                max_features=100,\n",
    "                ngram_range=(1,1)\n",
    "                )\n",
    "\n",
    "vectorizer.fit_transform(text_list_stem).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (51200, 100)\n"
     ]
    }
   ],
   "source": [
    "# vectorize train dataset\n",
    "train_text_stem = stem_text(df_train)\n",
    "train_vectorized = vectorizer.transform(train_text_stem).toarray()\n",
    "\n",
    "print('Shape:', train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (12800, 100)\n"
     ]
    }
   ],
   "source": [
    "# vectorize val dataset\n",
    "val_text_stem = stem_text(df_val)\n",
    "val_vectorized = vectorizer.transform(val_text_stem).toarray()\n",
    "\n",
    "print('Shape:', val_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (16000, 100)\n"
     ]
    }
   ],
   "source": [
    "# vectorize test dataset\n",
    "test_text_stem = stem_text(df_test)\n",
    "test_vectorized = vectorizer.transform(test_text_stem).toarray()\n",
    "\n",
    "print('Shape:', test_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create array of labels to use in logistic regression\n",
    "df_train_labels = np.array(df_train['isHelpful'])\n",
    "df_test_labels = np.array(df_test['isHelpful'])\n",
    "df_val_labels = np.array(df_val['isHelpful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train logistic regression\n",
    "lr = LogisticRegression(penalty='l2')\n",
    "lr.fit(train_vectorized, df_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 0.01   validation set accuracy: 0.745546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 0.1   validation set accuracy: 0.746796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 1.0   validation set accuracy: 0.747265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 10   validation set accuracy: 0.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 100   validation set accuracy: 0.74765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 1000   validation set accuracy: 0.74765625\n"
     ]
    }
   ],
   "source": [
    "# tune hyperparameters\n",
    "reg_str = [0.01, 0.1, 1.0, 10, 100, 1000]\n",
    "\n",
    "best_acc = -1\n",
    "best_c = None\n",
    "\n",
    "for r in reg_str:\n",
    "    lr = LogisticRegression(penalty='l2', C=r)\n",
    "    lr.fit(train_vectorized, df_train_labels)\n",
    "    preds = lr.predict(val_vectorized)\n",
    "    acc = np.mean(preds == df_val_labels)\n",
    "    print('regularization strength:', r, ' ', 'validation set accuracy:', acc)\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_c = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF and Logistic Regression Accuracy Score -> 74.99375\n"
     ]
    }
   ],
   "source": [
    "# test accuracy\n",
    "lr_final = LogisticRegression(penalty='l2', C = best_c)\n",
    "lr_final.fit(train_vectorized, df_train_labels)\n",
    "\n",
    "preds = lr_final.predict(test_vectorized)\n",
    "accuracy_3 = 100*np.mean(preds == df_test_labels)\n",
    "\n",
    "print(\"TF-IDF and Logistic Regression Accuracy Score ->\", accuracy_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with term frequency–inverse document frequency and logistic regression produces a marginally higher accuracy than the Naive Bayes Bag of Words model, but it is still not higher than the rudimentary Every Review is Helpful model. This motivates the need for a more robust representation of the language in the reviews. Enter BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code built around Strongio's notebook here https://github.com/strongio/keras-bert/blob/master/keras-bert.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "# if this doesnt work, ensure tensorflow is version <2.0\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Tensorflow hub path to BERT module of choice\n",
    "BERT_DIR =  \"./bert\"\n",
    "BERT_PATH = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "MAX_SEQ_LENGTH = 256\n",
    "\n",
    "sys.path.insert(0,BERT_DIR)\n",
    "\n",
    "# Initialize session, may need to remove config if no GPU\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "  When running eval/predict on the TPU, we need to pad the number of examples\n",
    "  to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "  size. The alternative is to drop the last batch, which is bad because it means\n",
    "  the entire output data won't be generated.\n",
    "  We use this class instead of `None` because treating `None` as padding\n",
    "  battches could cause silent errors.\n",
    "  \"\"\"\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "def create_tokenizer_from_hub_module(path):\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module =  hub.Module(path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tucker\\Berkeley\\W266\\Final\\Amazon-Review-Analysis\\bert\\tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tucker\\Berkeley\\W266\\Final\\Amazon-Review-Analysis\\bert\\tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module(BERT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now create the combinedText with casing and no longer than 512 characters (max of BERT embedding input)\n",
    "df['combinedText'] = df['summary'] + \". \" + df['reviewText']\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2)\n",
    "df_train, df_val = train_test_split(df_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f89527fd1d44d5cb205f85bb57e9c12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40930d597f7c4129a456e5eda86a1b86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93cd6de50fc41749e1c3893772485e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(df_train['combinedText'], df_train['helpful_perc'])\n",
    "val_examples = convert_text_to_examples(df_val['combinedText'], df_val['helpful_perc'])\n",
    "test_examples = convert_text_to_examples(df_test['combinedText'], df_test['helpful_perc'])\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
    ") = convert_examples_to_features(tokenizer, train_examples, max_seq_length=MAX_SEQ_LENGTH)\n",
    "(val_input_ids, val_input_masks, val_segment_ids, val_labels \n",
    ") = convert_examples_to_features(tokenizer, val_examples, max_seq_length=MAX_SEQ_LENGTH)\n",
    "(test_input_ids, test_input_masks, test_segment_ids, test_labels\n",
    ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"first\",\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_path = bert_path\n",
    "        if self.pooling not in [\"first\", \"mean\"]:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "\n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'n_fine_tune_layers': self.n_fine_tune_layers,\n",
    "                  'pooling': self.pooling,\n",
    "                  'bert_path': self.bert_path}\n",
    "        base_config = super(MyMeanPooling, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(max_seq_length, model_loss): \n",
    "    in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    bert_output = BertLayer(n_fine_tune_layers=3, pooling=\"first\")(bert_inputs)\n",
    "    dense = tf.keras.layers.Dense(max_seq_length, activation='relu')(bert_output)\n",
    "    pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss=model_loss, optimizer='adam')\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer (BertLayer)          (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      bert_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 22,051,329\n",
      "Non-trainable params: 88,250,682\n",
      "__________________________________________________________________________________________________\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_1 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          196864      bert_layer_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            257         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 22,051,329\n",
      "Non-trainable params: 88,250,682\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# let's define some models!\n",
    "\n",
    "#BCE Model: using BCE in regression https://stats.stackexchange.com/questions/370179/why-binary-crossentropy-can-be-used-as-the-loss-function-in-autoencoders/370180#370180\n",
    "model_BCE = build_model(MAX_SEQ_LENGTH, 'binary_crossentropy')\n",
    "model_RMSE = build_model(MAX_SEQ_LENGTH, 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51200 samples, validate on 16000 samples\n",
      "51200/51200 [==============================] - 2450s 48ms/sample - loss: 0.4406 - val_loss: 0.4372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1688060d160>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can now finally build a model\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "model_BCE.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n",
    "    epochs=1,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51200 samples, validate on 16000 samples\n",
      "51200/51200 [==============================] - 2505s 49ms/sample - loss: 0.0807 - val_loss: 0.0832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1688bd3bef0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can now finally build a model\n",
    "# Instantiate variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce127f3ba77a4fdbb47e0a2c89e8da81"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc871561606e4574be200fdb2a7f5ef4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96f722b1a994fd6b20a9d811785969a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_4 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 512)          393728      bert_layer_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            513         dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 110,499,131\n",
      "Trainable params: 22,248,449\n",
      "Non-trainable params: 88,250,682\n",
      "__________________________________________________________________________________________________\n",
      "Train on 51200 samples, validate on 16000 samples\n",
      "51200/51200 [==============================] - 5462s 107ms/sample - loss: 0.0819 - val_loss: 0.0832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16876a886a0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see if a different input length changes our model\n",
    "MAX_SEQ_LENGTH = 512\n",
    "\n",
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(df_train['combinedText'], df_train['helpful_perc'])\n",
    "val_examples = convert_text_to_examples(df_val['combinedText'], df_val['helpful_perc'])\n",
    "test_examples = convert_text_to_examples(df_test['combinedText'], df_test['helpful_perc'])\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
    ") = convert_examples_to_features(tokenizer, train_examples, max_seq_length=MAX_SEQ_LENGTH)\n",
    "(val_input_ids, val_input_masks, val_segment_ids, val_labels \n",
    ") = convert_examples_to_features(tokenizer, val_examples, max_seq_length=MAX_SEQ_LENGTH)\n",
    "(test_input_ids, test_input_masks, test_segment_ids, test_labels\n",
    ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=MAX_SEQ_LENGTH)\n",
    "\n",
    "model_RMSE2 = build_model(MAX_SEQ_LENGTH, 'mean_squared_error')\n",
    "\n",
    "#we can now finally build a model\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "model_RMSE2.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n",
    "    epochs=1,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_ids to have shape (512,) but got array with shape (256,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-d8ba242c4dbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m acc_RMSE2 = model_RMSE2.evaluate([test_input_ids, \n\u001b[0;32m      2\u001b[0m                        \u001b[0mtest_input_masks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                        test_segment_ids], test_labels)\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_RMSE2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    830\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 832\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m   def predict(self,\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'steps'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m         steps=steps)\n\u001b[0m\u001b[0;32m    696\u001b[0m     return test_loop(\n\u001b[0;32m    697\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2469\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2470\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2471\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2473\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    570\u001b[0m                              \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m                              str(data_shape))\n\u001b[0m\u001b[0;32m    573\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_ids to have shape (512,) but got array with shape (256,)"
     ]
    }
   ],
   "source": [
    "acc_RMSE2 = model_RMSE2.evaluate([test_input_ids, \n",
    "                       test_input_masks, \n",
    "                       test_segment_ids], test_labels)\n",
    "print('Test accuracy:', acc_RMSE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f6aa2281654325a8ac99af74c4eac9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330482c3f7de4e5d8d95b7fcbd793caa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361487141cfa44a68e55684f1a68d660"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_6 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 256)          196864      bert_layer_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            257         dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 22,051,329\n",
      "Non-trainable params: 88,250,682\n",
      "__________________________________________________________________________________________________\n",
      "Train on 51200 samples, validate on 12800 samples\n",
      "Epoch 1/5\n",
      "51200/51200 [==============================] - 3204s 63ms/sample - loss: 0.0823 - val_loss: 0.0844\n",
      "Epoch 2/5\n",
      "51200/51200 [==============================] - 2015s 39ms/sample - loss: 0.0817 - val_loss: 0.0844\n",
      "Epoch 3/5\n",
      "51200/51200 [==============================] - 2016s 39ms/sample - loss: 0.0817 - val_loss: 0.0844\n",
      "Epoch 4/5\n",
      "51200/51200 [==============================] - 2016s 39ms/sample - loss: 0.0817 - val_loss: 0.0844\n",
      "Epoch 5/5\n",
      "51200/51200 [==============================] - 2017s 39ms/sample - loss: 0.0817 - val_loss: 0.0844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x168777c4ac8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see if a different input length changes our model\n",
    "MAX_SEQ_LENGTH = 256\n",
    "\n",
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(df_train['combinedText'], df_train['helpful_perc'])\n",
    "val_examples = convert_text_to_examples(df_val['combinedText'], df_val['helpful_perc'])\n",
    "test_examples = convert_text_to_examples(df_test['combinedText'], df_test['helpful_perc'])\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
    ") = convert_examples_to_features(tokenizer, train_examples, max_seq_length=MAX_SEQ_LENGTH)\n",
    "(val_input_ids, val_input_masks, val_segment_ids, val_labels \n",
    ") = convert_examples_to_features(tokenizer, val_examples, max_seq_length=MAX_SEQ_LENGTH)\n",
    "(test_input_ids, test_input_masks, test_segment_ids, test_labels\n",
    ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=MAX_SEQ_LENGTH)\n",
    "\n",
    "model_RMSE3 = build_model(MAX_SEQ_LENGTH, 'mean_squared_error')\n",
    "\n",
    "#we can now finally build a model\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "model_RMSE3.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data=([val_input_ids, val_input_masks, val_segment_ids], val_labels),\n",
    "    epochs=5,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 368s 23ms/sample - loss: 0.0832\n",
      "Test loss: 0.08323233327269554\n"
     ]
    }
   ],
   "source": [
    "loss_RMSE3 = model_RMSE3.evaluate([test_input_ids, \n",
    "                       test_input_masks, \n",
    "                       test_segment_ids], test_labels)\n",
    "print('Test loss:', loss_RMSE3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True, gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_coefficient_loss(y_true, y_pred):\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    mx = K.mean(x)\n",
    "    my = K.mean(y)\n",
    "    xm, ym = x-mx, y-my\n",
    "    r_num = K.sum(tf.multiply(xm,ym))\n",
    "    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym))))\n",
    "    r = r_num / r_den\n",
    "\n",
    "    r = K.maximum(K.minimum(r, 1.0), -1.0)\n",
    "    return 1 - K.square(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_9 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 256)          196864      bert_layer_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            257         dense_18[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 22,051,329\n",
      "Non-trainable params: 88,250,682\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Dst tensor is not initialized.\n\t [[node checkpoint_initializer_125 (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n\nOriginal stack trace for 'checkpoint_initializer_125':\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-43-cd743eb9ee68>\", line 2, in <module>\n    tokenizer = create_tokenizer_from_hub_module(BERT_PATH)\n  File \"<ipython-input-42-229ddd287702>\", line 32, in create_tokenizer_from_hub_module\n    bert_module =  hub.Module(path)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\module.py\", line 176, in __init__\n    tags=self._tags)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py\", line 386, in _create_impl\n    name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py\", line 445, in __init__\n    self._init_state(name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py\", line 453, in _init_state\n    self._variable_map)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\training\\checkpoint_utils.py\", line 291, in init_from_checkpoint\n    init_from_checkpoint_fn)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 1940, in merge_call\n    return self._merge_call(merge_fn, args, kwargs)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 1947, in _merge_call\n    return merge_fn(self._strategy, *args, **kwargs)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\training\\checkpoint_utils.py\", line 286, in <lambda>\n    ckpt_dir_or_file, assignment_map)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\training\\checkpoint_utils.py\", line 334, in _init_from_checkpoint\n    _set_variable_or_list_initializer(var, ckpt_file, tensor_name_in_ckpt)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\training\\checkpoint_utils.py\", line 458, in _set_variable_or_list_initializer\n    _set_checkpoint_initializer(variable_or_list, ckpt_file, tensor_name, \"\")\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\training\\checkpoint_utils.py\", line 412, in _set_checkpoint_initializer\n    ckpt_file, [tensor_name], [slice_spec], [base_type], name=name)[0]\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Dst tensor is not initialized.\n\t [[{{node checkpoint_initializer_125}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-68a10531048c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#we can now finally build a model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Instantiate variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0minitialize_vars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m model_corrcoeff.fit(\n",
      "\u001b[1;32m<ipython-input-47-c5573ea8c57c>\u001b[0m in \u001b[0;36minitialize_vars\u001b[1;34m(sess)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minitialize_vars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Dst tensor is not initialized.\n\t [[node checkpoint_initializer_125 (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n\nOriginal stack trace for 'checkpoint_initializer_125':\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-43-cd743eb9ee68>\", line 2, in <module>\n    tokenizer = create_tokenizer_from_hub_module(BERT_PATH)\n  File \"<ipython-input-42-229ddd287702>\", line 32, in create_tokenizer_from_hub_module\n    bert_module =  hub.Module(path)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\module.py\", line 176, in __init__\n    tags=self._tags)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py\", line 386, in _create_impl\n    name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py\", line 445, in __init__\n    self._init_state(name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py\", line 453, in _init_state\n    self._variable_map)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\training\\checkpoint_utils.py\", line 291, in init_from_checkpoint\n    init_from_checkpoint_fn)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 1940, in merge_call\n    return self._merge_call(merge_fn, args, kwargs)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 1947, in _merge_call\n    return merge_fn(self._strategy, *args, **kwargs)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\training\\checkpoint_utils.py\", line 286, in <lambda>\n    ckpt_dir_or_file, assignment_map)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\training\\checkpoint_utils.py\", line 334, in _init_from_checkpoint\n    _set_variable_or_list_initializer(var, ckpt_file, tensor_name_in_ckpt)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\training\\checkpoint_utils.py\", line 458, in _set_variable_or_list_initializer\n    _set_checkpoint_initializer(variable_or_list, ckpt_file, tensor_name, \"\")\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\training\\checkpoint_utils.py\", line 412, in _set_checkpoint_initializer\n    ckpt_file, [tensor_name], [slice_spec], [base_type], name=name)[0]\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "model_corrcoeff = build_model(MAX_SEQ_LENGTH, correlation_coefficient_loss)\n",
    "\n",
    "#we can now finally build a model\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "model_corrcoeff.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data=([val_input_ids, val_input_masks, val_segment_ids], val_labels),\n",
    "    epochs=1,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_corr = model_RMSE3.evaluate([test_input_ids, \n",
    "                       test_input_masks, \n",
    "                       test_segment_ids], test_labels)\n",
    "print('Test loss:', loss_RMSE3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Layers with arguments in `__init__` must override `get_config`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-025f90fe8de5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# serialize model to JSON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_RMSE3_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_RMSE3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_RMSE3_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# serialize weights to HDF5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1403\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mJSON\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \"\"\"\n\u001b[1;32m-> 1405\u001b[1;33m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1406\u001b[0m     return json.dumps(\n\u001b[0;32m   1407\u001b[0m         model_config, default=serialization.get_json_type, **kwargs)\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_updated_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1381\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeras_version\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1384\u001b[0m     model_config = {\n\u001b[0;32m   1385\u001b[0m         \u001b[1;34m'class_name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mget_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# From the earliest layers on.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m       \u001b[0mlayer_class_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 886\u001b[1;33m       \u001b[0mlayer_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[0mfiltered_inbound_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mget_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[1;31m# or that `get_config` has been overridden:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_is_default'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       raise NotImplementedError('Layers with arguments in `__init__` must '\n\u001b[0m\u001b[0;32m    581\u001b[0m                                 'override `get_config`.')\n\u001b[0;32m    582\u001b[0m     \u001b[1;31m# TODO(reedwm): Handle serializing self._dtype_policy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Layers with arguments in `__init__` must override `get_config`."
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_RMSE3_json = model_RMSE3.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_RMSE3_json)\n",
    "# serialize weights to HDF5\n",
    "model_RMSE3_json.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "W266_Final_AmazonReviews.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
