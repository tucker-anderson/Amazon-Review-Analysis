{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Yoks35UT5or"
   },
   "source": [
    "# Predicting the Helpfulness of Amazon Reviews\n",
    "### Keane Johnson and Tucker Anderson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook builds multiple models that predict the helpfulness of Amazon reviews. It uses the [2015 Amazon Review dataset](http://jmcauley.ucsd.edu/data/amazon/index.html), compiled by Julian McAuley, associate professor in the Computer Science department at the University of California, San Diego.\n",
    "\n",
    "The dataset contains product reviews from Amazon from May 1996 - July 2014, and includes ratings, text, helpfulness votes, descriptions, category information, price, brand, and image features. It is broken into smaller subsets, organized by product category.\n",
    "\n",
    "This notebook focuses on the Home and Kitchen sub-category, and uses the aforementioned features to predict helpfulness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "- Import Libraries\n",
    "- Load and Prepare Dataset\n",
    "- Exploratory Data Analysis\n",
    "- Model 1: Every review is 100% helpful\n",
    "- Model 2: Naive Bayes Bag of Words with Binary Helpfulness Labels\n",
    "- Model 3: TFIDF and Logistic Regression\n",
    "- Model 4: BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9t_9MV2_UO1O"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WXeTT4GwA9bN"
   },
   "outputs": [],
   "source": [
    "# load packages\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import wget\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset - download directly from source, save to data directory\n",
    "\n",
    "file_name = \"data/reviews_Home_and_Kitchen_5.json.gz\"\n",
    "output_dir = \"data\"\n",
    "url = \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Home_and_Kitchen_5.json.gz\"\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "if not os.path.isfile(file_name):\n",
    "    file_name = wget.download(url, out=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to parse data from compressed json into pandas DF\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def get_dataframe(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "\n",
    "# helper function to pull out total helpful votes\n",
    "def get_helpful_votes(helpful):\n",
    "    [helpful, total] = helpful\n",
    "    return helpful\n",
    "\n",
    "\n",
    "# helper function to pull out total votes (helpful and unhelpful)\n",
    "def get_total_votes(helpful):\n",
    "    [helpful, total] = helpful\n",
    "    return total\n",
    "    \n",
    "    \n",
    "# helper function to calculate helpfulness percentage \n",
    "def calculate_helpful_perc(helpful):\n",
    "    [helpful, total] = helpful\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (helpful/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wHEe5MIfBIsL"
   },
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df = get_dataframe(file_name)\n",
    "\n",
    "# parse helpful column into new columns of helpful_votes, total_votes, helpful_perc\n",
    "df['helpful_votes'] = df['helpful'].apply(get_helpful_votes)\n",
    "df['total_votes'] = df['helpful'].apply(get_total_votes)\n",
    "df['helpful_perc'] = df['helpful'].apply(calculate_helpful_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCDusLkwUHJr"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(551682, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 551,682 rows and twelve columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345800</th>\n",
       "      <td>AJ6GY55K1ZSUV</td>\n",
       "      <td>B0036CQ8GO</td>\n",
       "      <td>Deborah</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Finally a mattress pad that fits a thick mattr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes it fits.</td>\n",
       "      <td>1367452800</td>\n",
       "      <td>05 2, 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109010</th>\n",
       "      <td>A1D03ANAAU6E8T</td>\n",
       "      <td>B0007INM5A</td>\n",
       "      <td>Margie L. Rusher</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I purchased these filters because I got tired ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>refillable coffee  filters</td>\n",
       "      <td>1358121600</td>\n",
       "      <td>01 14, 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349969</th>\n",
       "      <td>AUCIFMWP3DU8R</td>\n",
       "      <td>B00394E0TQ</td>\n",
       "      <td>R.S. Eisenberg \"Keeping it real since 1959\"</td>\n",
       "      <td>[4, 8]</td>\n",
       "      <td>In the eighties, near as I can remember, there...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Paddle me.</td>\n",
       "      <td>1277251200</td>\n",
       "      <td>06 23, 2010</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174947</th>\n",
       "      <td>A1F98QM3ACQKYC</td>\n",
       "      <td>B000KRWA24</td>\n",
       "      <td>Leslie L. Raymond \"book escapes\"</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>This pillow cover fit perfectly and is made of...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Perfect fit.</td>\n",
       "      <td>1366156800</td>\n",
       "      <td>04 17, 2013</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395899</th>\n",
       "      <td>A1YX3462Z32M36</td>\n",
       "      <td>B00479OWFO</td>\n",
       "      <td>Me</td>\n",
       "      <td>[111, 114]</td>\n",
       "      <td>I don't typically have unreasonable expectatio...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great product backed by great customer service.</td>\n",
       "      <td>1297641600</td>\n",
       "      <td>02 14, 2011</td>\n",
       "      <td>111</td>\n",
       "      <td>114</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin  \\\n",
       "345800   AJ6GY55K1ZSUV  B0036CQ8GO   \n",
       "109010  A1D03ANAAU6E8T  B0007INM5A   \n",
       "349969   AUCIFMWP3DU8R  B00394E0TQ   \n",
       "174947  A1F98QM3ACQKYC  B000KRWA24   \n",
       "395899  A1YX3462Z32M36  B00479OWFO   \n",
       "\n",
       "                                       reviewerName     helpful  \\\n",
       "345800                                      Deborah      [0, 0]   \n",
       "109010                             Margie L. Rusher      [0, 0]   \n",
       "349969  R.S. Eisenberg \"Keeping it real since 1959\"      [4, 8]   \n",
       "174947             Leslie L. Raymond \"book escapes\"      [2, 2]   \n",
       "395899                                           Me  [111, 114]   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "345800  Finally a mattress pad that fits a thick mattr...      5.0   \n",
       "109010  I purchased these filters because I got tired ...      5.0   \n",
       "349969  In the eighties, near as I can remember, there...      3.0   \n",
       "174947  This pillow cover fit perfectly and is made of...      5.0   \n",
       "395899  I don't typically have unreasonable expectatio...      5.0   \n",
       "\n",
       "                                                summary  unixReviewTime  \\\n",
       "345800                                     Yes it fits.      1367452800   \n",
       "109010                       refillable coffee  filters      1358121600   \n",
       "349969                                       Paddle me.      1277251200   \n",
       "174947                                     Perfect fit.      1366156800   \n",
       "395899  Great product backed by great customer service.      1297641600   \n",
       "\n",
       "         reviewTime  helpful_votes  total_votes  helpful_perc  \n",
       "345800   05 2, 2013              0            0      0.000000  \n",
       "109010  01 14, 2013              0            0      0.000000  \n",
       "349969  06 23, 2010              4            8      0.500000  \n",
       "174947  04 17, 2013              2            2      1.000000  \n",
       "395899  02 14, 2011            111          114      0.973684  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The twelve columns contain data including the reviewer name and review time, in addition to more applicable data to our models, like review text, summary, and helpful scores. The helpful column is a list of two numbers. The first number is the number of individuals who found that review helpful. The second number is the total number of individuals who scored that review.\n",
    "\n",
    "We parse out these two numbers in helpful_votes and total_votes. We calculate the helpfulness percentage as well in helpful_perc. This is simply the number of helpful_votes divided by the number of total_votes. Helpful_perc will be our target variable in our models.\n",
    "\n",
    "There are two sources of natural language in the dataset - reviewText and summary. We assume the reviewText will be more robust and impactful in determining whether a review is helpful or not. However, summary is a good resource for our models as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to examine the completeness of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19ad4cda2b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19ad4c35908>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),cbar=False,yticklabels=False,cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This heatmap shows that there are missing values for some observations of reviewerName. However, with such a large dataset, we could be missing some values for other features that just do not appear on this chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerName</th>\n",
       "      <td>4953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewText</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unixReviewTime</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewTime</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful_votes</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_votes</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful_perc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "reviewerID         0\n",
       "asin               0\n",
       "reviewerName    4953\n",
       "helpful            0\n",
       "reviewText         0\n",
       "overall            0\n",
       "summary            0\n",
       "unixReviewTime     0\n",
       "reviewTime         0\n",
       "helpful_votes      0\n",
       "total_votes        0\n",
       "helpful_perc       0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = pd.DataFrame(df.isnull().sum())\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We confirm that we are only missing values for reviewerName. We reason that this does not have an impact on our analysis because we will be using primarily the reviewText, and possibly the summary, to determine a review's helpfulness. Additionally, we argue that individuals do not consistently use a reviewer's name when determining a review's helpfulness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reviewing some sample data, and examining missing values, we next look at some summary statistics of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>551682.000000</td>\n",
       "      <td>5.516820e+05</td>\n",
       "      <td>551682.000000</td>\n",
       "      <td>551682.000000</td>\n",
       "      <td>551682.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.316655</td>\n",
       "      <td>1.348687e+09</td>\n",
       "      <td>3.497348</td>\n",
       "      <td>3.939469</td>\n",
       "      <td>0.367910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.110749</td>\n",
       "      <td>6.120238e+07</td>\n",
       "      <td>76.539142</td>\n",
       "      <td>77.801556</td>\n",
       "      <td>0.456931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.572256e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.331770e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.367626e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.388880e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.406074e+09</td>\n",
       "      <td>52176.000000</td>\n",
       "      <td>52861.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             overall  unixReviewTime  helpful_votes    total_votes  \\\n",
       "count  551682.000000    5.516820e+05  551682.000000  551682.000000   \n",
       "mean        4.316655    1.348687e+09       3.497348       3.939469   \n",
       "std         1.110749    6.120238e+07      76.539142      77.801556   \n",
       "min         1.000000    9.572256e+08       0.000000       0.000000   \n",
       "25%         4.000000    1.331770e+09       0.000000       0.000000   \n",
       "50%         5.000000    1.367626e+09       0.000000       0.000000   \n",
       "75%         5.000000    1.388880e+09       1.000000       2.000000   \n",
       "max         5.000000    1.406074e+09   52176.000000   52861.000000   \n",
       "\n",
       "        helpful_perc  \n",
       "count  551682.000000  \n",
       "mean        0.367910  \n",
       "std         0.456931  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These summary statistics show that over half of our observations have a 0% helpfulness. In addition, these observations have zero total votes. This means that the reviews simply haven't been voted upon. We should remove these observations from our dataset because our model could misinterpret the 0% helpful_perc to mean that the review was not helpful when in fact the review just hasn't been voted upon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a histogram to visualize the distribution of helpful percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x19ad8fcdbe0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X+0VVW99/H3R1HCVOTHkQhMVNBCnzRFpF/3kiSgWdgdangryUtqV7Ofz7j+eCpML/fRcS3Sp6tlyRC1VFJLMsnwR6m3EI+GIv4ICgwQAQFFLTX0+/yx5r4udmefsw+cuTccPq8x9jhrzbXm3N+5z2Z/z5xrsrYiAjMzs5x2aHYAZmbW/TnZmJlZdk42ZmaWnZONmZll52RjZmbZOdmYmVl2Tja2WSQtlDS62XE0k6SPS1om6SVJ78nQ/tWS/r3Oc3tJ+rmkFyT9pI7zfy3ps1sepVl9nGzs70haKunDVWWfkXR/ZT8iDoyIX3fQzhBJIalHplCb7RLg8xGxa0T8vvpg6vvQqrLzJV2XIZbjgQFAv4g4YUsaSjH+LSXR5yX9VtJ7uybMrpHxdbRMnGxsm7UVJLG9gYVNjqFib+APEbGxi9q7MSJ2BVqA+4FbJKkzDWwFvx/bijjZ2GYpj34kjZTUKmmDpFWSvp1Ouzf9fD79lfxeSTtI+pqkpyWtlnSNpN6ldk9Ox9ZK+nrV85wv6SZJ10naAHwmPffv0l/gKyV9V9LOpfZC0hmSFkl6UdKFkvZLf61vkDSzfH5VH9uMVVJPSS8BOwKPSPrjFryO75Q0R9I6SU9JOrHGeaMlLZd0nqTn0uvyyXTsm8A3gE+k13ly9V/+mzvKjIi/ATOAtwH9Ulv/IukJSesl3SFp79LzhKQzJS0CFqWyA0t9XCXpvFS+g6RzJP0x/b5nSupbFe8kSX9Off4/6dh44LxSfx9J5aekuF6U9CdJp1e9hv+W3iPPSPpseeSZfqeXpOdaJel7knqlY/0l3ZbeY+sk3SfJn52d5BfMusKlwKURsTuwHzAzlf9D+rlHmmr6HfCZ9PgQsC+wK/BdAEnDgcuBTwIDgd7AoKrnmgDcBOwB/Ah4Hfgy0B94LzAGOKOqzjjgMGAU8G/AlcCngL2Ag4CTavSrzVgj4tX0Vz/AwRGxX+2XpjZJbwXmAD8G9gQmApen16Etb6Po5yBgEnClpAMiYgrwH6TRSERctTnx1IixJ8VrsCwinpM0geKD/p8oRj33AddXVTsOOAIYLmk34E7gl8DbgaHAXem8s9K5/5iOrQf+q6qtDwAHUPxevyHpXRHxy6r+HpzOXQ0cC+wOnAJMk3Ro6sd44CvAh1MMo6ue5yJgf+CQdHwQRQIH+CqwPPV3QOq/7/PVWRHhhx+bPIClwEvA86XHX4D7q875cNq+F/gm0L+qnSEU/yh7lMruAs4o7R8A/A3oQfGP+/rSsV2A10rPcz5wbwexfwn4aWk/gPeX9h8Czi7tfwv4To22asZaantoO7EEsKHqdXwFuC4d/wRwX1Wd7wNT0vbVwL+n7dHARuCtpXNnAl8vvTbXlY5V72/yuwB+DXy2Rtznp9f9eYoP8LuBw9Kx2cDk0rk7pPfG3qU+H1k6fhLw+xrP8wQwprQ/sPReqMQ7uHR8HjCxrf7VaP9nwBfT9nTg/5aODa38/gABLwP7lY6/F1iSti8Abm3vd+1Hxw+PbKyW4yJij8qDvx8tlE2m+KvwSUkPSjq2nXPfDjxd2n+a4sNlQDq2rHIgIv4CrK2qv6y8I2n/NMXxbJpa+w+Kv/7LVpW2/9rG/q60rb1Y63Vo1et4UenY3sARaXrmeUnPU4zq3lajrfUR8XJVPG/vRCydMTPFvGdEHBkRD5VivrQU7zqKD+vyCLT8O9oLqDXNuDfw01JbT1CMVMuv77Ol7b9Q+3eFpKMlzU1TXc8Dx/Dme2GT91bVdgvFHzYPlWL5ZSoH+E9gMfCrND13Tq0YrDYnG9tiEbEoIk6imAq6GLgpTRG1NdXwDMWHTMU7KP5iXwWsBAZXDqQ5837VT1e1fwXwJDAsimm88yg+/LpCe7F2hWXAb8rJKIppoX+tcX6f9LqW43mmxrkvU3yAVtRKYJ21DDi9KuZeEfHb0jlRdf6+7bR1dFVbb4mIFXXEscn7IE333UyxQnBASuy38+Z7YZP3FkUSrHiO4o+OA0tx9I40VRoRL0bEVyNiX+BjwFckjakjRitxsrEtJulTkloi4g2KqReAN4A16Wf5w+Z64MuS9pG0K2/OvW+kuBbzUUnvSxftz6fjxLEbxVTVS5LeCdT6oN4c7cXaFW4D9pf0aUk7pcfhkt7VTp1vStpZ0gcprk/U+j8184F/kPQOFQswzu2imL8HnCvpQAAVCybaW2p9GzBQ0pfSRfjdJB1RamtqZYGBpJZ0Tageq4AhpQv1OwM9Kd5zGyUdDYwtnT8TOEXSuyTtAny9ciC9b39AcY1nzxTLIEnj0vaxkoZKEvACxejrjTrjtMTJxrrCeGChihVal1LMq/81TYNNBf47TU+Mopg7v5biOs8SimsYZwFExMK0fQPFX6IvUVwzeLWd5/7fwD8DL1J8YNzYhf2qGWtXiIgXKT4QJ1KMUJ6lGBn2rFHlWYqL6M9QLI74XEQ8WaPtORSvxaMU16lu66KYf5pivCFNWz4GHN3O+S8CRwEfTfEvolhwAcV7ZRbF9NSLwFyKhQX1qCTZtZIeTs/zBYqksp7iPTGrFMds4DLgHoopsbnpUOW9dXalPPXrToprdADD0v5LwO+AyyPinjrjtEQRXlRhW6c0mnieYopsSbPjaSYVd2u4LiIGd3SudSyNHh8DenbhSNXa4ZGNbVUkfVTSLunaxCXAAoqVb2ZbRMXthXpK6kMxOvu5E03jONnY1mYCxTTRMxTTFxPDw2/rGqdTTMv+keK6S1de37MOeBrNzMyy88jGzMyy843ykv79+8eQIUOaHYaZ2TbloYceei4iWjo6z8kmGTJkCK2trc0Ow8xsmyLp6Y7P8jSamZk1gJONmZll52RjZmbZOdmYmVl2TjZmZpadk42ZmWXnZGNmZtk52ZiZWXZONmZmlp3vINBFhpzzi5rHll70kQZGYma29fHIxszMsnOyMTOz7JxszMwsOycbMzPLzsnGzMyyc7IxM7PsnGzMzCw7JxszM8vOycbMzLJzsjEzs+ycbMzMLDsnGzMzyy5bspH0FknzJD0iaaGkb6byvpLmSFqUfvYp1TlX0mJJT0kaVyo/TNKCdOwySUrlPSXdmMofkDSkVGdSeo5Fkibl6qeZmXUs58jmVeDIiDgYOAQYL2kUcA5wV0QMA+5K+0gaDkwEDgTGA5dL2jG1dQVwKjAsPcan8snA+ogYCkwDLk5t9QWmAEcAI4Ep5aRmZmaNlS3ZROGltLtTegQwAZiRymcAx6XtCcANEfFqRCwBFgMjJQ0Edo+IuRERwDVVdSpt3QSMSaOeccCciFgXEeuBObyZoMzMrMGyXrORtKOk+cBqig//B4ABEbEynfIsMCBtDwKWlaovT2WD0nZ1+SZ1ImIj8ALQr522quM7TVKrpNY1a9Zsdj/NzKx9WZNNRLweEYcAgylGKQdVHQ+K0U5TRMSVETEiIka0tLQ0Kwwzs26vIavRIuJ54B6KqaxVaWqM9HN1Om0FsFep2uBUtiJtV5dvUkdSD6A3sLadtszMrAlyrkZrkbRH2u4FHAU8CcwCKqvDJgG3pu1ZwMS0wmwfioUA89KU2wZJo9L1mJOr6lTaOh64O42W7gDGSuqTFgaMTWVmZtYEPTK2PRCYkVaU7QDMjIjbJP0OmClpMvA0cCJARCyUNBN4HNgInBkRr6e2zgCuBnoBs9MD4CrgWkmLgXUUq9mIiHWSLgQeTOddEBHrMvbVzMzakS3ZRMSjwHvaKF8LjKlRZyowtY3yVuCgNspfAU6o0dZ0YHrnojYzsxx8BwEzM8vOycbMzLJzsjEzs+ycbMzMLDsnGzMzy87JxszMsnOyMTOz7JxszMwsOycbMzPLzsnGzMyyc7IxM7PsnGzMzCw7JxszM8vOycbMzLJzsjEzs+ycbMzMLDsnGzMzy87JxszMsnOyMTOz7JxszMwsOycbMzPLzsnGzMyyy5ZsJO0l6R5Jj0taKOmLqfx8SSskzU+PY0p1zpW0WNJTksaVyg+TtCAdu0ySUnlPSTem8gckDSnVmSRpUXpMytVPMzPrWI+MbW8EvhoRD0vaDXhI0px0bFpEXFI+WdJwYCJwIPB24E5J+0fE68AVwKnAA8DtwHhgNjAZWB8RQyVNBC4GPiGpLzAFGAFEeu5ZEbE+Y3/NzKyGbCObiFgZEQ+n7ReBJ4BB7VSZANwQEa9GxBJgMTBS0kBg94iYGxEBXAMcV6ozI23fBIxJo55xwJyIWJcSzByKBGVmZk3QkGs2aXrrPRQjE4CzJD0qabqkPqlsELCsVG15KhuUtqvLN6kTERuBF4B+7bRlZmZNkD3ZSNoVuBn4UkRsoJgS2xc4BFgJfCt3DO3EdpqkVkmta9asaVYYZmbdXtZkI2knikTzo4i4BSAiVkXE6xHxBvADYGQ6fQWwV6n64FS2Im1Xl29SR1IPoDewtp22NhERV0bEiIgY0dLSsiVdNTOzduRcjSbgKuCJiPh2qXxg6bSPA4+l7VnAxLTCbB9gGDAvIlYCGySNSm2eDNxaqlNZaXY8cHe6rnMHMFZSnzRNNzaVmZlZE+RcjfZ+4NPAAknzU9l5wEmSDqFYJbYUOB0gIhZKmgk8TrGS7cy0Eg3gDOBqoBfFKrTZqfwq4FpJi4F1FKvZiIh1ki4EHkznXRAR6zL108zMOpAt2UTE/YDaOHR7O3WmAlPbKG8FDmqj/BXghBptTQem1xuvmZnl4zsImJlZdk42ZmaWnZONmZll52RjZmbZOdmYmVl2TjZmZpadk42ZmWXnZGNmZtk52ZiZWXZONmZmlp2TjZmZZedkY2Zm2TnZmJlZdk42ZmaWnZONmZll52RjZmbZOdmYmVl2TjZmZpadk42ZmWXnZGNmZtk52ZiZWXZ1JRtJ/yt3IGZm1n3VO7K5XNI8SWdI6p01IjMz63bqSjYR8UHgk8BewEOSfizpqPbqSNpL0j2SHpe0UNIXU3lfSXMkLUo/+5TqnCtpsaSnJI0rlR8maUE6dpkkpfKekm5M5Q9IGlKqMyk9xyJJkzrxmpiZWRer+5pNRCwCvgacDfwjcJmkJyX9U40qG4GvRsRwYBRwpqThwDnAXRExDLgr7ZOOTQQOBMZTjKZ2TG1dAZwKDEuP8al8MrA+IoYC04CLU1t9gSnAEcBIYEo5qZmZWWPVe83m3ZKmAU8ARwIfjYh3pe1pbdWJiJUR8XDafjHVHQRMAGak02YAx6XtCcANEfFqRCwBFgMjJQ0Edo+IuRERwDVVdSpt3QSMSaOeccCciFgXEeuBObyZoMzMrMHqHdn8P+Bh4OCIOLOURJ6hGO20K01vvQd4ABgQESvToWeBAWl7ELCsVG15KhuUtqvLN6kTERuBF4B+7bRVHddpklolta5Zs6ajbpiZ2WaqN9l8BPhxRPwVQNIOknYBiIhr26soaVfgZuBLEbGhfCyNVKLTUXeRiLgyIkZExIiWlpZmhWFm1u3Vm2zuBHqV9ndJZe2StBNFovlRRNySilelqTHSz9WpfAXFAoSKwalsRdquLt+kjqQeQG9gbTttmZlZE9SbbN4SES9VdtL2Lu1VSNdOrgKeiIhvlw7NAiqrwyYBt5bKJ6YVZvtQLASYl6bcNkgaldo8uapOpa3jgbvTaOkOYKykPmlhwNhUZmZmTdCjzvNelnRo5VqNpMOAv3ZQ5/3Ap4EFkuansvOAi4CZkiYDTwMnAkTEQkkzgccpVrKdGRGvp3pnAFdTjK5mpwcUyexaSYuBdRSr2YiIdZIuBB5M510QEevq7KuZmXWxepPNl4CfSHoGEPA24BPtVYiI+9O5bRlTo85UYGob5a3AQW2UvwKcUKOt6cD09mI0M7PGqCvZRMSDkt4JHJCKnoqIv+ULy8zMupN6RzYAhwNDUp1DJRER12SJyszMupW6ko2ka4H9gPlA5TpK5T9YmpmZtavekc0IYHha6WVmZtYp9S59foxiUYCZmVmn1Tuy6Q88Lmke8GqlMCI+liUqMzPrVupNNufnDMLMzLq3epc+/0bS3sCwiLgz3Rdtx47qmZmZQf1fMXAqxS38v5+KBgE/yxWUmZl1L/UuEDiT4vYzG+B/vkhtz1xBmZlZ91Jvsnk1Il6r7KQ7LHsZtJmZ1aXeZPMbSecBvSQdBfwE+Hm+sMzMrDupN9mcA6wBFgCnA7dTxzd0mpmZQf2r0d4AfpAeZmZmnVLvvdGW0MY1mojYt8sjMjOzbqcz90areAvFd8j07fpwzMysO6rrmk1ErC09VkTEd4CPZI7NzMy6iXqn0Q4t7e5AMdLpzHfhmJnZdqzehPGt0vZGYClwYpdHY2Zm3VK9q9E+lDsQMzPrvuqdRvtKe8cj4ttdE46ZmXVHnVmNdjgwK+1/FJgHLMoRlJmZdS/1JpvBwKER8SKApPOBX0TEp3IFZmZm3Ue9t6sZALxW2n8tldUkabqk1ZIeK5WdL2mFpPnpcUzp2LmSFkt6StK4UvlhkhakY5dJUirvKenGVP6ApCGlOpMkLUqPSXX20czMMqk32VwDzEvJ4nzgAWBGB3WuBsa3UT4tIg5Jj9sBJA0HJgIHpjqXS6p8OdsVwKnAsPSotDkZWB8RQ4FpwMWprb7AFOAIYCQwRVKfOvtpZmYZ1Lsabaqk2cAHU9EpEfH7DurcWx5tdGACcENEvAoskbQYGClpKbB7RMwFkHQNcBwwO9U5P9W/CfhuGvWMA+ZExLpUZw5Fgrq+zljMzLqdIef8ouaxpRfl/z/69Y5sAHYBNkTEpcBySfts5nOeJenRNM1WGXEMApaVzlmeygal7eryTepExEbgBaBfO239HUmnSWqV1LpmzZrN7I6ZmXWk3q+FngKcDZybinYCrtuM57sC2Bc4BFjJpv9ZtOEi4sqIGBERI1paWpoZiplZt1bvyObjwMeAlwEi4hlgt84+WUSsiojXS19ZMDIdWgHsVTp1cCpbkbaryzepk745tDewtp22zMysSepNNq9FRJC+ZkDSWzfnySQNLO1+HKisVJsFTEwrzPahWAgwLyJWAhskjUrXY04Gbi3Vqaw0Ox64O8V4BzBWUp80TTc2lZmZWZPU+/9sZkr6PrCHpFOBf6GDL1KTdD0wGugvaTnFCrHRkg6hSFpLKb71k4hYKGkm8DjFvdfOjIjXU1NnUKxs60WxMGB2Kr8KuDYtJlhHsZqNiFgn6ULgwXTeBZXFAmZm1hz1rka7RNJRwAbgAOAbETGngzontVF8VTvnTwWmtlHeChzURvkrFN+r01Zb04Hp7cVnZmaN02GySf/f5c50M852E4yZmVlbOrxmk6az3pDUuwHxmJlZN1TvNZuXgAXpP0i+XCmMiC9kicrMzLqVepPNLelhZmbWae0mG0nviIg/R0RH90EzMzOrqaNrNj+rbEi6OXMsZmbWTXWUbFTa3jdnIGZm1n11lGyixraZmVndOlogcLCkDRQjnF5pm7QfEbF71ujMzKxbaDfZRMSO7R03MzOrR2e+z8bMzGyzONmYmVl2TjZmZpadk42ZmWXnZGNmZtk52ZiZWXZONmZmlp2TjZmZZedkY2Zm2TnZmJlZdk42ZmaWnZONmZll52RjZmbZZUs2kqZLWi3psVJZX0lzJC1KP/uUjp0rabGkpySNK5UfJmlBOnaZJKXynpJuTOUPSBpSqjMpPcciSZNy9dHMzOqTc2RzNTC+quwc4K6IGAbclfaRNByYCByY6lwuqfL1BlcApwLD0qPS5mRgfUQMBaYBF6e2+gJTgCOAkcCUclIzM7PGy5ZsIuJeYF1V8QRgRtqeARxXKr8hIl6NiCXAYmCkpIHA7hExNyICuKaqTqWtm4AxadQzDpgTEesiYj0wh79PemZm1kCNvmYzICJWpu1ngQFpexCwrHTe8lQ2KG1Xl29SJyI2Ai8A/dpp6+9IOk1Sq6TWNWvWbG6fzMysA01bIJBGKtGs508xXBkRIyJiREtLSzNDMTPr1hqdbFalqTHSz9WpfAWwV+m8walsRdquLt+kjqQeQG9gbTttmZlZkzQ62cwCKqvDJgG3lsonphVm+1AsBJiXptw2SBqVrsecXFWn0tbxwN1ptHQHMFZSn7QwYGwqMzOzJumRq2FJ1wOjgf6SllOsELsImClpMvA0cCJARCyUNBN4HNgInBkRr6emzqBY2dYLmJ0eAFcB10paTLEQYWJqa52kC4EH03kXRET1QgUzM2ugbMkmIk6qcWhMjfOnAlPbKG8FDmqj/BXghBptTQem1x2smZll5TsImJlZdk42ZmaWnZONmZll52RjZmbZOdmYmVl2TjZmZpadk42ZmWXnZGNmZtk52ZiZWXZONmZmlp2TjZmZZedkY2Zm2TnZmJlZdk42ZmaWnZONmZll52RjZmbZOdmYmVl2TjZmZpadk42ZmWXnZGNmZtk52ZiZWXZONmZmlp2TjZmZZdeUZCNpqaQFkuZLak1lfSXNkbQo/exTOv9cSYslPSVpXKn8sNTOYkmXSVIq7ynpxlT+gKQhje6jmZm9qZkjmw9FxCERMSLtnwPcFRHDgLvSPpKGAxOBA4HxwOWSdkx1rgBOBYalx/hUPhlYHxFDgWnAxQ3oj5mZ1bA1TaNNAGak7RnAcaXyGyLi1YhYAiwGRkoaCOweEXMjIoBrqupU2roJGFMZ9ZiZWeM1K9kEcKekhySdlsoGRMTKtP0sMCBtDwKWleouT2WD0nZ1+SZ1ImIj8ALQrzoISadJapXUumbNmi3vlZmZtalHk573AxGxQtKewBxJT5YPRkRIitxBRMSVwJUAI0aMyP58Zmbbq6aMbCJiRfq5GvgpMBJYlabGSD9Xp9NXAHuVqg9OZSvSdnX5JnUk9QB6A2tz9MXMzDrW8GQj6a2SdqtsA2OBx4BZwKR02iTg1rQ9C5iYVpjtQ7EQYF6actsgaVS6HnNyVZ1KW8cDd6frOmZm1gTNmEYbAPw0Xa/vAfw4In4p6UFgpqTJwNPAiQARsVDSTOBxYCNwZkS8nto6A7ga6AXMTg+Aq4BrJS0G1lGsZjMzsyZpeLKJiD8BB7dRvhYYU6POVGBqG+WtwEFtlL8CnLDFwZqZWZfYmpY+m5lZN+VkY2Zm2TnZmJlZdk42ZmaWnZONmZll52RjZmbZOdmYmVl2TjZmZpadk42ZmWXnZGNmZtk52ZiZWXZONmZmlp2TjZmZZedkY2Zm2TnZmJlZdk42ZmaWXTO+qdPMOmnIOb+oeWzpRR9pYCRmm8cjGzMzy87JxszMsnOyMTOz7HzNxswayteftk8e2ZiZWXYe2ZjZNq+90RJ4xLQ16NbJRtJ44FJgR+CHEXFRk0Mys63M5k7rdZTgmmFrTqrdNtlI2hH4L+AoYDnwoKRZEfF4cyOzRvG1AdvebI0JsKLbJhtgJLA4Iv4EIOkGYALgZNME29oH/7YW7+bK8eG0Ja9Prg/LzW13a/7w3tYoIpodQxaSjgfGR8Rn0/6ngSMi4vOlc04DTku7BwBPbcFT9gee24L626Ltrc/bW3/Bfd5ebEmf946Ilo5O6s4jmw5FxJXAlV3RlqTWiBjRFW1tK7a3Pm9v/QX3eXvRiD5356XPK4C9SvuDU5mZmTVYd042DwLDJO0jaWdgIjCryTGZmW2Xuu00WkRslPR54A6Kpc/TI2Jhxqfskum4bcz21uftrb/gPm8vsve52y4QMDOzrUd3nkYzM7OthJONmZll52TTCZLGS3pK0mJJ57RxXJIuS8cflXRoM+LsSnX0+ZOprwsk/VbSwc2Isyt11OfSeYdL2pj+T9c2rZ4+Sxotab6khZJ+0+gYu1od7+3ekn4u6ZHU51OaEWdXkTRd0mpJj9U4nvfzKyL8qONBscjgj8C+wM7AI8DwqnOOAWYDAkYBDzQ77gb0+X1An7R99PbQ59J5dwO3A8c3O+4G/J73oLj7xjvS/p7NjrsBfT4PuDhttwDrgJ2bHfsW9PkfgEOBx2ocz/r55ZFN/f7n9jcR8RpQuf1N2QTgmijMBfaQNLDRgXahDvscEb+NiPVpdy7F/2faltXzewY4C7gZWN3I4DKpp8//DNwSEX8GiIhtvd/19DmA3SQJ2JUi2WxsbJhdJyLupehDLVk/v5xs6jcIWFbaX57KOnvOtqSz/ZlM8ZfRtqzDPksaBHwcuKKBceVUz+95f6CPpF9LekjSyQ2LLo96+vxd4F3AM8AC4IsR8UZjwmuKrJ9f3fb/2VhjSfoQRbL5QLNjaYDvAGdHxBvFH73bhR7AYcAYoBfwO0lzI+IPzQ0rq3HAfOBIYD9gjqT7ImJDc8PaNjnZ1K+e2990t1vk1NUfSe8GfggcHRFrGxRbLvX0eQRwQ0o0/YFjJG2MiJ81JsQuV0+flwNrI+Jl4GVJ9wIHA9tqsqmnz6cAF0VxQWOxpCXAO4F5jQmx4bJ+fnkarX713P5mFnByWtUxCnghIlY2OtAu1GGfJb0DuAX4dDf5K7fDPkfEPhExJCKGADcBZ2zDiQbqe2/fCnxAUg9JuwBHAE80OM6uVE+f/0wxkkPSAIo7w/+poVE2VtbPL49s6hQ1bn8j6XPp+PcoViYdAywG/kLxl9E2q84+fwPoB1ye/tLfGNvwHXPr7HO3Uk+fI+IJSb8EHgXeoPjm2zaX0G4L6vw9XwhcLWkBxQqtsyNim/3qAUnXA6OB/pKWA1OAnaAxn1++XY2ZmWXnaTQzM8vOycbMzLJzsjEzs+ycbMzMLDsnGzMzy87JxqyTJL1Utf8ZSd/toE6H56Tzrk933P1yO+eMlnRbjfIX0p2Zn5A0paPnM2sU/z8bs62EpLcBh0fE0C1o5r6IOFbSW4H5kn4eEQ/X8dw9ImKbvcmkbf08sjHrQpJaJN0s6cH0eH8b51wt6XuSWiX9QdKx6dCvgEFpZPLBdNPLEalOf0lL640j3VbmIWCopB0l/WeK51FJp6c2R0u6T9Isiq8PQNLJ6ZxHJF27Za+G2Zs8sjHnQH29AAABr0lEQVTrvF6S5pf2+/LmrU4uBaZFxP3pVj53UNw5uNoQitvc7wfcI2ko8DHgtog4BGBLbvIpqR/Fd5JcSHGD1Bci4nBJPYH/lvSrdOqhwEERsUTSgcDXgPdFxHOS+m52AGZVnGzMOu+vlYQAxfUYiptzAnwYGF5KFLtL2rWNNmam29UvkvQnihs8Pt8FsX1Q0u8pbilzUboFyzeBd+vNbxTtDQwDXgPmRcSSVH4k8JPKLVkior3vPjHrFCcbs661AzAqIl4pF7YxSqm+T1Rb943ayJtT3W+p8/nvi4hjq8oEnBURd1TFNBp4uc52zbaIr9mYda1fUXyLJwCSDqlx3gmSdpC0H8VXEz/VxjlLKb5DBuD4No7X6w7gXyXtlGLaPy0gqHZ3iqtfOs/TaNZlnGzMutYXgBHpIvvjwOdqnPdniu9FmQ18rnoklFxCkSR+T/G9OZvrhxQLAB6W9BjwfdqY1YiIhcBU4DeSHgG+vQXPabYJ3/XZrMEkXU2xEOCmZsdi1ige2ZiZWXYe2ZiZWXYe2ZiZWXZONmZmlp2TjZmZZedkY2Zm2TnZmJlZdv8fvj+s0e6/cEwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19ae63b7128>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "n, bins, patches = ax1.hist(x=df['helpful_perc'], bins='auto')\n",
    "                                 \n",
    "ax1.set_xlabel('Helpful Perc')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Histogram of Helpful Percentages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram shows that the majority of reviews have a 0% helpful percentage, with the second most prevalent percentage being 100%. However, our dataset needs to be cleaned to remove observations that may add noise, but do not add meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be purposeful with the data that we are supplying to our model. We want to only analyze reviews where there are at least three total votes, or reviews where there are two total votes, but both votes are in agreement.\n",
    "\n",
    "Our rationale is that two total votes that are split does not tell us much. However, if both are an agreeement, that could tell us something about a reviews helpfulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139470, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset df of reviews that have at least three votes\n",
    "df_three = df[df.total_votes >= 3]\n",
    "\n",
    "# subset df of reviews that have two both and both are in agreeement\n",
    "df_two = df[((df.total_votes == 2) & (df.helpful_perc == 1)) | ((df.total_votes == 2) & (df.helpful_perc == 0))]\n",
    "\n",
    "# combine the dfs back together\n",
    "df = df_three.append(df_two, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of our dataset is now 139,470 rows. Next we can examine the new distribution of helpful_perc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>139470.000000</td>\n",
       "      <td>1.394700e+05</td>\n",
       "      <td>139470.000000</td>\n",
       "      <td>139470.000000</td>\n",
       "      <td>139470.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.988270</td>\n",
       "      <td>1.301792e+09</td>\n",
       "      <td>13.178676</td>\n",
       "      <td>14.704022</td>\n",
       "      <td>0.848035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.356746</td>\n",
       "      <td>8.137408e+07</td>\n",
       "      <td>151.811710</td>\n",
       "      <td>154.232187</td>\n",
       "      <td>0.242654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.572256e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.261181e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.324080e+09</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.362874e+09</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.405728e+09</td>\n",
       "      <td>52176.000000</td>\n",
       "      <td>52861.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             overall  unixReviewTime  helpful_votes    total_votes  \\\n",
       "count  139470.000000    1.394700e+05  139470.000000  139470.000000   \n",
       "mean        3.988270    1.301792e+09      13.178676      14.704022   \n",
       "std         1.356746    8.137408e+07     151.811710     154.232187   \n",
       "min         1.000000    9.572256e+08       0.000000       2.000000   \n",
       "25%         3.000000    1.261181e+09       2.000000       3.000000   \n",
       "50%         5.000000    1.324080e+09       4.000000       5.000000   \n",
       "75%         5.000000    1.362874e+09       9.000000      10.000000   \n",
       "max         5.000000    1.405728e+09   52176.000000   52861.000000   \n",
       "\n",
       "        helpful_perc  \n",
       "count  139470.000000  \n",
       "mean        0.848035  \n",
       "std         0.242654  \n",
       "min         0.000000  \n",
       "25%         0.750000  \n",
       "50%         1.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median helpful_perc is 100%. We could be at risk of not having a good distribution of data to train on. This could result in our model being overly optimistic and inflating the helpfulness scores of reviews. We can visualize this skew with another histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x19a810d9358>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19a82b73be0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(1, 1, 1)\n",
    "n, bins, patches = ax2.hist(x=df['helpful_perc'], bins='auto')\n",
    "                                 \n",
    "ax2.set_xlabel('Helpful Perc')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Histogram of Helpful Percentages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Subsetting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to resource constraints, we'll subset our data to roughly half the original size. This is still more than enough data to build and test our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled = df.sample(80000)\n",
    "df_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x19af7eab358>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19afe982320>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig3 = plt.figure()\n",
    "ax3 = fig3.add_subplot(1, 1, 1)\n",
    "n, bins, patches = ax3.hist(x=df['helpful_perc'], bins='auto')\n",
    "                                 \n",
    "ax3.set_xlabel('Helpful Perc')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('Histogram of Helpful Percentages of Subsetted Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the sampled data visually matches the distribution of the original dataset. We can confirm the distributions are identical with the Kolmogorov-Smirnov statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.0010859718935971596, pvalue=0.99999998789089961)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "df_sampled_helpful_prec = df_sampled['helpful_perc']\n",
    "df_helpful_perc = df['helpful_perc']\n",
    "\n",
    "ks_2samp(df_sampled_helpful_prec, df_helpful_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sampled becomes our df\n",
    "df = df_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Every Review is Helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic model we can produce is to label each review as being helpful if it meets a certain helpful_perc threshold. We choose 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every Review is Helpful Accuracy Score ->  79.32625\n"
     ]
    }
   ],
   "source": [
    "# calculate total number of reviews\n",
    "total_reviews = len(df)\n",
    "\n",
    "# calculate total number of reviews that are at least 75% helpful\n",
    "helpful_reviews = len(df[df.helpful_perc >= 0.75])\n",
    "\n",
    "# calculate accuracy if we predicted each review is at least 75% helpful\n",
    "accuracy_1 = 100*(helpful_reviews/total_reviews)\n",
    "\n",
    "print(\"Every Review is Helpful Accuracy Score -> \", accuracy_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model would produce an accuracy score of 79.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Naive Bayes Bag of Words with Binary Helpfulness Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more sophisticated model is one where we estimate the hepfulness of a review using its text. We use a Bag of Words model to determine whether a review is helpful or not. We again define a helpful review as one whose helpfulness percentage is at least 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# this nltk download may be needed. download stopwords, punkt\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure there are no missing values in the review or summary text or the overall helpullness percentage\n",
    "len(df) == len(df.dropna(subset=['reviewText', 'summary', 'helpful_perc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our bag of words model, we will combine the reviewText and summary text fields to combine into a single \"document\" with which to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize(text):\n",
    "    return [word for word in word_tokenize(text) if not word in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should then tokenize and stem the review data before ingesting into our NLP models\n",
    "df['combinedText'] = df['summary'].str.lower() + \". \" +  df['reviewText'].str.lower()\n",
    "\n",
    "# Now tokenize these and remove stop words\n",
    "df['processedText'] = df['combinedText'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column for helpful reviews (reviews with at least a 75% helpfulness rating)\n",
    "\n",
    "df[\"isHelpful\"] = df[\"helpful_perc\"] > .75\n",
    "df[\"isHelpful\"] = df[\"isHelpful\"].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "      <th>combinedText</th>\n",
       "      <th>processedText</th>\n",
       "      <th>isHelpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103034</th>\n",
       "      <td>A1ZCJ13AM3GZSC</td>\n",
       "      <td>B00B6EKM70</td>\n",
       "      <td>Tamimp \"princer\"</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>I am the newest Z Malouf  pillow fan.  I've bo...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Perfect Size, Comfortable &amp; Cool</td>\n",
       "      <td>1395014400</td>\n",
       "      <td>03 17, 2014</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>perfect size, comfortable &amp; cool. i am the new...</td>\n",
       "      <td>[perfect, size, ,, comfortable, &amp;, cool, ., ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107681</th>\n",
       "      <td>A3EEAA5MOWZBIE</td>\n",
       "      <td>B00FSQTSB8</td>\n",
       "      <td>Amazon Scott</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>After discovering that the battery charger for...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>More time options and less expensive than othe...</td>\n",
       "      <td>1394928000</td>\n",
       "      <td>03 16, 2014</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>more time options and less expensive than othe...</td>\n",
       "      <td>[time, options, less, expensive, brand, ., qui...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34939</th>\n",
       "      <td>A37O2OVL04L241</td>\n",
       "      <td>B000FKT6UA</td>\n",
       "      <td>Highland Gal</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>The directions leave much to be desired ... pa...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Chef's Choice Egg cooker</td>\n",
       "      <td>1234569600</td>\n",
       "      <td>02 14, 2009</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>chef's choice egg cooker. the directions leave...</td>\n",
       "      <td>[chef, 's, choice, egg, cooker, ., directions,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121031</th>\n",
       "      <td>A3EBOICV63T4BK</td>\n",
       "      <td>B000OQAMOO</td>\n",
       "      <td>S. Kallshian</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>This dog really is man's best friend.  Our hou...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Old Yeller does a mighty fine job!</td>\n",
       "      <td>1236124800</td>\n",
       "      <td>03 4, 2009</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>old yeller does a mighty fine job!. this dog r...</td>\n",
       "      <td>[old, yeller, mighty, fine, job, !, ., dog, re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56146</th>\n",
       "      <td>A94YSWPEFRFEO</td>\n",
       "      <td>B001D4F7NM</td>\n",
       "      <td>rlg64</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>It is exactly what I needed.  You can take the...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>perfect drying rack!</td>\n",
       "      <td>1347321600</td>\n",
       "      <td>09 11, 2012</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>perfect drying rack!. it is exactly what i nee...</td>\n",
       "      <td>[perfect, drying, rack, !, ., exactly, needed,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin      reviewerName  helpful  \\\n",
       "103034  A1ZCJ13AM3GZSC  B00B6EKM70  Tamimp \"princer\"   [3, 3]   \n",
       "107681  A3EEAA5MOWZBIE  B00FSQTSB8      Amazon Scott   [5, 5]   \n",
       "34939   A37O2OVL04L241  B000FKT6UA      Highland Gal   [3, 4]   \n",
       "121031  A3EBOICV63T4BK  B000OQAMOO      S. Kallshian   [2, 2]   \n",
       "56146    A94YSWPEFRFEO  B001D4F7NM             rlg64  [8, 10]   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "103034  I am the newest Z Malouf  pillow fan.  I've bo...      5.0   \n",
       "107681  After discovering that the battery charger for...      5.0   \n",
       "34939   The directions leave much to be desired ... pa...      3.0   \n",
       "121031  This dog really is man's best friend.  Our hou...      5.0   \n",
       "56146   It is exactly what I needed.  You can take the...      5.0   \n",
       "\n",
       "                                                  summary  unixReviewTime  \\\n",
       "103034                   Perfect Size, Comfortable & Cool      1395014400   \n",
       "107681  More time options and less expensive than othe...      1394928000   \n",
       "34939                            Chef's Choice Egg cooker      1234569600   \n",
       "121031                 Old Yeller does a mighty fine job!      1236124800   \n",
       "56146                                perfect drying rack!      1347321600   \n",
       "\n",
       "         reviewTime  helpful_votes  total_votes  helpful_perc  \\\n",
       "103034  03 17, 2014              3            3          1.00   \n",
       "107681  03 16, 2014              5            5          1.00   \n",
       "34939   02 14, 2009              3            4          0.75   \n",
       "121031   03 4, 2009              2            2          1.00   \n",
       "56146   09 11, 2012              8           10          0.80   \n",
       "\n",
       "                                             combinedText  \\\n",
       "103034  perfect size, comfortable & cool. i am the new...   \n",
       "107681  more time options and less expensive than othe...   \n",
       "34939   chef's choice egg cooker. the directions leave...   \n",
       "121031  old yeller does a mighty fine job!. this dog r...   \n",
       "56146   perfect drying rack!. it is exactly what i nee...   \n",
       "\n",
       "                                            processedText  isHelpful  \n",
       "103034  [perfect, size, ,, comfortable, &, cool, ., ne...          1  \n",
       "107681  [time, options, less, expensive, brand, ., qui...          1  \n",
       "34939   [chef, 's, choice, egg, cooker, ., directions,...          0  \n",
       "121031  [old, yeller, mighty, fine, job, !, ., dog, re...          1  \n",
       "56146   [perfect, drying, rack, !, ., exactly, needed,...          1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's make sure everything looks ok\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x19a990a5438>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19a99086b38>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take a look at distribution of Helpful/Not Helpful\n",
    "\n",
    "fig4 = plt.figure()\n",
    "ax4 = fig4.add_subplot(1, 1, 1)\n",
    "n, bins, patches = ax4.hist(x=df['isHelpful'], bins=2)\n",
    "                                 \n",
    "ax4.set_xlabel('Helpful')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title('Histogram of Helpful/Not Helpful Reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "data = df[['combinedText', 'isHelpful']]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "preprocessed_data = data.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(preprocessed_data['combinedText'], \n",
    "                                                    preprocessed_data['isHelpful'],\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Accuracy Score ->  74.95625\n"
     ]
    }
   ],
   "source": [
    "# and train our classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "g_classifier = GaussianNB().fit(np.array(Train_X.values.tolist()).reshape(-1, 1), Train_Y)\n",
    "accuracy_2 = accuracy_score(Test_Y, g_classifier.predict(np.array(Test_X.values.tolist()).reshape(-1, 1)))*100\n",
    "\n",
    "print(\"Gaussian Naive Bayes Accuracy Score -> \", accuracy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Naive Bayes Bag of Words model performs worse than our previous \"every review is helpful\" baseline model. It produces an accuracy score of 75.3%, down from 79.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: TF-IDF and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import sklearn\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/validation/test sets\n",
    "data = df[['combinedText', 'isHelpful']]\n",
    "\n",
    "df_train, df_test = train_test_split(data, test_size = 0.2)\n",
    "df_train, df_val = train_test_split(df_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem combinedText to reduce size of corpus\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter=PorterStemmer()\n",
    "\n",
    "def stem_text(df):\n",
    "    text_list = df['combinedText'].tolist()\n",
    "    text_list_stem = [None] * len(text_list)\n",
    "\n",
    "    for i in range(len(text_list)):\n",
    "        text_list_stem[i] = ' '.join([porter.stem(w) for w in text_list[i].split()])\n",
    "    \n",
    "    return text_list_stem\n",
    "\n",
    "text_list_stem = stem_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.32598197,  0.09018808],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.12857731,  0.19565122],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.11887192,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.04998395,  0.        ,  0.04506791, ...,  0.        ,\n",
       "         0.10960478,  0.05559382]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "                max_features=100,\n",
    "                ngram_range=(1,1)\n",
    "                )\n",
    "\n",
    "vectorizer.fit_transform(text_list_stem).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (51200, 100)\n"
     ]
    }
   ],
   "source": [
    "# vectorize train dataset\n",
    "train_text_stem = stem_text(df_train)\n",
    "train_vectorized = vectorizer.transform(train_text_stem).toarray()\n",
    "\n",
    "print('Shape:', train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (12800, 100)\n"
     ]
    }
   ],
   "source": [
    "# vectorize val dataset\n",
    "val_text_stem = stem_text(df_val)\n",
    "val_vectorized = vectorizer.transform(val_text_stem).toarray()\n",
    "\n",
    "print('Shape:', val_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (16000, 100)\n"
     ]
    }
   ],
   "source": [
    "# vectorize test dataset\n",
    "test_text_stem = stem_text(df_test)\n",
    "test_vectorized = vectorizer.transform(test_text_stem).toarray()\n",
    "\n",
    "print('Shape:', test_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array of labels to use in logistic regression\n",
    "df_train_labels = np.array(df_train['isHelpful'])\n",
    "df_test_labels = np.array(df_test['isHelpful'])\n",
    "df_val_labels = np.array(df_val['isHelpful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tla0113\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train logistic regression\n",
    "lr = LogisticRegression(penalty='l2')\n",
    "lr.fit(train_vectorized, df_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tla0113\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 0.01   validation set accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tla0113\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 0.1   validation set accuracy: 0.752734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tla0113\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 1.0   validation set accuracy: 0.751953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tla0113\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 10   validation set accuracy: 0.751640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tla0113\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 100   validation set accuracy: 0.7515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tla0113\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 1000   validation set accuracy: 0.7515625\n"
     ]
    }
   ],
   "source": [
    "# tune hyperparameters\n",
    "reg_str = [0.01, 0.1, 1.0, 10, 100, 1000]\n",
    "\n",
    "best_acc = -1\n",
    "best_c = None\n",
    "\n",
    "for r in reg_str:\n",
    "    lr = LogisticRegression(penalty='l2', C=r)\n",
    "    lr.fit(train_vectorized, df_train_labels)\n",
    "    preds = lr.predict(val_vectorized)\n",
    "    acc = np.mean(preds == df_val_labels)\n",
    "    print('regularization strength:', r, ' ', 'validation set accuracy:', acc)\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_c = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tla0113\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF and Logistic Regression Accuracy Score -> 75.4625\n"
     ]
    }
   ],
   "source": [
    "# test accuracy\n",
    "lr_final = LogisticRegression(penalty='l2', C = best_c)\n",
    "lr_final.fit(train_vectorized, df_train_labels)\n",
    "\n",
    "preds = lr_final.predict(test_vectorized)\n",
    "accuracy_3 = 100*np.mean(preds == df_test_labels)\n",
    "\n",
    "print(\"TF-IDF and Logistic Regression Accuracy Score ->\", accuracy_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with term frequency–inverse document frequency and logistic regression produces a marginally higher accuracy than the Naive Bayes Bag of Words model, but it is still not higher than the rudimentary Every Review is Helpful model. This motivates the need for a more robust representation of the language in the reviews. Enter BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code built around Strongio's notebook here https://github.com/strongio/keras-bert/blob/master/keras-bert.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import optimization\n",
    "import run_classifier\n",
    "import tokenization\n",
    "import run_classifier_with_tfhub\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Tensorflow hub path to BERT module of choice\n",
    "BERT_DIR =  \"./bert\"\n",
    "BERT_PATH = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "BERT_PATH\n",
    "MAX_SEQ_LENGTH = 512\n",
    "\n",
    "sys.path.insert(0,BERT_DIR)\n",
    "\n",
    "# Initialize session, may need to remove config if no GPU\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "  When running eval/predict on the TPU, we need to pad the number of examples\n",
    "  to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "  size. The alternative is to drop the last batch, which is bad because it means\n",
    "  the entire output data won't be generated.\n",
    "  We use this class instead of `None` because treating `None` as padding\n",
    "  battches could cause silent errors.\n",
    "  \"\"\"\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "def create_tokenizer_from_hub_module(path):\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module =  hub.Module(path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1127 10:56:19.844864 29908 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module(BERT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create the combinedText with casing and no longer than 512 characters (max of BERT embedding input)\n",
    "df['combinedText'] = df['summary'] + \". \" + df['reviewText']\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2)\n",
    "df_train, df_val = train_test_split(df_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd396957f73f438aa23d450d59c8b57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=51200, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051e0c2a46474617b1e5a87e401cd699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=12800, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10133dd759f4166bea9472e01cde218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=16000, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(df_train['combinedText'], df_train['helpful_perc'])\n",
    "val_examples = convert_text_to_examples(df_val['combinedText'], df_val['helpful_perc'])\n",
    "test_examples = convert_text_to_examples(df_test['combinedText'], df_test['helpful_perc'])\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
    ") = convert_examples_to_features(tokenizer, train_examples, max_seq_length=MAX_SEQ_LENGTH)\n",
    "(val_input_ids, val_input_masks, val_segment_ids, val_labels \n",
    ") = convert_examples_to_features(tokenizer, val_examples, max_seq_length=MAX_SEQ_LENGTH)\n",
    "(test_input_ids, test_input_masks, test_segment_ids, test_labels\n",
    ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"first\",\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_path = bert_path\n",
    "        if self.pooling not in [\"first\", \"mean\"]:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "\n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(max_seq_length, model_loss): \n",
    "    in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    bert_output = BertLayer(n_fine_tune_layers=3, pooling=\"first\")(bert_inputs)\n",
    "    dense = tf.keras.layers.Dense(max_seq_length, activation='relu')(bert_output)\n",
    "    pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss=model_loss, optimizer='adam')\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)\n",
    "    K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1127 13:38:14.005822 29908 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_2 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          393728      bert_layer_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            513         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 110,499,131\n",
      "Trainable params: 22,248,449\n",
      "Non-trainable params: 88,250,682\n",
      "__________________________________________________________________________________________________\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1127 13:38:29.905910 29908 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tla0113\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 13:38:30.310913 29908 deprecation.py:323] From C:\\Users\\tla0113\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_3 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          393728      bert_layer_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            513         dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 110,499,131\n",
      "Trainable params: 22,248,449\n",
      "Non-trainable params: 88,250,682\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# let's define some models!\n",
    "\n",
    "#BCE Model: using BCE in regression https://stats.stackexchange.com/questions/370179/why-binary-crossentropy-can-be-used-as-the-loss-function-in-autoencoders/370180#370180\n",
    "model_BCE = build_model(MAX_SEQ_LENGTH, 'binary_crossentropy')\n",
    "model_RMSE = build_model(MAX_SEQ_LENGTH, 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#we can now finally build a model\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "model_BCE.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n",
    "    epochs=1,\n",
    "    batch_size=32\n",
    ")\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#we can now finally build a model\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "model_RMSE.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n",
    "    epochs=1,\n",
    "    batch_size=32\n",
    ")\n",
    "warnings.filterwarnings('default')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "W266_Final_AmazonReviews.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
