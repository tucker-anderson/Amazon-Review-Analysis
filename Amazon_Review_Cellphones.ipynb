{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Helpfulness of Amazon Reviews - Cellphones and Accessories Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import wget\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "# this nltk download may be needed. download stopwords, punkt\n",
    "# nltk.download()\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset - download directly from source, save to data directory\n",
    "\n",
    "file_name = \"data/reviews_Cell_Phones_and_Accessories_5.json.gz\"\n",
    "output_dir = \"data\"\n",
    "url = \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz\"\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "if not os.path.isfile(file_name):\n",
    "    file_name = wget.download(url, out=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to parse data from compressed json into pandas DF\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def get_dataframe(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "\n",
    "# helper function to pull out total helpful votes\n",
    "def get_helpful_votes(helpful):\n",
    "    [helpful, total] = helpful\n",
    "    return helpful\n",
    "\n",
    "\n",
    "# helper function to pull out total votes (helpful and unhelpful)\n",
    "def get_total_votes(helpful):\n",
    "    [helpful, total] = helpful\n",
    "    return total\n",
    "    \n",
    "    \n",
    "# helper function to calculate helpfulness percentage \n",
    "def calculate_helpful_perc(helpful):\n",
    "    [helpful, total] = helpful\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (helpful/total)\n",
    "\n",
    "# helper function to return a df of only and equally-balanced zero and one hundred percent helpful percentages\n",
    "def ones_and_zeroes_df(df):\n",
    "    df_zeroes = df[df.helpful_perc == 0]\n",
    "    len_zero = len(df_zeroes)\n",
    "    \n",
    "    df_ones = df[df.helpful_perc == 1]\n",
    "    len_one = len(df_ones)\n",
    "    \n",
    "    min_len = min(len_zero, len_one)\n",
    "    \n",
    "    df_ones = df.sample(min_len)\n",
    "    df_zeroes = df.sample(min_len)\n",
    "    \n",
    "    df = df_ones.append(df_zeroes, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df = get_dataframe(file_name)\n",
    "\n",
    "# parse helpful column into new columns of helpful_votes, total_votes, helpful_perc\n",
    "df['helpful_votes'] = df['helpful'].apply(get_helpful_votes)\n",
    "df['total_votes'] = df['helpful'].apply(get_total_votes)\n",
    "df['helpful_perc'] = df['helpful'].apply(calculate_helpful_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194439, 12)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93558</th>\n",
       "      <td>A1ZSX42Q9RAEVF</td>\n",
       "      <td>B00891F4ZS</td>\n",
       "      <td>Stephanie Seymore</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I received product in a timely manner and in g...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great product for a great price</td>\n",
       "      <td>1355184000</td>\n",
       "      <td>12 11, 2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188981</th>\n",
       "      <td>A58F10T4OE58C</td>\n",
       "      <td>B00HWX16GU</td>\n",
       "      <td>S. Montgomery \"green dad\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Or house was ina virtual ATT dead zone. We cou...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Solved our cell dead zone issues</td>\n",
       "      <td>1403654400</td>\n",
       "      <td>06 25, 2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10508</th>\n",
       "      <td>A1M9OT024TYW99</td>\n",
       "      <td>B002D4IHYM</td>\n",
       "      <td>Colorado Guy</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>This battery charger is a excellent solution a...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great solution for back up power</td>\n",
       "      <td>1348444800</td>\n",
       "      <td>09 24, 2012</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13846</th>\n",
       "      <td>A2PS16JA81FYY</td>\n",
       "      <td>B0030HW0R6</td>\n",
       "      <td>Diana Vasquez</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>awesome deal for so many colors... just as wha...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1404950400</td>\n",
       "      <td>07 10, 2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62227</th>\n",
       "      <td>ANPWK0UIQ5B21</td>\n",
       "      <td>B005VNJH7I</td>\n",
       "      <td>Nickolaus Benson</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>My wife ordered this hoping it would be good f...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Too big for a girl</td>\n",
       "      <td>1387238400</td>\n",
       "      <td>12 17, 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin               reviewerName helpful  \\\n",
       "93558   A1ZSX42Q9RAEVF  B00891F4ZS          Stephanie Seymore  [0, 0]   \n",
       "188981   A58F10T4OE58C  B00HWX16GU  S. Montgomery \"green dad\"  [0, 0]   \n",
       "10508   A1M9OT024TYW99  B002D4IHYM               Colorado Guy  [0, 2]   \n",
       "13846    A2PS16JA81FYY  B0030HW0R6              Diana Vasquez  [0, 0]   \n",
       "62227    ANPWK0UIQ5B21  B005VNJH7I           Nickolaus Benson  [0, 0]   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "93558   I received product in a timely manner and in g...      5.0   \n",
       "188981  Or house was ina virtual ATT dead zone. We cou...      4.0   \n",
       "10508   This battery charger is a excellent solution a...      4.0   \n",
       "13846   awesome deal for so many colors... just as wha...      5.0   \n",
       "62227   My wife ordered this hoping it would be good f...      3.0   \n",
       "\n",
       "                                 summary  unixReviewTime   reviewTime  \\\n",
       "93558    Great product for a great price      1355184000  12 11, 2012   \n",
       "188981  Solved our cell dead zone issues      1403654400  06 25, 2014   \n",
       "10508   Great solution for back up power      1348444800  09 24, 2012   \n",
       "13846                         Five Stars      1404950400  07 10, 2014   \n",
       "62227                 Too big for a girl      1387238400  12 17, 2013   \n",
       "\n",
       "        helpful_votes  total_votes  helpful_perc  \n",
       "93558               0            0           0.0  \n",
       "188981              0            0           0.0  \n",
       "10508               0            2           0.0  \n",
       "13846               0            0           0.0  \n",
       "62227               0            0           0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at a sample of rows\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa4719b6810>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAFECAYAAAAQt0QWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAH/9JREFUeJzt3Xm4ZFV97vHv2yAiIAjXRmIMLXBRNCiCoEwOgIhelUcjgwajIigKN6IoGrxExTHhBgcQUUTBm4AiGoOzoEKDKILNjENQEKcoYuCCiALhlz/Wqu7q06cP2OzfqtXV7+d5+uk+Vd312+f0rnfvWqMiAjMzm7x5kz4AMzMrHMhmZp1wIJuZdcKBbGbWCQeymVknHMhmZp1wIJuZdcKBbGbWCQeymVknVv9T/vLu8/ZuNq3v7LvPYPd5e7cq53qu161p/1muCvUA3Zu/6ztkM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz64QD2cysEw5kM7NOOJDNzDrhQDYz68Tqkz6Annz1l5dP+hDMbBXmQB6zx0O3albr7LublTKzlYSbLMzMOuFANjPrhAPZzKwTbkMe4049M5skB/IYd+qZ2SS5ycLMrBMOZDOzTjiQzcw64UA2M+uEA9nMrBMOZDOzTnjY2xiPQzazSXIgj/E4ZDObJDdZmJl1woFsZtYJB7KZWSccyGZmnXCn3hiPsjCzSXIgj/EoCzObJDdZmJl1woFsZtYJB7KZWSccyGZmnXAgm5l1woFsZtYJB7KZWSccyGZmnXAgm5l1woFsZtYJB7KZWSccyGZmnXAgm5l1woFsZtYJB7KZWSccyGZmnXAgm5l1woFsZtYJB7KZWSccyGZmnXAgm5l1woFsZtYJB7KZWSccyGZmnXAgm5l1woFsZtYJB7KZWSccyGZmnXAgm5l1woFsZtYJB7KZWSccyGZmnXAgm5l1woFsZtaJ1Sd9AD356i8vn/QhmNkqzIE8Zo+HbtWs1tl3NytlZisJN1mYmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmXXCgWxm1gkHsplZJxzIZmadcCCbmfUiItJ/Aa9oUWcS9ab5e3M913O9tvVa3SG/olGdSdSb5u/N9VzP9RrWc5OFmVknHMhmZp1oFcgnNqoziXrT/L25nuu5XsN6qg3VZmY2YW6yMDPrhAPZzKwTDmQzs06kBLKk1SU9R9Lh9dezJa2eUWtSJC2Q9LT65wdIeuCkj2koks66N48NUGeDuX4NXW+s7j9J+sus15+lniS9SNKb69cbS3pCcs2JnJ+S5klaN/H115Y0r/75EZL2lHS/rHqtDd6pJ+mhwDnAfwCXAgK2BjYCdomIXw5asNR8BHA4sABYHPwRsevQtWq9l1MGiG8QEZtJ2hz4UETsNnCd44Dl/gdFxKsHrrcGsCZwPrAz5f8OYF3gaxGxxcD1rqN8f5rl6YiITYesN1b3QGB/yrlyMvCJiPj/GbVqvROAu4FdI+JRktYHzoqI7ZLqNTk/x+qdBrwS+C9gEbAe8J6I+L8JtRYBTwLWBy4Evgv8PiL2G7rWWM2PA4dGxM316/WBYyLiZUPXyrhrfRdwQkS8b/xBSa8G3g28JKHmGcCHgI9QTopshwBPAL4DEBHXSNowoc53E15zLocAhwEbAlezJChvofx8BxURmwz9mvey7knASZIeSQnmKyRdAHwkIs5JKPnEiNhG0qW1/k314pel1fk58uiIuEXSfsCXgDdSgnnwQKbcRP5e0gHAcRFx9OjnmuixozCGxf9/W2cUygjk7SPipTMfjIhjJf0woR7AXRFxQtJrz+aPEXGHVPKqNscMPn4wIj4+9GveQ733Au+V9JqZF9QMkra5h+O5JLH2asAW9deNwOXAYZIOiogXDFzuzlovau35lDvmLE3OzzH3q80GzwU+EBF3SsqqJ0k7APsBB9THsptD50laPyJuqgewQVbNjBe9fY7nfp9QD+Dzkg4GPgv8cfRgRPxnUr2Fkt4EPEDS7sDBwOeTaiHpHGZ5Q2U1yQDrSZoXEXfX+usA742Ilw9c55g5ngsgq8npPcBzgG8A74qIi+pT/5h003As5dzcUNI7gb2AIxPqjDQ9P4EPAz+hXNTOk7SA8qkqw2uAI4DPRsTVkjalNJFmOgb4lqRPU87LfYB3ZhTKaEO+Fnj9bE8BR0fEZoMWZHFb5EyZbZDzKFfnp1O+r68CJ0XSLBtJjx/7ck3g+ZRPBW9Iqnc0sAvwUuAhwAcpbZDpd83ZVG4bj6S0AS5zgyBpvYz2ZElbALtRzpevR8T3h64xVqvp+bmcY1g9Iu5KfP21I+K2rNefpd6jKTcIo/+/76XUSQjkk+d6PiL2H7TgKkrSwoh4SuLr7w6cCdwMPDUi/j2rVq23JfBoygUHgIj4f0m1FkXE4+/5bw5ac33gL1i60zmtSaYlSQ+h9B09NCKeWcNrh4j4aEKtHYCPAutExMaStgIOioiDh65V680DroiILTNef5l6K/PUaUm7RsQ3JP3VbM9HxL8m1X028HaWjOpQKRcpw31mDAGbBzweODYiHplUb0fKnP3TgS2BtYEDI+JXSfXeAjyVEshfAp4JfDMi9kqqdzxwSkRcnPH6s9R7O+XTxo9Z0vQUiaOAWp+fX6aMVvk/EbFVbbO+NCIek1DrO5Qmn89FxNb1sasyA1PSqcAREfHTrBojg7chSzpsrucj4j0DlnsKpR3wObOVAlICGXgf8FfAlY0+Bi5iyfCwu4DrWNKhkeFY4IURcSWApH2BhUDKBYDyBtuK8ibev95xnZRUC0pzzEGSrgduY0lgPTap3j7AZhFxR9Lrz9T6/HxwRHxK0hEAEXGXpLTRThHxs1GHZZU9surPgKslXUQ5X0bHsefQhTI69ZpNkIiIt9TfWzeD/Ay4Kvtkl7R3RJwB7BYR12bWmmH78fa/iDhd0jcS690eEXdLuqtOKrgBSGn/r56Z+NqzuQp4EOX7aqHJ+TnmNkn/gyWjSLYHssZ1/6x+gos6dPDVQFp7fHVU8usvltJkUYf4vLoOo0on6VDKR6ZbKWORtwH+LiIGn11W621H+Ui4kKVHdQx594+kS+r41UsiYs4hYgPXnQ+8A3hYRDyrtgk+ISJOSar3QeBNwAuA1wG/Ay7LvtDWsbnjbdYpH0klbUtpj7+Kpc+Xwe+war0m5+dYvW2A4yjNW1cB84G9I+LyhFoPBt4PPI3yyeYsStZkjaga1V0AbB4RX5O0FrBaRNw6eJ2si6ikcyJil5QXX7bW5bXtag/KoPi/B07OCjGVacS/A65kbDxpRAx6JZV0NuVTzOMos+eWkviG/iJwKvDG+nO9H3BJUpugKMH/s/r1w4F1I+KKoWuN1dyTMpTpoZS71gXA9yMiZTq1pKspQ8Nmni8Lk+o1OT/H6t2f0mzwSEpI/hCYFxF/nPMfrlitnSLignt6bOCazWY+Zg6o/pakD1A6hsbbXTJ6lkcNSv+LEsSXa0Yj08A2iIinJ77+yLMod/v/zNxjdoe2YUScJulwgDrQP6WdLiJC0r9ROiqJiJ9k1Jnh7cD2lOngW0vaBXhhYr0bI+LYxNefqdX5OfLtevNz9egBSZdQzt2hHTfL68722JCazXzMDOQd6+9vG3ssa7D/onpXsAlwhMpCKpkzob4m6elZTSIjtRPoQkk7RsRvavtqZHxUmuG2OrJj1Ca4HaU5KMuFkrZrNeoBuDMifquyEM68iDhH0j8m1lsk6d3A51i6CSFr2FuT81PSRsCfUyagbM3Sa5+sNXCtHSiZMn/GwIF1gdWGrDWLZjMf0wK5VXNFdQDlY/39gG2BBwOnJNY7BHiDpD8Cd5I8rAhYUDvVHkj5lH8z8LKIWJRU7/WUmV2bSlpIedOlDEGrdgFeKekntBn1cLPK7MPzgFMl3UAZvZJltO7B9mOPpc1EpN35uQdlON/DgPH26VspfQJDWgNYh5JZ4wMHbiH33ISGMx8z25BbDhY/EDiUcmJcRjnxv501zrM1SVcAh0TE+fXrnYEPDh1YkraPiAvrn9cAHkV5M38vc8hW7TBZRkRcn1RvbeAPlO9tP8rqZKdGxG8z6k07Sc+PiM80qrUgIq6vn4IjIn7XoGazmY+ZgdxysPiVwHbAhRHxOJVpqkdFxL5D1xqruT6wOUv30p+XVOuCiNjpnh4boE7T0Rwzau9M6cU+uY7yWCciZpsSP2TNdVl65tygPfWSXhQR/7K8sfkJo3K2iIgfaDmLNmU1kUh6EPBm4Mn1oYXA2yJnCvqWlD6V0WSpG4GXRMRVQ9eaUXcNykJUAfww6wYlsw255WDxP0TEHyQh6f71pMyaxLDcO3LyPoJeJOnDwCcoJ8S+wLmjN15iW2QTKjP1tqX00p9MaXr6F2DQC85YvYMofRu3U/oaRPm5Dj32edSO2mps/mGU0QCzdQBnNpF8lDLcbZ/69d9Q/h9nnUF7H50IHBZ1mVRJT62P7TjXP7ovJD2LsvzsjynnyiYqqwJ+eehamYHccrD4z+tV+t+AsyXdBAy+EP6YQ1lyR77L6I48sd7j6u9vmfH4jgz7RttU0ueW92TWMDvgeZR21ktqnV8qd4eL1wN/GRE3JtaA0u6ZNtxsFh+r9Vr230CZhfj8sa+PknRZUq21Y2zN6og4tzZBZTqGsrnGjwAkbQZ8EVipAvl1lF7lzVQW/55PUuN7RDyv/vGtKktVrgd8JaNW1fSOvOEb7De0HV43ckcd/ja6eGe/wX5M3lKw414GfKBBnZEPkjv8a3lul7RzRHwTyrhg5l6G9764VtLfU5otAF5EWUog0w2jMB4dA0mzLjNHWSyS9BTGBotHxJ1Z9cbqpgy2n6HJHfny2h5HEmZe3dro5zfTp2qTzIPqIPyXUWZcZjmCMk7+Oyw9DG3QLbFWIa8CPi5pvfr1TeTsDATl3DiKsk6NKO3V2UsnXC3pS8CnKJ9I9wYuVl3ULAZcxCyzU+98yrCi84ELGoydnYh60VkP+MrQDf21bXW5EmYG/mtEZLT73ZvauzPWix0RZyfWugj4JsvOZBt0hxZJdzH7nXjKMLQ6HHK5HcuJMztXi4j/qp2kRETW4vRI2joisrdsmllzriWFIwbcWy8zkDelbJT5JEqn1x+B8yPitSkFbTCtL6aSXgucERE/z6wzVu9bEZHWCTRW59KoS0S2IOka4MDlPZ/16UfSTylNhKcD38gYDjZW6xzK6mtnAJ+MiKvv4Z+kk3RERLx7kNdK/Nkh6c8oS2Q+iTL4/6cR8Yy0gskk3cqyuyQHpelnjYhIaQJS2VX7BOAhEbGlpMcCe0bEO5LqNb2Y1k8C+wD/CXwS+HRE/DqjVq33TuB6yuD+tC2/JhDIExm2KOkBlCVwX0Bpw/4CJSy/mVRvI8r5si9lpt7pWe+Fe3k8g/3cM++Qf0wZI3ga5U7rsqh7tE2LOhLgYOAgyh5fr0uqsxA4HPhwtFuUu/nFtF5o9qVsUfXziHhaUp0mW35JelNEvEvSmhHxhyFfezn1JtbkNHYM61NWY9svIlKnNEt6DPAGYN+IyNzF+56OY7ALb+Yoi2Mpd1kvpAxpWijpvIj4cWLNJmqH3muAF1MuONslz/JaKyIu0tLrJWXuVzZ+Mf0o8LeNLqY3AL8CfgukbVsfEZtkvfaMOu+qf7xK0q8pNybnUZqBBh8COgrjSfTf1L6UfSlrTV/MkjHJQ9d5VK2zF+U8+SRlRNckDXZXm76Fk8qaAftTxn4+LPuqmUllLdbXUU6IjwHHZbyxZqn7ZeB/U9pZt5G0F3BARKQstK6yvvTOlD3gfkDpyU67mEp6FeVnOh/4NOUjaMomkrXeapSV9B7O0jP1UtYLrjU3pnza2ImyKuHNEfG4uf/VCtdq3eR0HWWC1KcoWyulbT4q6ULKBKkzIiJzrsG9tlLcIUs6hnJSrEOZxfZmZlnTdyVzPWWs7smU3vMDxu9aE9/Qh1BmI20h6ReUcZf7JdUiIt4PvH/sYvpWyqzErIvpAspkmydT7jbul1Rn5POUtSyWGmWRRdLDKEH8JMpWVVdTRnmkiIhrJd0O3FF/7UJZlyTLVnONrBiy0ysitp/reUmfmTFJpYUzhnqhzDbkvSl3VWmdM61JeislMGZ27AHpC4DvRbmj24CywlVExNvm+nf3od7Mi+n5lDuslG2k6h35gSwZW/o84MSIOC6p3hWRt5LcbPXupnyMf1dEnNmgXlf9Ny07G4e8W5V0HHM0R2SMW88M5HnAXwObRMTb60e2jSLiopSCjajx9lS15leAmylTixevBxIRKbPqWl9MVVaz22H0UbfO1Pt2VmiqrH389UheL3is3laUC9yTgY2Ba4CFkbDyYa3XtMnpXhxPs9Emg454kOac3DL0uHXIDeQTKB8Hd42IR9Xe17MiYruUgg2p4fZUtV7qiIpZ6jW9mKqu1jcaiSBpTeDiSFgZsL7+8yiLF82jzXrWo76UUbvui2q9h2fVG6s58f6bxnfIE1uxcAiZoyyeWDugLgWIiJtUlrCbBi23pxrVe0xEXJn0+jMdT72YUrY7uhX4DGVBpQwnA9+R9Nn69XMpozuyHAPsAFyZOYlhRNJ3gfsD36K0HT85ktZ6rvV667/J3E4tvVadjLLMeRIJ661nBvKd9eP9aMGY+TToQGmkyfZU9c5xNPFkf0nXUnrMs3fUaHoxjYj3SDqXEiIC9k+eHnsNcFWLMK6eGRG/aVQL4ELg6I76bwbr9LoX3pjwmq8f+/OalHHyKcNOM5ss9qMMZdoG+DilU+rIiGj5n7NS03J20hjJustSWXRnR0qzwTb1YnpWy1lnmSSdQln7+MssPVMvZZSMGu6eU+s1aXJq2ek1dnOyzFPk3pws73gWRsRThn7dzNXeTpW0CNiN8kN7bkR8P6teS63eYJkfa+/BscBngQ3rNOO9gCMndCwZrqu/1qi/sp1C3T2nfv3vlOaurGaZVk1O3x349eby7Ia1lqKy4e/IPMoO6Rul1Br6DlnSuhFxy4xvYrEYeL2ASVDD7akmRWXR/dHF9OvTcjGdBEkXR8R246MNJF2WODHkklGT01i9yyNiq4x6065OfBkNdb2LcjF/WySs1ZFxh3wa5Wq2iKU/YmRtkzMJLbenambGxfQGyoyo0XMbTMPFFNp20lQtd8+Bxv03LX+e9Wd3HGWiyxqUyUq3ZYyQkbR3bWLdLWsM/kyDB3JEPLv+3mS9gAlp/QZrZVW4mELDTprqMBrtnlO1bnJq+fP8AGVVuTMo+zC+GPifSbWOqHU+TaOdWDI79c6kLPxxZkS02C6nGUmPp5z0W1I2d5wP7BURV0z0wGyFZXXSjL3+6jTcPWfSTU5ZP09J342IbcdnWyppfWtJZ1NuWh/HLMMGI2HB/8xhb++hjLL4B5UdGk4HvhANliHMFhPanqqVab6YwqydNNuS0EkjadeI+IbqVj9jHiFp0K1/ar2JNDm17PQCfl+HYF4m6WjgP4CsPRifRbkz/mca7TXZYrW31Si9vS8HnpE5G6oVTfn2VFqylOKzgKm6mMIynTR3Aj8hoZNG0lER8RbNvgVQxIBb/9R6X4iIZ499f4ufImG957G6zTq96lDQX1Paj19L2T7t+Mxp4ZLmR8RvVLaoisz3e/aOIaOdBEbjkb8QEX+bVrARrSLbU03jxRRA0j6UPRBvUdnBeBvg7VkzLVX3nMt47UkadXpJ2rRVp5ekQ6OsRjjnYwPX3JYyquqBlIvOzcDLImLR0LXmDf2CI5JOB75PeUMfD2w2DWEMZXlD4Gzg65Q75bXIXd6wuXoxfT7wSsr41cEXUpmgI2sY7wzsThknfEJivesknShpN0np04glnSnphZLWSi51RP3908l1xs224M9Lk2t+DDg4Ih4eEQsoy+HOtfHpCsvs1HsGcPaU3hl0tbzh0OrF9ImUjSs/BZw7Zd/fpRGxtaR3U9azOE2JK5Kp/Z5zTZqcWnZ6SXohZfbhzjNqrQvcFUnbfdXaF0TETvf02CC1EgN5Lcpwn40j4hWSNgceGRFfSCnYkDpb3nBo03wxhdLWCvwCeBqlA+p24KIWEyfUds+51Can2rk26vRaZrfrGHCX69p2vAnwbuDvxp66FbgiIjK3NHsv5VPwJyht5fsCN1FmPw66qFhmIJ9OGc/64ig7JT+AssZtyuykSVAnyxsObZovprD4+3sG5e74GpUNXR8Tiesja9k9506PiM8k1mvWf9Oy06vWewhLpoFfFBE3JNc7Z46nY8gJMJmBPBovOHXTN9V4R43WVoWLaUtquOdcrde0yallp5fK5gn/BJxbaz0JODwiWrZjp8kch3xHfSOPZrNtxtjKWiu53pY3HNpmEbFvbbcjIm5v0Rk1xebccy7BycBfN2xyGnV6nQ9QO0tPBjJWYDuSspnBDbXWfOBrJHQsSjpsrucjYXXAlFEW9c37IcoV+i8knUoZkfCGjHoT8Blg9zpkCkkbS3rChI9pSNN8MZ2EjSR9XdJVAJIeKylzKvN5wBGSTqz1NpeUuVraraMwBqidlVnNFvNmNFH8lrzRYg+8h1+Dy2yyWAQ8nTJOV8CFEXFjSrHGNN3bUwn4G+AA4NHAWZQdk18aEedO8NBWWpIWAocDHx5rvkvblqt1k1PTTq8yO28rlsxC3JfSqZexMH1zmU0WFwKbRsQXE2tMytRuTxURUUeRjF9MD52Wi+mErBURF81o9clczKh1k9Mo6N8y4/EdGX4nnQA+zJLdZU6knKdpJD2CMk79IfUC91hgz4h4x9C1MgN5F+AgSddT9p2byMr+SaZ5eyqY7ovpJNxYm31G58telDUYsjRtcoqGG/4Cu9e74cXrgEg6ipytm0Y+Qv2EAxARV0g6DVipAvmZia89adO+o8Y0X0wn4RDKndwWkn5BWevhRRmFltN/sxMJs9ladnpJehVwMLCppPFVFR8IXDBUneVo9gkncwunSW0/lC6meHuqapovps3V4ZBPk7Q2pVMqbZxu4yanlI6t5TiNsgfiMhNDIn/jhGafcNJXe5smWgW2p7Jh1aat9UeBWPsaXgIcFhEp659IOh44JSIuznj9VY3KYmInUtrEb6J8wtkv46bTgfwn0ISWN7SVk6QXUNodbwOuAd5KmWZ8Mbmry30PeATQpMmpZafXJEi6P6VZ8uHABsAtlJ/n2wav5UA2y1HHHT83In4kaRvKrM4XRMRnk+sumO3xrGbE1sP6WpP0Fcrsw0uAxZNtImLwReszO/WmlqZ8Rw0bzB0R8SMoY3ElXZcdxrVW6/6b1sP6WntYRDyjRSEH8oqZ2u2pbFAbzhiJsM741xlTbyek9bC+1r4l6TERcWV2ITdZ3AfZyxvayk3SzIkSS4mIo1odS6aWnV4tSbqScpFZHdgcuJYynjutTd6BvIJaLm9o00fSGhFxx6SPYwgtO71aWl5b/EjGBcdNFitgxvKGxzNlO2rYsCSdS1kL5Cf16+2AkyhrMkyDM1nS6fXLCR/LYCZxh+875BWgKd9Rw4YlaQ/KLiHHAn9OmXhzYNawt9amaUTFpDmQV4CmfEcNG56kp1I2xr0R2DoifjXZIxpOXebzuBadXtPOTRYr5mTK8oY71q9/DpxB2bzSbCl13ex9gCdTFm0/V9LrVvbFm2Z0eu0vKb3Ta9o5kFeMd9SwP8WDgSdExO3At+tEg5OAlTqQgcxF71dJDuQV4x017F6LiENnfH09sPuEDmcwK/uwth45kP9ELZc3tJWbpPdFxGskfZ6l1z4BICL2nMBhWcfcqbcCpnl7KhuOpMdHxCJJT5nt+YhY2PqYrG8O5BXg5Q3NLIMDeQW0Xt7QVm6SdqIsvbmA0kzo5VptVg7kFdB6eUNbuUn6AfBaylDJ8eUbfzuxg7IuOZDNkkn6TkQ8cdLHYf1zIJslk/QPwGqUnZIXD4+clqnTNhwHslkySefUP47ebKM25F0ndEjWKY9DNst37iyP+U7IluFANsv3u7E/r0mZcvz9CR2LdcxNFmaN1QXdPxcRe0z6WKwv8yZ9AGaroLUAj0G2ZbjJwizZ2DKVUEZbzAdW6u2NLIebLMySzZhIdBfw64i4a1LHY/1yIJuZdcJtyGZmnXAgm5l1woFsZtYJB7KZWSccyGZmnfhvpuGd/r10SuwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see if there are any missing values by feature\n",
    "# missing values show up in yellow\n",
    "sns.heatmap(df.isnull(),cbar=False,yticklabels=False,cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerName</th>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewText</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unixReviewTime</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewTime</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful_votes</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_votes</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful_perc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "reviewerID         0\n",
       "asin               0\n",
       "reviewerName    3519\n",
       "helpful            0\n",
       "reviewText         0\n",
       "overall            0\n",
       "summary            0\n",
       "unixReviewTime     0\n",
       "reviewTime         0\n",
       "helpful_votes      0\n",
       "total_votes        0\n",
       "helpful_perc       0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate how many values are missing by feature\n",
    "missing_df = pd.DataFrame(df.isnull().sum())\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>194439.000000</td>\n",
       "      <td>1.944390e+05</td>\n",
       "      <td>194439.000000</td>\n",
       "      <td>194439.000000</td>\n",
       "      <td>194439.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.129912</td>\n",
       "      <td>1.368714e+09</td>\n",
       "      <td>1.437741</td>\n",
       "      <td>1.737043</td>\n",
       "      <td>0.193055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.222499</td>\n",
       "      <td>3.230032e+07</td>\n",
       "      <td>15.857623</td>\n",
       "      <td>16.800879</td>\n",
       "      <td>0.372417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.828000e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.357603e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.374538e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.390262e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.406074e+09</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>2031.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             overall  unixReviewTime  helpful_votes    total_votes  \\\n",
       "count  194439.000000    1.944390e+05  194439.000000  194439.000000   \n",
       "mean        4.129912    1.368714e+09       1.437741       1.737043   \n",
       "std         1.222499    3.230032e+07      15.857623      16.800879   \n",
       "min         1.000000    9.828000e+08       0.000000       0.000000   \n",
       "25%         4.000000    1.357603e+09       0.000000       0.000000   \n",
       "50%         5.000000    1.374538e+09       0.000000       0.000000   \n",
       "75%         5.000000    1.390262e+09       0.000000       1.000000   \n",
       "max         5.000000    1.406074e+09    1984.000000    2031.000000   \n",
       "\n",
       "        helpful_perc  \n",
       "count  194439.000000  \n",
       "mean        0.193055  \n",
       "std         0.372417  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at summary statistics of dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Histogram of Helpful Percentages')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at distribution of helpful_perc\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "n, bins, patches = ax1.hist(x=df['helpful_perc'], bins='auto')\n",
    "                                 \n",
    "ax1.set_xlabel('Helpful Perc')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Histogram of Helpful Percentages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23534, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset df of reviews that have at least three votes\n",
    "df_three = df[df.total_votes >= 3]\n",
    "\n",
    "# subset df of reviews that have two both and both are in agreeement\n",
    "df_two = df[((df.total_votes == 2) & (df.helpful_perc == 1)) | ((df.total_votes == 2) & (df.helpful_perc == 0))]\n",
    "\n",
    "# combine the dfs back together\n",
    "df = df_three.append(df_two, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23534.000000</td>\n",
       "      <td>2.353400e+04</td>\n",
       "      <td>23534.000000</td>\n",
       "      <td>23534.000000</td>\n",
       "      <td>23534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.862114</td>\n",
       "      <td>1.349077e+09</td>\n",
       "      <td>10.958358</td>\n",
       "      <td>12.898870</td>\n",
       "      <td>0.772259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.424595</td>\n",
       "      <td>4.950273e+07</td>\n",
       "      <td>44.426959</td>\n",
       "      <td>46.785794</td>\n",
       "      <td>0.288889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.828000e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.330733e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.361405e+09</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.383178e+09</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.405987e+09</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>2031.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            overall  unixReviewTime  helpful_votes   total_votes  helpful_perc\n",
       "count  23534.000000    2.353400e+04   23534.000000  23534.000000  23534.000000\n",
       "mean       3.862114    1.349077e+09      10.958358     12.898870      0.772259\n",
       "std        1.424595    4.950273e+07      44.426959     46.785794      0.288889\n",
       "min        1.000000    9.828000e+08       0.000000      2.000000      0.000000\n",
       "25%        3.000000    1.330733e+09       2.000000      3.000000      0.666667\n",
       "50%        5.000000    1.361405e+09       3.000000      4.000000      0.875000\n",
       "75%        5.000000    1.383178e+09       7.000000      8.000000      1.000000\n",
       "max        5.000000    1.405987e+09    1984.000000   2031.000000      1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Histogram of Helpful Percentages')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(1, 1, 1)\n",
    "n, bins, patches = ax2.hist(x=df['helpful_perc'], bins='auto')\n",
    "                                 \n",
    "ax2.set_xlabel('Helpful Perc')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Histogram of Helpful Percentages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Helpful Reviews Are Determined Randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0016068365532971554"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to repeat results\n",
    "random.seed(12345)\n",
    "\n",
    "# calculate total number of reviews\n",
    "total_reviews = len(df)\n",
    "\n",
    "helpful_perc = df['helpful_perc']\n",
    "\n",
    "random_helpful = []\n",
    "for i in range(total_reviews):\n",
    "    random_helpful.append(random.random())\n",
    "    \n",
    "\n",
    "np.corrcoef(helpful_perc, random_helpful)[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Encoded Words and Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure there are no missing values in the review or summary text or the overall helpullness percentage\n",
    "len(df) == len(df.dropna(subset=['reviewText', 'summary', 'helpful_perc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words and tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize(text):\n",
    "    return [word for word in word_tokenize(text) if not word in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the reviewText and summary text fields to combine into a single \"document\" with which to analyze\n",
    "df['combinedText'] = df['summary'].str.lower() + \". \" +  df['reviewText'].str.lower()\n",
    "\n",
    "# Now tokenize these and remove stop words\n",
    "df['processedText'] = df['combinedText'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "data = df[['combinedText', 'helpful_perc']]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "preprocessed_data = data.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(preprocessed_data['combinedText'], \n",
    "                                                    preprocessed_data['helpful_perc'],\n",
    "                                                    random_state = 12345, # reproduce results\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# train the model using the training sets\n",
    "regr.fit(np.array(Train_X.values.tolist()).reshape(-1, 1), Train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test Labels and Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027932312806567966"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict values\n",
    "pred = regr.predict(np.array(Test_X.values.tolist()).reshape(-1, 1))\n",
    "\n",
    "# score with correlation coefficient\n",
    "np.corrcoef(Test_Y,pred)[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: TF-IDF and Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train//test sets\n",
    "data = df[['combinedText', 'helpful_perc']]\n",
    "\n",
    "df_train, df_test = train_test_split(data, test_size = 0.2, random_state = 12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem combinedText to reduce size of corpus\n",
    "porter=PorterStemmer()\n",
    "\n",
    "def stem_text(df):\n",
    "    text_list = df['combinedText'].tolist()\n",
    "    text_list_stem = [None] * len(text_list)\n",
    "\n",
    "    for i in range(len(text_list)):\n",
    "        text_list_stem[i] = ' '.join([porter.stem(w) for w in text_list[i].split()])\n",
    "    \n",
    "    return text_list_stem\n",
    "\n",
    "text_list_stem = stem_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.17713675, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.19837654, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.06237604, 0.03611045, ..., 0.        , 0.15155843,\n",
       "        0.16257494],\n",
       "       [0.        , 0.10427993, 0.        , ..., 0.        , 0.0844582 ,\n",
       "        0.10871678],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize text\n",
    "vectorizer = TfidfVectorizer(\n",
    "                max_features=100,\n",
    "                ngram_range=(1,1)\n",
    "                )\n",
    "\n",
    "vectorizer.fit_transform(text_list_stem).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (18827, 100)\n"
     ]
    }
   ],
   "source": [
    "# vectorize train dataset\n",
    "train_text_stem = stem_text(df_train)\n",
    "train_vectorized = vectorizer.transform(train_text_stem).toarray()\n",
    "\n",
    "print('Shape:', train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4707, 100)\n"
     ]
    }
   ],
   "source": [
    "# vectorize test dataset\n",
    "test_text_stem = stem_text(df_test)\n",
    "test_vectorized = vectorizer.transform(test_text_stem).toarray()\n",
    "\n",
    "print('Shape:', test_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array of labels to use in linear regression\n",
    "df_train_labels = np.array(df_train['helpful_perc'])\n",
    "df_test_labels = np.array(df_test['helpful_perc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\n",
    "regr_2 = linear_model.LinearRegression()\n",
    "\n",
    "# train the model using the training sets\n",
    "regr_2.fit(np.array(train_vectorized.tolist()), df_train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test Labels and Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25494885117229604"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict values\n",
    "pred_2 = regr_2.predict(np.array(test_vectorized.tolist()))\n",
    "\n",
    "# score with correlation coefficient\n",
    "np.corrcoef(df_test_labels, pred_2)[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "# if this doesnt work, ensure tensorflow is version <2.0\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Tensorflow hub path to BERT module of choice\n",
    "BERT_DIR =  \"./bert\"\n",
    "BERT_PATH = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "sys.path.insert(0,BERT_DIR)\n",
    "\n",
    "# Initialize session, may need to remove config if no GPU\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "  When running eval/predict on the TPU, we need to pad the number of examples\n",
    "  to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "  size. The alternative is to drop the last batch, which is bad because it means\n",
    "  the entire output data won't be generated.\n",
    "  We use this class instead of `None` because treating `None` as padding\n",
    "  battches could cause silent errors.\n",
    "  \"\"\"\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.text_a)\n",
    "\n",
    "def create_tokenizer_from_hub_module(path):\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module =  hub.Module(path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    tokens_b = tokenizer.tokenize(example.text_b)\n",
    "    \n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    elif (len(tokens_a)+len(tokens_b)) > max_seq_length - 3:\n",
    "        tokens_b = tokens_b[0 : (max_seq_length - 3 - len(tokens_a))]\n",
    "        \n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    \n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    if len(tokens) < max_seq_length:\n",
    "        for token in tokens_b:\n",
    "            tokens.append(token)\n",
    "            segment_ids.append(1)\n",
    "        tokens.append(\"[SEP]\")\n",
    "        segment_ids.append(1)\n",
    "    \n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "def convert_text_to_examples(titles, texts, labels, max_examples=None):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for title, text, label in zip(titles, texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=title, text_b=text, label=label)\n",
    "        )\n",
    "    return InputExamples[:max_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module(BERT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n"
     ]
    }
   ],
   "source": [
    "# process df - only reviews that have 0 or 100% ratings and at least 10 reviews\n",
    "df = ones_and_zeroes_df(df)\n",
    "df = df.drop(df[df.total_votes < 10].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2)\n",
    "df_train, df_val = train_test_split(df_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922006aa10db40dd8fe771eea91aad57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=258), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee456797c3241b583610ab7005a51b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=65), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0119d2e8da8b472cb781f3696f4a819b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=81), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert data to InputExample format, ensure we don't have too many examples to encounter memory issues\n",
    "train_examples = convert_text_to_examples(df_train['summary'], df_train['reviewText'], df_train['helpful_perc'], max_examples=10000)\n",
    "val_examples = convert_text_to_examples(df_val['summary'], df_val['reviewText'], df_val['helpful_perc'], max_examples=2000)\n",
    "test_examples = convert_text_to_examples(df_test['summary'], df_test['reviewText'], df_test['helpful_perc'], max_examples=2000)\n",
    "\n",
    "#make sure the test Y is the same format\n",
    "test_actual = np.array(df_test['helpful_perc'][:2000])\n",
    "test_actual = test_actual.reshape(-1,1)\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
    ") = convert_examples_to_features(tokenizer, train_examples, max_seq_length=MAX_SEQ_LENGTH)\n",
    "(val_input_ids, val_input_masks, val_segment_ids, val_labels \n",
    ") = convert_examples_to_features(tokenizer, val_examples, max_seq_length=MAX_SEQ_LENGTH)\n",
    "(test_input_ids, test_input_masks, test_segment_ids, test_labels\n",
    ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create neural net\n",
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"first\",\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_path = bert_path\n",
    "        if self.pooling not in [\"first\", \"mean\"]:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "\n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'n_fine_tune_layers': self.n_fine_tune_layers,\n",
    "                  'pooling': self.pooling,\n",
    "                  'bert_path': self.bert_path}\n",
    "        base_config = super(MyMeanPooling, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Build model\n",
    "def build_model(max_seq_length, model_loss, reg=False): \n",
    "\n",
    "    in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "\n",
    "    bert_output = BertLayer(n_fine_tune_layers=3, pooling=\"first\")(bert_inputs)\n",
    "    if reg:\n",
    "        dense = tf.keras.layers.Dense(max_seq_length, activation='relu', kernel_regularizer=regularizers.l2(0.01))(bert_output)\n",
    "    else:\n",
    "        dense = tf.keras.layers.Dense(max_seq_length, activation='relu')(bert_output)\n",
    "    pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss=model_loss, optimizer='adam')\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_2 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          98432       bert_layer_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            129         dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 110,203,451\n",
      "Trainable params: 21,952,769\n",
      "Non-trainable params: 88,250,682\n",
      "__________________________________________________________________________________________________\n",
      "Train on 258 samples, validate on 65 samples\n",
      "Epoch 1/3\n",
      "258/258 [==============================] - 255s 989ms/sample - loss: 1.2693 - val_loss: 0.6123\n",
      "Epoch 2/3\n",
      "258/258 [==============================] - 238s 922ms/sample - loss: 0.3723 - val_loss: 0.2771\n",
      "Epoch 3/3\n",
      "258/258 [==============================] - 238s 923ms/sample - loss: 0.1891 - val_loss: 0.1614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa430d8ad10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "#BCE Model: using BCE in regression https://stats.stackexchange.com/questions/370179/why-binary-crossentropy-can-be-used-as-the-loss-function-in-autoencoders/370180#370180\n",
    "model_RMSE_reg = build_model(MAX_SEQ_LENGTH, 'mean_squared_error', reg=True)\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "model_RMSE_reg.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data=([val_input_ids, val_input_masks, val_segment_ids], val_labels),\n",
    "    epochs=3,\n",
    "    batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights\n",
    "model_RMSE_reg.save_weights('./models/model_RMSE_reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.03421395],\n",
       "       [-0.03421395,  1.        ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model's predictions\n",
    "preds_RMSE_reg = model_RMSE_reg.predict([test_input_ids, test_input_masks, test_segment_ids])\n",
    "np.corrcoef(preds_RMSE_reg.T, test_actual.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
