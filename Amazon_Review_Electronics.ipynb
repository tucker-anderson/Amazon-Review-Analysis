{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Helpfulness of Amazon Reviews - Electronics Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import wget\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "# this nltk download may be needed. download stopwords, punkt\n",
    "# nltk.download()\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset - download directly from source, save to data directory\n",
    "\n",
    "file_name = \"data/reviews_Electronics_5.json.gz\"\n",
    "output_dir = \"data\"\n",
    "url = \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\"\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "if not os.path.isfile(file_name):\n",
    "    file_name = wget.download(url, out=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to parse data from compressed json into pandas DF\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def get_dataframe(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        if i < 800000: # actual electronics file is too big to hold in memory\n",
    "            df[i] = d\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "\n",
    "# helper function to pull out total helpful votes\n",
    "def get_helpful_votes(helpful):\n",
    "    [helpful, total] = helpful\n",
    "    return helpful\n",
    "\n",
    "\n",
    "# helper function to pull out total votes (helpful and unhelpful)\n",
    "def get_total_votes(helpful):\n",
    "    [helpful, total] = helpful\n",
    "    return total\n",
    "    \n",
    "    \n",
    "# helper function to calculate helpfulness percentage \n",
    "def calculate_helpful_perc(helpful):\n",
    "    [helpful, total] = helpful\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (helpful/total)\n",
    "\n",
    "# helper function to return a df of only and equally-balanced zero and one hundred percent helpful percentages\n",
    "def ones_and_zeroes_df(df):\n",
    "    df_zeroes = df[df.helpful_perc == 0]\n",
    "    len_zero = len(df_zeroes)\n",
    "    \n",
    "    df_ones = df[df.helpful_perc == 1]\n",
    "    len_one = len(df_ones)\n",
    "    \n",
    "    min_len = min(len_zero, len_one)\n",
    "    \n",
    "    while min_len > 250:\n",
    "        min_len = min_len*.9\n",
    "    \n",
    "    min_len = int(min_len)\n",
    "    df_ones = df.sample(min_len)\n",
    "    df_zeroes = df.sample(min_len)\n",
    "    \n",
    "    df = df_ones.append(df_zeroes, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df = get_dataframe(file_name)\n",
    "\n",
    "# parse helpful column into new columns of helpful_votes, total_votes, helpful_perc\n",
    "df['helpful_votes'] = df['helpful'].apply(get_helpful_votes)\n",
    "df['total_votes'] = df['helpful'].apply(get_total_votes)\n",
    "df['helpful_perc'] = df['helpful'].apply(calculate_helpful_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800000, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>613002</th>\n",
       "      <td>A1QPI8F7A4SOEN</td>\n",
       "      <td>B002JQNXZC</td>\n",
       "      <td>Vincent J.T.</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>For the price I was expecting a cheap throwawa...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Perfect!</td>\n",
       "      <td>1397001600</td>\n",
       "      <td>04 9, 2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326792</th>\n",
       "      <td>A3CXRGNK7U9GDU</td>\n",
       "      <td>B000V7AF8E</td>\n",
       "      <td>melvin breland</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Satisfied with this item, for the price it is ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Satisfied with my purchase!!1</td>\n",
       "      <td>1387152000</td>\n",
       "      <td>12 16, 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508556</th>\n",
       "      <td>A30J898CIPRWT2</td>\n",
       "      <td>B001PBYQHG</td>\n",
       "      <td>dlt074</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Fast, simple and easy to setup. I love the fac...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great system</td>\n",
       "      <td>1395100800</td>\n",
       "      <td>03 18, 2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658635</th>\n",
       "      <td>A38Y8Z0IWJJS9F</td>\n",
       "      <td>B002TLH4OI</td>\n",
       "      <td>J. Clay</td>\n",
       "      <td>[4, 7]</td>\n",
       "      <td>The price for this large selection of music is...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Great Selection of Songs, Mediocre Audio Quality</td>\n",
       "      <td>1280707200</td>\n",
       "      <td>08 2, 2010</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285561</th>\n",
       "      <td>AXUJOJ21SN31V</td>\n",
       "      <td>B000OPB4U6</td>\n",
       "      <td>Keith M. Hamm \"KMHamm\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I ordered this for my Verizon phone. It charge...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Ooops</td>\n",
       "      <td>1344816000</td>\n",
       "      <td>08 13, 2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin            reviewerName helpful  \\\n",
       "613002  A1QPI8F7A4SOEN  B002JQNXZC            Vincent J.T.  [0, 0]   \n",
       "326792  A3CXRGNK7U9GDU  B000V7AF8E          melvin breland  [0, 0]   \n",
       "508556  A30J898CIPRWT2  B001PBYQHG                  dlt074  [0, 0]   \n",
       "658635  A38Y8Z0IWJJS9F  B002TLH4OI                 J. Clay  [4, 7]   \n",
       "285561   AXUJOJ21SN31V  B000OPB4U6  Keith M. Hamm \"KMHamm\"  [0, 0]   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "613002  For the price I was expecting a cheap throwawa...      5.0   \n",
       "326792  Satisfied with this item, for the price it is ...      4.0   \n",
       "508556  Fast, simple and easy to setup. I love the fac...      5.0   \n",
       "658635  The price for this large selection of music is...      3.0   \n",
       "285561  I ordered this for my Verizon phone. It charge...      3.0   \n",
       "\n",
       "                                                 summary  unixReviewTime  \\\n",
       "613002                                          Perfect!      1397001600   \n",
       "326792                     Satisfied with my purchase!!1      1387152000   \n",
       "508556                                      Great system      1395100800   \n",
       "658635  Great Selection of Songs, Mediocre Audio Quality      1280707200   \n",
       "285561                                             Ooops      1344816000   \n",
       "\n",
       "         reviewTime  helpful_votes  total_votes  helpful_perc  \n",
       "613002   04 9, 2014              0            0      0.000000  \n",
       "326792  12 16, 2013              0            0      0.000000  \n",
       "508556  03 18, 2014              0            0      0.000000  \n",
       "658635   08 2, 2010              4            7      0.571429  \n",
       "285561  08 13, 2012              0            0      0.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at a sample of rows\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f68692e2750>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see if there are any missing values by feature\n",
    "# missing values show up in yellow\n",
    "sns.heatmap(df.isnull(),cbar=False,yticklabels=False,cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerName</th>\n",
       "      <td>7677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewText</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unixReviewTime</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewTime</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful_votes</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_votes</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful_perc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "reviewerID         0\n",
       "asin               0\n",
       "reviewerName    7677\n",
       "helpful            0\n",
       "reviewText         0\n",
       "overall            0\n",
       "summary            0\n",
       "unixReviewTime     0\n",
       "reviewTime         0\n",
       "helpful_votes      0\n",
       "total_votes        0\n",
       "helpful_perc       0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate how many values are missing by feature\n",
    "missing_df = pd.DataFrame(df.isnull().sum())\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800000.000000</td>\n",
       "      <td>8.000000e+05</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.206629</td>\n",
       "      <td>1.309132e+09</td>\n",
       "      <td>3.690540</td>\n",
       "      <td>4.310763</td>\n",
       "      <td>0.350446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.206717</td>\n",
       "      <td>7.633675e+07</td>\n",
       "      <td>29.700364</td>\n",
       "      <td>31.035890</td>\n",
       "      <td>0.448158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.292320e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.264032e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.326067e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.369008e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.975610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.406074e+09</td>\n",
       "      <td>5971.000000</td>\n",
       "      <td>6310.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             overall  unixReviewTime  helpful_votes    total_votes  \\\n",
       "count  800000.000000    8.000000e+05  800000.000000  800000.000000   \n",
       "mean        4.206629    1.309132e+09       3.690540       4.310763   \n",
       "std         1.206717    7.633675e+07      29.700364      31.035890   \n",
       "min         1.000000    9.292320e+08       0.000000       0.000000   \n",
       "25%         4.000000    1.264032e+09       0.000000       0.000000   \n",
       "50%         5.000000    1.326067e+09       0.000000       0.000000   \n",
       "75%         5.000000    1.369008e+09       1.000000       2.000000   \n",
       "max         5.000000    1.406074e+09    5971.000000    6310.000000   \n",
       "\n",
       "        helpful_perc  \n",
       "count  800000.000000  \n",
       "mean        0.350446  \n",
       "std         0.448158  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.975610  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at summary statistics of dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Histogram of Helpful Percentages')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at distribution of helpful_perc\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "n, bins, patches = ax1.hist(x=df['helpful_perc'], bins='auto')\n",
    "                                 \n",
    "ax1.set_xlabel('Helpful Perc')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Histogram of Helpful Percentages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216218, 12)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset df of reviews that have at least three votes\n",
    "df_three = df[df.total_votes >= 3]\n",
    "\n",
    "# subset df of reviews that have two both and both are in agreeement\n",
    "df_two = df[((df.total_votes == 2) & (df.helpful_perc == 1)) | ((df.total_votes == 2) & (df.helpful_perc == 0))]\n",
    "\n",
    "# combine the dfs back together\n",
    "df = df_three.append(df_two, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce size of df\n",
    "df = df.sample(80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>80000.000000</td>\n",
       "      <td>8.000000e+04</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.871738</td>\n",
       "      <td>1.247907e+09</td>\n",
       "      <td>13.160087</td>\n",
       "      <td>15.241825</td>\n",
       "      <td>0.804120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.409436</td>\n",
       "      <td>8.045828e+07</td>\n",
       "      <td>54.267460</td>\n",
       "      <td>56.301700</td>\n",
       "      <td>0.283421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.352800e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.198541e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.258675e+09</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.302653e+09</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.405555e+09</td>\n",
       "      <td>3869.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            overall  unixReviewTime  helpful_votes   total_votes  helpful_perc\n",
       "count  80000.000000    8.000000e+04   80000.000000  80000.000000  80000.000000\n",
       "mean       3.871738    1.247907e+09      13.160087     15.241825      0.804120\n",
       "std        1.409436    8.045828e+07      54.267460     56.301700      0.283421\n",
       "min        1.000000    9.352800e+08       0.000000      2.000000      0.000000\n",
       "25%        3.000000    1.198541e+09       2.000000      3.000000      0.692308\n",
       "50%        4.000000    1.258675e+09       4.000000      5.000000      0.953125\n",
       "75%        5.000000    1.302653e+09       9.000000     11.000000      1.000000\n",
       "max        5.000000    1.405555e+09    3869.000000   3972.000000      1.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Histogram of Helpful Percentages')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(1, 1, 1)\n",
    "n, bins, patches = ax2.hist(x=df['helpful_perc'], bins='auto')\n",
    "                                 \n",
    "ax2.set_xlabel('Helpful Perc')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Histogram of Helpful Percentages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Helpful Reviews Are Determined Randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005739722853518907"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to repeat results\n",
    "random.seed(12345)\n",
    "\n",
    "# calculate total number of reviews\n",
    "total_reviews = len(df)\n",
    "\n",
    "helpful_perc = df['helpful_perc']\n",
    "\n",
    "random_helpful = []\n",
    "for i in range(total_reviews):\n",
    "    random_helpful.append(random.random())\n",
    "    \n",
    "\n",
    "np.corrcoef(helpful_perc, random_helpful)[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Encoded Words and Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure there are no missing values in the review or summary text or the overall helpullness percentage\n",
    "len(df) == len(df.dropna(subset=['reviewText', 'summary', 'helpful_perc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words and tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize(text):\n",
    "    return [word for word in word_tokenize(text) if not word in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the reviewText and summary text fields to combine into a single \"document\" with which to analyze\n",
    "df['combinedText'] = df['summary'].str.lower() + \". \" +  df['reviewText'].str.lower()\n",
    "\n",
    "# Now tokenize these and remove stop words\n",
    "df['processedText'] = df['combinedText'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "data = df[['combinedText', 'helpful_perc']]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "preprocessed_data = data.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(preprocessed_data['combinedText'], \n",
    "                                                    preprocessed_data['helpful_perc'],\n",
    "                                                    random_state = 12345, # reproduce results\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# train the model using the training sets\n",
    "regr.fit(np.array(Train_X.values.tolist()).reshape(-1, 1), Train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test Labels and Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011940009351676727"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict values\n",
    "pred = regr.predict(np.array(Test_X.values.tolist()).reshape(-1, 1))\n",
    "\n",
    "# score with correlation coefficient\n",
    "np.corrcoef(Test_Y,pred)[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: TF-IDF and Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train//test sets\n",
    "data = df[['combinedText', 'helpful_perc']]\n",
    "\n",
    "df_train, df_test = train_test_split(data, test_size = 0.2, random_state = 12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem combinedText to reduce size of corpus\n",
    "porter=PorterStemmer()\n",
    "\n",
    "def stem_text(df):\n",
    "    text_list = df['combinedText'].tolist()\n",
    "    text_list_stem = [None] * len(text_list)\n",
    "\n",
    "    for i in range(len(text_list)):\n",
    "        text_list_stem[i] = ' '.join([porter.stem(w) for w in text_list[i].split()])\n",
    "    \n",
    "    return text_list_stem\n",
    "\n",
    "text_list_stem = stem_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.07120491, 0.        , 0.        , ..., 0.        , 0.20437253,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.10443922, 0.07632301,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.08908831, ..., 0.        , 0.07088923,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize text\n",
    "vectorizer = TfidfVectorizer(\n",
    "                max_features=100,\n",
    "                ngram_range=(1,1)\n",
    "                )\n",
    "\n",
    "vectorizer.fit_transform(text_list_stem).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (64000, 100)\n"
     ]
    }
   ],
   "source": [
    "# vectorize train dataset\n",
    "train_text_stem = stem_text(df_train)\n",
    "train_vectorized = vectorizer.transform(train_text_stem).toarray()\n",
    "\n",
    "print('Shape:', train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (16000, 100)\n"
     ]
    }
   ],
   "source": [
    "# vectorize test dataset\n",
    "test_text_stem = stem_text(df_test)\n",
    "test_vectorized = vectorizer.transform(test_text_stem).toarray()\n",
    "\n",
    "print('Shape:', test_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array of labels to use in linear regression\n",
    "df_train_labels = np.array(df_train['helpful_perc'])\n",
    "df_test_labels = np.array(df_test['helpful_perc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\n",
    "regr_2 = linear_model.LinearRegression()\n",
    "\n",
    "# train the model using the training sets\n",
    "regr_2.fit(np.array(train_vectorized.tolist()), df_train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test Labels and Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36515069509275905"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict values\n",
    "pred_2 = regr_2.predict(np.array(test_vectorized.tolist()))\n",
    "\n",
    "# score with correlation coefficient\n",
    "np.corrcoef(df_test_labels, pred_2)[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "# if this doesnt work, ensure tensorflow is version <2.0\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Tensorflow hub path to BERT module of choice\n",
    "BERT_DIR =  \"./bert\"\n",
    "BERT_PATH = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "sys.path.insert(0,BERT_DIR)\n",
    "\n",
    "# Initialize session, may need to remove config if no GPU\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "  When running eval/predict on the TPU, we need to pad the number of examples\n",
    "  to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "  size. The alternative is to drop the last batch, which is bad because it means\n",
    "  the entire output data won't be generated.\n",
    "  We use this class instead of `None` because treating `None` as padding\n",
    "  battches could cause silent errors.\n",
    "  \"\"\"\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.text_a)\n",
    "\n",
    "def create_tokenizer_from_hub_module(path):\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module =  hub.Module(path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    tokens_b = tokenizer.tokenize(example.text_b)\n",
    "    \n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    elif (len(tokens_a)+len(tokens_b)) > max_seq_length - 3:\n",
    "        tokens_b = tokens_b[0 : (max_seq_length - 3 - len(tokens_a))]\n",
    "        \n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    \n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    if len(tokens) < max_seq_length:\n",
    "        for token in tokens_b:\n",
    "            tokens.append(token)\n",
    "            segment_ids.append(1)\n",
    "        tokens.append(\"[SEP]\")\n",
    "        segment_ids.append(1)\n",
    "    \n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "def convert_text_to_examples(titles, texts, labels, max_examples=None):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for title, text, label in zip(titles, texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=title, text_b=text, label=label)\n",
    "        )\n",
    "    return InputExamples[:max_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/keanejohnson/Amazon-Review-Analysis/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module(BERT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process df - only reviews that have 0 or 100% ratings and at least 10 reviews\n",
    "df = df.drop(df[df.total_votes < 5].index)\n",
    "df = ones_and_zeroes_df(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2)\n",
    "df_train, df_val = train_test_split(df_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c6d6dcfc8347c28d7e0369f482e2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=310), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc36893f77d84f8aa569b7d8a87c79cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=78), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae80ac55d785452cb61829b6bb2bf17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=98), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert data to InputExample format, ensure we don't have too many examples to encounter memory issues\n",
    "train_examples = convert_text_to_examples(df_train['summary'], df_train['reviewText'], df_train['helpful_perc'], max_examples=10000)\n",
    "val_examples = convert_text_to_examples(df_val['summary'], df_val['reviewText'], df_val['helpful_perc'], max_examples=2000)\n",
    "test_examples = convert_text_to_examples(df_test['summary'], df_test['reviewText'], df_test['helpful_perc'], max_examples=2000)\n",
    "\n",
    "#make sure the test Y is the same format\n",
    "test_actual = np.array(df_test['helpful_perc'][:2000])\n",
    "test_actual = test_actual.reshape(-1,1)\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
    ") = convert_examples_to_features(tokenizer, train_examples, max_seq_length=MAX_SEQ_LENGTH)\n",
    "(val_input_ids, val_input_masks, val_segment_ids, val_labels \n",
    ") = convert_examples_to_features(tokenizer, val_examples, max_seq_length=MAX_SEQ_LENGTH)\n",
    "(test_input_ids, test_input_masks, test_segment_ids, test_labels\n",
    ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create neural net\n",
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"first\",\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_path = bert_path\n",
    "        if self.pooling not in [\"first\", \"mean\"]:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "\n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'n_fine_tune_layers': self.n_fine_tune_layers,\n",
    "                  'pooling': self.pooling,\n",
    "                  'bert_path': self.bert_path}\n",
    "        base_config = super(MyMeanPooling, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Build model\n",
    "def build_model(max_seq_length, model_loss, reg=False): \n",
    "\n",
    "    in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "\n",
    "    bert_output = BertLayer(n_fine_tune_layers=3, pooling=\"first\")(bert_inputs)\n",
    "    if reg:\n",
    "        dense = tf.keras.layers.Dense(max_seq_length, activation='relu', kernel_regularizer=regularizers.l2(0.01))(bert_output)\n",
    "    else:\n",
    "        dense = tf.keras.layers.Dense(max_seq_length, activation='relu')(bert_output)\n",
    "    pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss=model_loss, optimizer='adam')\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/keanejohnson/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer (BertLayer)          (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          98432       bert_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 110,203,451\n",
      "Trainable params: 21,952,769\n",
      "Non-trainable params: 88,250,682\n",
      "__________________________________________________________________________________________________\n",
      "Train on 310 samples, validate on 78 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/keanejohnson/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "310/310 [==============================] - 304s 982ms/sample - loss: 1.1219 - val_loss: 0.3804\n",
      "Epoch 2/3\n",
      "310/310 [==============================] - 287s 927ms/sample - loss: 0.2573 - val_loss: 0.1494\n",
      "Epoch 3/3\n",
      "310/310 [==============================] - 301s 969ms/sample - loss: 0.1164 - val_loss: 0.0903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f89847f5210>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "#BCE Model: using BCE in regression https://stats.stackexchange.com/questions/370179/why-binary-crossentropy-can-be-used-as-the-loss-function-in-autoencoders/370180#370180\n",
    "model_RMSE_reg = build_model(MAX_SEQ_LENGTH, 'mean_squared_error', reg=True)\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "model_RMSE_reg.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data=([val_input_ids, val_input_masks, val_segment_ids], val_labels),\n",
    "    epochs=3,\n",
    "    batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights\n",
    "model_RMSE_reg.save_weights('./models/model_RMSE_reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.03640819],\n",
       "       [-0.03640819,  1.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model's predictions\n",
    "preds_RMSE_reg = model_RMSE_reg.predict([test_input_ids, test_input_masks, test_segment_ids])\n",
    "np.corrcoef(preds_RMSE_reg.T, test_actual.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
