{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Yoks35UT5or"
   },
   "source": [
    "# Predicting the Helpfulness of Amazon Reviews\n",
    "### Keane Johnson and Tucker Anderson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook builds multiple models that predict the helpfulness of Amazon reviews. It uses the [2015 Amazon Review dataset](http://jmcauley.ucsd.edu/data/amazon/index.html), compiled by Julian McAuley, associate professor in the Computer Science department at the University of California, San Diego.\n",
    "\n",
    "The dataset contains product reviews from Amazon from May 1996 - July 2014, and includes ratings, text, helpfulness votes, descriptions, category information, price, brand, and image features. It is broken into smaller subsets, organized by product category.\n",
    "\n",
    "This notebook focuses on the Home and Kitchen sub-category, and uses the aforementioned features to predict helpfulness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "- Import Libraries\n",
    "- Load and Prepare Dataset\n",
    "- Exploratory Data Analysis\n",
    "- Model 1: Every review is 100% helpful\n",
    "- Model 2: Naive Bayes Bag of Words with Binary Helpfulness Labels\n",
    "- Model 3: TFIDF and Logistic Regression\n",
    "- Model 4: BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9t_9MV2_UO1O"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WXeTT4GwA9bN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load packages\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import wget\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load dataset - download directly from source, save to data directory\n",
    "\n",
    "file_name = \"data/reviews_Home_and_Kitchen_5.json.gz\"\n",
    "output_dir = \"data\"\n",
    "url = \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Home_and_Kitchen_5.json.gz\"\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "if not os.path.isfile(file_name):\n",
    "    file_name = wget.download(url, out=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to parse data from compressed json into pandas DF\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def get_dataframe(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    \n",
    "    df_return = pd.DataFrame.from_dict(df, orient='index')\n",
    "    #shuffle all records to reduce bias of order of data\n",
    "    df_return = df_return.sample(frac=1)\n",
    "    \n",
    "    return df_return\n",
    "\n",
    "\n",
    "# helper function to pull out total helpful votes\n",
    "def get_helpful_votes(helpful):\n",
    "    [helpful, total] = helpful\n",
    "    return helpful\n",
    "\n",
    "\n",
    "# helper function to pull out total votes (helpful and unhelpful)\n",
    "def get_total_votes(helpful):\n",
    "    [helpful, total] = helpful\n",
    "    return total\n",
    "    \n",
    "    \n",
    "# helper function to calculate helpfulness percentage \n",
    "def calculate_helpful_perc(helpful):\n",
    "    [helpful, total] = helpful\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (helpful/total)\n",
    "    \n",
    "def balance_df(df):\n",
    "    df_non_one = df[df.helpful_perc != 1]\n",
    "    len_zero = len(df[df.helpful_perc == 0])\n",
    "    print(len_zero)\n",
    "    print(len(df[df.helpful_perc == 1]))\n",
    "    df_one = df[df.helpful_perc == 1].sample(len_zero)\n",
    "    df = df_non_one.append(df_one, ignore_index=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wHEe5MIfBIsL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n",
      "23257\n"
     ]
    }
   ],
   "source": [
    "# create dataframe\n",
    "df = get_dataframe(file_name)\n",
    "\n",
    "# parse helpful column into new columns of helpful_votes, total_votes, helpful_perc\n",
    "df['helpful_votes'] = df['helpful'].apply(get_helpful_votes)\n",
    "df['total_votes'] = df['helpful'].apply(get_total_votes)\n",
    "df['helpful_perc'] = df['helpful'].apply(calculate_helpful_perc)\n",
    "\n",
    "\n",
    "# Now create the combinedText with casing and no longer than 512 characters (max of BERT embedding input)\n",
    "df['combinedText'] = df['summary'] + \". \" + df['reviewText']\n",
    "\n",
    "#drop rows where not enough votes exist to discern helpfullness\n",
    "kitchen_df = df.drop(df[df.total_votes < 5].index)\n",
    "balanced_kitchen_df = balance_df(kitchen_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCDusLkwUHJr"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(551682, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 551,682 rows and twelve columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>438202</th>\n",
       "      <td>A1UY3S4OR2ZLK4</td>\n",
       "      <td>B005DN65WG</td>\n",
       "      <td>John L</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These mattress protector are terrific. Unlike ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Terrific Product</td>\n",
       "      <td>1391126400</td>\n",
       "      <td>01 31, 2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471318</th>\n",
       "      <td>A30WZ2LGA8VVPR</td>\n",
       "      <td>B0077L8YFI</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Pros: Really loved the look, it wasn't too dif...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Was disappointed so I returned it.  The weight...</td>\n",
       "      <td>1396310400</td>\n",
       "      <td>04 1, 2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68407</th>\n",
       "      <td>ATS3U1L4F89VQ</td>\n",
       "      <td>B0000DE9B8</td>\n",
       "      <td>Diane</td>\n",
       "      <td>[2, 4]</td>\n",
       "      <td>You really can't go wrong with a glass measuri...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>You Can't Go Wrong</td>\n",
       "      <td>1124409600</td>\n",
       "      <td>08 19, 2005</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401258</th>\n",
       "      <td>A2JSKM60VTCNI</td>\n",
       "      <td>B004CLYAM2</td>\n",
       "      <td>Paul Stuart \"&amp;#34;...also I'll brush my teeth...</td>\n",
       "      <td>[8, 13]</td>\n",
       "      <td>Reviewer Disclaimer: This was received as a Re...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Crisp, clean air in a sleek package...but bett...</td>\n",
       "      <td>1341446400</td>\n",
       "      <td>07 5, 2012</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548589</th>\n",
       "      <td>A1JBBR4MNGQ70G</td>\n",
       "      <td>B00J7XVNAM</td>\n",
       "      <td>Falkor The White Luck Dragon</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>I needed a window air conditioner as the upsta...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Just What I Was Looking For</td>\n",
       "      <td>1402358400</td>\n",
       "      <td>06 10, 2014</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin  \\\n",
       "438202  A1UY3S4OR2ZLK4  B005DN65WG   \n",
       "471318  A30WZ2LGA8VVPR  B0077L8YFI   \n",
       "68407    ATS3U1L4F89VQ  B0000DE9B8   \n",
       "401258   A2JSKM60VTCNI  B004CLYAM2   \n",
       "548589  A1JBBR4MNGQ70G  B00J7XVNAM   \n",
       "\n",
       "                                            reviewerName  helpful  \\\n",
       "438202                                            John L   [0, 0]   \n",
       "471318                                          Jonathan   [0, 0]   \n",
       "68407                                              Diane   [2, 4]   \n",
       "401258  Paul Stuart \"&#34;...also I'll brush my teeth...  [8, 13]   \n",
       "548589                      Falkor The White Luck Dragon   [2, 2]   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "438202  These mattress protector are terrific. Unlike ...      5.0   \n",
       "471318  Pros: Really loved the look, it wasn't too dif...      1.0   \n",
       "68407   You really can't go wrong with a glass measuri...      5.0   \n",
       "401258  Reviewer Disclaimer: This was received as a Re...      3.0   \n",
       "548589  I needed a window air conditioner as the upsta...      5.0   \n",
       "\n",
       "                                                  summary  unixReviewTime  \\\n",
       "438202                                   Terrific Product      1391126400   \n",
       "471318  Was disappointed so I returned it.  The weight...      1396310400   \n",
       "68407                                  You Can't Go Wrong      1124409600   \n",
       "401258  Crisp, clean air in a sleek package...but bett...      1341446400   \n",
       "548589                        Just What I Was Looking For      1402358400   \n",
       "\n",
       "         reviewTime  helpful_votes  total_votes  helpful_perc  \n",
       "438202  01 31, 2014              0            0      0.000000  \n",
       "471318   04 1, 2014              0            0      0.000000  \n",
       "68407   08 19, 2005              2            4      0.500000  \n",
       "401258   07 5, 2012              8           13      0.615385  \n",
       "548589  06 10, 2014              2            2      1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The twelve columns contain data including the reviewer name and review time, in addition to more applicable data to our models, like review text, summary, and helpful scores. The helpful column is a list of two numbers. The first number is the number of individuals who found that review helpful. The second number is the total number of individuals who scored that review.\n",
    "\n",
    "We parse out these two numbers in helpful_votes and total_votes. We calculate the helpfulness percentage as well in helpful_perc. This is simply the number of helpful_votes divided by the number of total_votes. Helpful_perc will be our target variable in our models.\n",
    "\n",
    "There are two sources of natural language in the dataset - reviewText and summary. We assume the reviewText will be more robust and impactful in determining whether a review is helpful or not. However, summary is a good resource for our models as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to examine the completeness of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a4722e2898>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a46e8b9d30>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),cbar=False,yticklabels=False,cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This heatmap shows that there are missing values for some observations of reviewerName. However, with such a large dataset, we could be missing some values for other features that just do not appear on this chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerName</th>\n",
       "      <td>4953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewText</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unixReviewTime</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewTime</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful_votes</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_votes</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful_perc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "reviewerID         0\n",
       "asin               0\n",
       "reviewerName    4953\n",
       "helpful            0\n",
       "reviewText         0\n",
       "overall            0\n",
       "summary            0\n",
       "unixReviewTime     0\n",
       "reviewTime         0\n",
       "helpful_votes      0\n",
       "total_votes        0\n",
       "helpful_perc       0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = pd.DataFrame(df.isnull().sum())\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We confirm that we are only missing values for reviewerName. We reason that this does not have an impact on our analysis because we will be using primarily the reviewText, and possibly the summary, to determine a review's helpfulness. Additionally, we argue that individuals do not consistently use a reviewer's name when determining a review's helpfulness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reviewing some sample data, and examining missing values, we next look at some summary statistics of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>551682.000000</td>\n",
       "      <td>5.516820e+05</td>\n",
       "      <td>551682.000000</td>\n",
       "      <td>551682.000000</td>\n",
       "      <td>551682.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.316655</td>\n",
       "      <td>1.348687e+09</td>\n",
       "      <td>3.497348</td>\n",
       "      <td>3.939469</td>\n",
       "      <td>0.367910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.110749</td>\n",
       "      <td>6.120238e+07</td>\n",
       "      <td>76.539142</td>\n",
       "      <td>77.801556</td>\n",
       "      <td>0.456931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.572256e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.331770e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.367626e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.388880e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.406074e+09</td>\n",
       "      <td>52176.000000</td>\n",
       "      <td>52861.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             overall  unixReviewTime  helpful_votes    total_votes  \\\n",
       "count  551682.000000    5.516820e+05  551682.000000  551682.000000   \n",
       "mean        4.316655    1.348687e+09       3.497348       3.939469   \n",
       "std         1.110749    6.120238e+07      76.539142      77.801556   \n",
       "min         1.000000    9.572256e+08       0.000000       0.000000   \n",
       "25%         4.000000    1.331770e+09       0.000000       0.000000   \n",
       "50%         5.000000    1.367626e+09       0.000000       0.000000   \n",
       "75%         5.000000    1.388880e+09       1.000000       2.000000   \n",
       "max         5.000000    1.406074e+09   52176.000000   52861.000000   \n",
       "\n",
       "        helpful_perc  \n",
       "count  551682.000000  \n",
       "mean        0.367910  \n",
       "std         0.456931  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These summary statistics show that over half of our observations have a 0% helpfulness. In addition, these observations have zero total votes. This means that the reviews simply haven't been voted upon. We should remove these observations from our dataset because our model could misinterpret the 0% helpful_perc to mean that the review was not helpful when in fact the review just hasn't been voted upon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a histogram to visualize the distribution of helpful percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1a47c27a240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a472fc0ac8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "n, bins, patches = ax1.hist(x=df['helpful_perc'], bins='auto')\n",
    "                                 \n",
    "ax1.set_xlabel('Helpful Perc')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Histogram of Helpful Percentages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram shows that the majority of reviews have a 0% helpful percentage, with the second most prevalent percentage being 100%. However, our dataset needs to be cleaned to remove observations that may add noise, but do not add meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be purposeful with the data that we are supplying to our model. We want to only analyze reviews where there are at least three total votes, or reviews where there are two total votes, but both votes are in agreement.\n",
    "\n",
    "Our rationale is that two total votes that are split does not tell us much. However, if both are an agreeement, that could tell us something about a reviews helpfulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139470, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset df of reviews that have at least three votes\n",
    "df_three = df[df.total_votes >= 3]\n",
    "\n",
    "# subset df of reviews that have two both and both are in agreeement\n",
    "df_two = df[((df.total_votes == 2) & (df.helpful_perc == 1)) | ((df.total_votes == 2) & (df.helpful_perc == 0))]\n",
    "\n",
    "# combine the dfs back together\n",
    "df = df_three.append(df_two, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of our dataset is now 139,470 rows. Next we can examine the new distribution of helpful_perc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>139470.000000</td>\n",
       "      <td>1.394700e+05</td>\n",
       "      <td>139470.000000</td>\n",
       "      <td>139470.000000</td>\n",
       "      <td>139470.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.988270</td>\n",
       "      <td>1.301792e+09</td>\n",
       "      <td>13.178676</td>\n",
       "      <td>14.704022</td>\n",
       "      <td>0.848035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.356746</td>\n",
       "      <td>8.137408e+07</td>\n",
       "      <td>151.811710</td>\n",
       "      <td>154.232187</td>\n",
       "      <td>0.242654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.572256e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.261181e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.324080e+09</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.362874e+09</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.405728e+09</td>\n",
       "      <td>52176.000000</td>\n",
       "      <td>52861.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             overall  unixReviewTime  helpful_votes    total_votes  \\\n",
       "count  139470.000000    1.394700e+05  139470.000000  139470.000000   \n",
       "mean        3.988270    1.301792e+09      13.178676      14.704022   \n",
       "std         1.356746    8.137408e+07     151.811710     154.232187   \n",
       "min         1.000000    9.572256e+08       0.000000       2.000000   \n",
       "25%         3.000000    1.261181e+09       2.000000       3.000000   \n",
       "50%         5.000000    1.324080e+09       4.000000       5.000000   \n",
       "75%         5.000000    1.362874e+09       9.000000      10.000000   \n",
       "max         5.000000    1.405728e+09   52176.000000   52861.000000   \n",
       "\n",
       "        helpful_perc  \n",
       "count  139470.000000  \n",
       "mean        0.848035  \n",
       "std         0.242654  \n",
       "min         0.000000  \n",
       "25%         0.750000  \n",
       "50%         1.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median helpful_perc is 100%. We could be at risk of not having a good distribution of data to train on. This could result in our model being overly optimistic and inflating the helpfulness scores of reviews. We can visualize this skew with another histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1a417e89198>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a419904828>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(1, 1, 1)\n",
    "n, bins, patches = ax2.hist(x=df['helpful_perc'], bins='auto')\n",
    "                                 \n",
    "ax2.set_xlabel('Helpful Perc')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Histogram of Helpful Percentages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Subsetting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to resource constraints, we'll subset our data to roughly half the original size. This is still more than enough data to build and test our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled = df.sample(80000)\n",
    "df_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1a40e73e0f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu4HFWZ7/Hvj4RLuAUIIYMJECQRBc6AECDekegQFA0zBzCOA4GJoAM6OuOMBI4z4pnJGXjGEeE4oCieBBiBCCIRjRqDCI6GEG6GADFbLiaBXAiBcBEw8J4/6m2oNN17906q96bZv8/z9NNVq2pVrVVd3W+tVdVVigjMzMyqsEV/F8DMzF4/HFTMzKwyDipmZlYZBxUzM6uMg4qZmVXGQcXMzCrjoLIZJC2WdER/l6M/SfpzScskPS3prW1Y/gxJ/9rivEMk/UDSk5K+28L8N0n6+OaX0lolaYSkmyU9Jek/Kl72OZKuqHKZ7SIpJI3p73K0g4NKE5IekvS+urSTJf2yNh4R+0fETT0sZ3TuQIPbVNT+9mXgUxGxfUTcWT+x0ZenjV/+44ARwLCIOH5zFpRl/GMGyyck/UrS26opZjU66Ue05DTgMWDHiPhc/URJoyRdK+mxPDi4R9LJfV7KV8rzqu9v/e9AG9Z5k6TnMvCul3S7pGmStu7FMvotaDmodLjXQLDaC1jcz2Wo2Qv4bURsqGh5V0fE9sBw4JfA9ySpNwt4DXw+rzV7AfdG839dXw4sy/mGAScCq/qobK8ln4qIHYDdgc8Bk4Ef9Xb/6w8OKpuh3JqRdJikhXlksUrSV3K2m/P9iTzqfZukLSR9QdLDklZLukzS0NJyT8ppayX9U916zpF0jaQrJK0HTs51/zqPqB+V9DVJW5WWF5JOl7Q0j37+RdI+efS9XtKs8vx1dWxYVklbS3oaGATcLel3m7Ed3yxprqTHJS2RdEKT+Y6QtFzS2Xkk+5Ckj+W0LwH/DHwkt/PU+iP5TW01RsQfgZnAn1D80CHpryXdJ2mdpJ9I2qu0npB0hqSlwNJM279Ux1WSzs70LfIo9Hf5ec+StEtdeadI+n3W+X/ltInA2aX63p3pp2S5npL0gKRP1G3Dz+c+8oikj5ePaPMz/XKua5Wkr0saktN2lXRD7mOPS7pFUsPfD0lvl3SbipbGbZLenukzgCnA57PM72uQ/VBgRkQ8ExEbIuLOiJiT+Y+QtLxuXfU9CttIujrrf4ekA0vznilpRU5bImlCT58BDb6/wNeBt+X4Ez1tu5z+j6Xt/teNtlsjuR1uAj4MvA34YC6v6XdeUq3Md2cZPyJp5/z81uQ+e4OkUa2Wo1ciwq8GL+Ah4H11aScDv2w0D/Br4MQc3h4Yn8OjgQAGl/L9NdAFvDHn/R5weU7bD3gaeCewFUX30h9L6zknx4+lOCgYAhwCjAcG5/ruAz5bWl8A1wM7AvsDzwPzcv1DgXuBKU22Q9OylpY9ppvt+KrpWYcrcng7iiPTU7L8b6XoHtkvp88A/jWHjwA2AF8BtgbeAzwD7Fu/3CbjG30WwE3Ax5uUu1zGrYF/B36f45Nym7wly/wF4Fd1dZ4L7JKfzw7AoxRHnNvk+OE572eA+cCoXM83gCvryvvNXM6B+dm9pVH9Mu2DwD6Acvs8Cxyc0yYCK3Mf2Ba4ovz5AOcDs7PcOwA/AP4tp/0bxY/plvl6F6AG220XYB1FC2Mw8NEcH1b/eTbZ7j8D/pviyHzPumlHAMubfU955btxXJbxH4AHc3hfiv3sDaVtu08vPoPy9/dkSr8DLWy7iRStrQMo9vfv0M33hib7JUWAOy+HW/nOjymNDwP+Z37uOwDfBb7flt/Odiz09fDKnfVp4InS61maB5WbgS8Bu9Ytp9FOOQ84vTS+b34ZBlMcbV9ZmrYt8ELdF+fmHsr+WeC6uh3sHaXx24EzS+P/AXy1ybKalrXRztsgfwDr67bjc7zyg/0R4Ja6PN8AvpjDM3h1UNmuNO8s4J9K26bKoPJClnc1cCNwSE6bA0wtzbtF7ht7lep8ZGn6R4E7m6znPmBCaXz30r5QK++o0vQFwORG9Wuy/O8Dn8nhb5M/dDk+pvb5UQShZ8gf2pz+NuDBHP7fFAcmTT/rnO9EYEFd2q+Bk+s/zyb5dwbOpehSfRG4Czi09Pn3FFTm130uj1IEwDH5Ob4P2HITPoOmQaWFbfdt4NzStDexaUHlKuCbvfjOd/e9PAhY191nuakvd39179iI2Kn2Ak7vZt6pFDvL/dnkP6abed8APFwaf5hiBx6R05bVJkTEs8DauvzLyiOS3pTN2ZUqusT+D7BrXZ5yv/QfGoxvvwllbdXBddvx3NK0vYDDsxn/RHYnfIyiq6mRdRHxTF153tCLsvTGrCzzbhFxZETcXirzBaXyPk7xwzKylLf8Ge0BNOse3Au4rrSs+yh+TMvbd2Vp+Fmaf1ZIOlrS/OyiegL4AK/sCxvtW3XDwykOYG4vleXHmQ5FS60L+Gl2q01rUoT6/YUcH9lg3leJiHURMS0i9qfYBncB35daPpdQ/u68BCynaJ10UfzwngOslnSVpNp+08pn0J2etl39dq/fPq0aSbGvtfqdf5mkbSV9Q0U39nqKg+CdJA3axLI05aBSkYhYGhEfBXYDzgOukbQdxRFDvUcoduSaPSmOwFdRHFm93NeZ/bLD6ldXN34xcD8wNiJ2pOhrr+qEXndlrcIy4BfloBPFlWR/02T+nXO7lsvzSJN5n6H4stc0C1S9tQz4RF2Zh0TEr0rzRN38b+xmWUfXLWubiFjRQjk22g9UXB10LUWX6YgM4D/ilX1ho32LItjVPEZxcLF/qRxDo7hQgYh4KiI+FxFvpOjf//vaOYk69fsLFJ9RK/XZuHIRj2Vd3kDRrbTR55k/iMPrsu1Rmr4FRX0fyeV9JyLemeULiu8pdP8ZNPr+1qd1u+0otnt5W+/Z2hZ4haQ9KLq8bsmk3n7nP0fRy3B4zv/u2qJ7W5aeOKhURNJfSRqeR0dPZPJLwJp8L/+oXAn8naS9JW1PcZRxdRRXLV0DfChPdm5FcWTV0we/A0UX09OS3gw0+0HeFN2VtQo3AG+SdKKkLfN1qKS3dJPnS5K2kvQu4BiK/uFG7gLeLWlPFRdCnFVRmb8OnCVpfwAVFy50dwnzDcDukj6bJ3R3kHR4aVnTlSf6JQ2XNKnFcqwCRuuVE+ZbUZwTWANskHQ08Gel+WcBp0h6i6RtgX+qTcj99pvA+ZJ2y7KMlHRUDh8jaUy2GJ6kOJJ/qUGZfkTxef6lpMGSPkJxnvCGViok6TxJB2TeHSj25a6IWAv8luJE/AclbUlxLqv+MttDJP2FiosxPktxDmq+pH0lHZmB9zmKIFArf3efQaPv7ypgVO3EeE/bjmK7nyxpv9zuX2xlW+RytpX0HoquxwUU2xd6/s6vqivzDlnnJ1RchNByGXrLQaU6E4HFKq6IuoCi3/sP2X01HfjvbBqPp+hjvZyiCfogxU7+aYCIWJzDV1Ec4TxN0Rf8fDfr/gfgL4GnKHbuqyusV9OyViEinqL44ZtMcUS5kuIIstk1+SspTvw+AvwX8MmIuL/JsudSbIvfUJxHaumHrYUyX5dlvCq7Eu4Bju5m/qeA9wMfyvIvBd6bky+gOMH7U0lPUZwwPrzRchqoBdO1ku7I9fwtxY/YOop9YnapHHOAC4GfU3Rlzc9JtX3rzFp61utnFEe3AGNz/GmKcyQXRcTPG9R1LUWg/xxFt+3ngWOy1dGKbYHrKA7MHqBoVXw4l/0kRRf0tyhaPs9QdG+VXU9xnq52scBfRHH13tYU3a6PUXwGu/HKQUbTz6DJ9/dGinM+KyXV6tV02+V2/2rm68r3nnwty7Iq814LTMwABj1/588BZmaZT8hlDMn6z6fonmsL5Ukbe43K1sETFM3cB/u7PP1Jxd0LroiI9lwKOcBka/AeYOsKW542wLml8hok6UPZ7N2Ook95EcVVLmabRcVtdbaWtDNFa+sHDihWJQeV16ZJFN07j1B0O0wONymtGp+g6E79HcV5kSrPv5m5+8vMzKrjloqZmVVmwN3sbtddd43Ro0f3dzHMzDrK7bff/lhE1P8v6FUGXFAZPXo0Cxcu7O9imJl1FEkt3QnA3V9mZlYZBxUzM6uMg4qZmVXGQcXMzCrjoGJmZpVxUDEzs8o4qJiZWWUcVMzMrDIOKmZmVpkB9496M7OBZPS0H748/NC5H2z7+txSMTOzyrQtqOQzoe8qvdbnM7p3kTRX0tJ837mU5yxJXZKWlJ7vjKRDJC3KaRfmc7LJhw1dnem3ShrdrvqYmVnP2hZUImJJRBwUEQcBhwDPUjx7ehowLyLGAvNyHEn7UTynfH+K571fJGlQLu5i4FSKB1aNzekAU4F1ETEGOJ/iSXZmZtZP+qr7awLwu4h4mOKphjMzfSZwbA5PAq6KiOfzWexdwGGSdgd2jIj5+fTDy+ry1JZ1DTCh1ooxM7O+11dBZTJwZQ6PiIhHc3glMCKHRwLLSnmWZ9rIHK5P3yhPPmf7SWBY/colnSZpoaSFa9as2fzamJlZQ20PKpK2Aj4MfLd+WrY82v4844i4JCLGRcS44cN7fMaMmZltor5oqRwN3BERq3J8VXZpke+rM30FsEcp36hMW5HD9ekb5ZE0GBgKrG1DHczMrAV9EVQ+yitdXwCzgSk5PAW4vpQ+Oa/o2pvihPyC7CpbL2l8ni85qS5PbVnHATdm68fMzPpBW//8KGk74P3AJ0rJ5wKzJE0FHgZOAIiIxZJmAfcCG4AzIuLFzHM6MAMYAszJF8ClwOWSuoDHKc7dmJlZP2lrUImIZ6g7cR4RaymuBms0/3RgeoP0hcABDdKfA46vpLBmZrbZ/I96MzOrjIOKmZlVxkHFzMwq46BiZmaVcVAxM7PKOKiYmVllHFTMzKwyDipmZlYZBxUzM6uMg4qZmVXGQcXMzCrjoGJmZpVxUDEzs8o4qJiZWWUcVMzMrDIOKmZmVhkHFTMzq4yDipmZVcZBxczMKuOgYmZmlWlrUJG0k6RrJN0v6T5Jb5O0i6S5kpbm+86l+c+S1CVpiaSjSumHSFqU0y6UpEzfWtLVmX6rpNHtrI+ZmXWv3S2VC4AfR8SbgQOB+4BpwLyIGAvMy3Ek7QdMBvYHJgIXSRqUy7kYOBUYm6+JmT4VWBcRY4DzgfPaXB8zM+tG24KKpKHAu4FLASLihYh4ApgEzMzZZgLH5vAk4KqIeD4iHgS6gMMk7Q7sGBHzIyKAy+ry1JZ1DTCh1ooxM7O+186Wyt7AGuD/SbpT0rckbQeMiIhHc56VwIgcHgksK+Vfnmkjc7g+faM8EbEBeBIYVl8QSadJWihp4Zo1ayqpnJmZvVo7g8pg4GDg4oh4K/AM2dVVky2PaGMZauu5JCLGRcS44cOHt3t1ZmYDVjuDynJgeUTcmuPXUASZVdmlRb6vzukrgD1K+Udl2oocrk/fKI+kwcBQYG3lNTEzs5a0LahExEpgmaR9M2kCcC8wG5iSaVOA63N4NjA5r+jam+KE/ILsKlsvaXyeLzmpLk9tWccBN2brx8zM+sHgNi//08B/SdoKeAA4hSKQzZI0FXgYOAEgIhZLmkUReDYAZ0TEi7mc04EZwBBgTr6guAjgckldwOMUV4+ZmVk/aWtQiYi7gHENJk1oMv90YHqD9IXAAQ3SnwOO38ximplZRfyPejMzq4yDipmZVcZBxczMKuOgYmZmlXFQMTOzyjiomJlZZRxUzMysMg4qZmZWGQcVMzOrjIOKmZlVxkHFzMwq46BiZmaVcVAxM7PKOKiYmVllHFTMzKwyDipmZlYZBxUzM6uMg4qZmVXGQcXMzCrjoGJmZpVpa1CR9JCkRZLukrQw03aRNFfS0nzfuTT/WZK6JC2RdFQp/ZBcTpekCyUp07eWdHWm3yppdDvrY2Zm3euLlsp7I+KgiBiX49OAeRExFpiX40jaD5gM7A9MBC6SNCjzXAycCozN18RMnwqsi4gxwPnAeX1QHzMza6I/ur8mATNzeCZwbCn9qoh4PiIeBLqAwyTtDuwYEfMjIoDL6vLUlnUNMKHWijEzs77X7qASwM8k3S7ptEwbERGP5vBKYEQOjwSWlfIuz7SROVyfvlGeiNgAPAkMqy+EpNMkLZS0cM2aNZtfKzMza2hwm5f/zohYIWk3YK6k+8sTIyIkRZvLQERcAlwCMG7cuLavz8xsoGprSyUiVuT7auA64DBgVXZpke+rc/YVwB6l7KMybUUO16dvlEfSYGAosLYddTEzs561LahI2k7SDrVh4M+Ae4DZwJScbQpwfQ7PBibnFV17U5yQX5BdZesljc/zJSfV5akt6zjgxjzvYmZm/aCd3V8jgOvyvPlg4DsR8WNJtwGzJE0FHgZOAIiIxZJmAfcCG4AzIuLFXNbpwAxgCDAnXwCXApdL6gIep7h6zMzM+knbgkpEPAAc2CB9LTChSZ7pwPQG6QuBAxqkPwccv9mFNTOzSvgf9WZmVhkHFTMzq4yDipmZVcZBxczMKuOgYmZmlWkpqEj6H+0uiJmZdb5WWyoXSVog6XRJQ9taIjMz61gtBZWIeBfwMYpbotwu6TuS3t/WkpmZWcdp+ZxKRCwFvgCcCbwHuFDS/ZL+ol2FMzOzztLqOZU/lXQ+cB9wJPChiHhLDp/fxvKZmVkHafU2Lf8X+BZwdkT8oZYYEY9I+kJbSmZmZh2n1aDyQeAPtRs8StoC2CYino2Iy9tWOjMz6yitnlP5GcUdgmu2zTQzM7OXtRpUtomIp2sjObxte4pkZmadqtWg8oykg2sjkg4B/tDN/GZmNgC1ek7ls8B3JT0CCPgT4CNtK5WZmXWkloJKRNwm6c3Avpm0JCL+2L5imZlZJ+rNkx8PBUZnnoMlERGXtaVUZmbWkVoKKpIuB/YB7gJqz40PwEHFzMxe1mpLZRywX0REOwtjZmadrdWrv+6hODnfa5IGSbpT0g05voukuZKW5vvOpXnPktQlaYmko0rph0halNMulKRM31rS1Zl+q6TRm1JGMzOrRqtBZVfgXkk/kTS79mox72co7hlWMw2YFxFjgXk5jqT9gMnA/sBEitvtD8o8FwOnAmPzNTHTpwLrImIMxT3IzmuxTGZm1gatdn+dsykLlzSK4hYv04G/z+RJwBE5PBO4ieLOx5OAqyLieeBBSV3AYZIeAnaMiPm5zMuAY4E5madWtmuAr0mSu+nMzPpHq89T+QXwELBlDt8G3NFC1q8CnwdeKqWNiIhHc3glMCKHRwLLSvMtz7SROVyfvlGeiNgAPAkMqy+EpNMkLZS0cM2aNS0U28zMNkWrt74/laIl8I1MGgl8v4c8xwCrI+L2ZvNki6LtrYqIuCQixkXEuOHDh7d7dWZmA1ar51TOAN4BrIeXH9i1Ww953gF8OLuvrgKOlHQFsErS7gD5vjrnX0HxZMmaUZm2Iofr0zfKI2kwMBRY22KdzMysYq0Glecj4oXaSP6Ad9vCiIizImJURIymOAF/Y0T8FTAbmJKzTQGuz+HZwOS8omtvihPyC7KrbL2k8XnV10l1eWrLOi7X4fMpZmb9pNUT9b+QdDYwJJ9Nfzrwg01c57nALElTgYeBEwAiYrGkWcC9wAbgjNrzW3J9Myhuvz8nXwCXApfnSf3HKYKXmZn1k1aDyjSKy3cXAZ8AfkTxJMiWRMRNFFd5ERFrgQlN5ptOcaVYffpC4IAG6c8Bx7daDjMza69Wbyj5EvDNfJmZmTXU6r2/HqTBOZSIeGPlJTIzs47Vm3t/1WxD0eW0S/XFMTOzTtbqnx/Xll4rIuKrFP+UNzMze1mr3V8Hl0a3oGi59OZZLGZmNgC0Ghj+ozS8geKWLSdUXhozM+torV799d52F8TMzDpfq91ff9/d9Ij4SjXFMTOzTtabq78OpbgtCsCHgAXA0nYUyszMOlOrQWUUcHBEPAUg6Rzgh3kvLzMzM6D1G0qOAF4ojb/AK89BMTMzA1pvqVwGLJB0XY4fS/HURjMzs5e1evXXdElzgHdl0ikRcWf7imVmZp2o1e4vgG2B9RFxAbA8n3liZmb2slYfJ/xF4EzgrEzaEriiXYUyM7PO1GpL5c+BDwPPAETEI8AO7SqUmZl1plaDygv5mN4AkLRd+4pkZmadqtWgMkvSN4CdJJ0K/Aw/sMvMzOq0evXXl/PZ9OuBfYF/joi5bS2ZmZl1nB5bKpIGSfp5RMyNiH+MiH9oJaBI2kbSAkl3S1os6UuZvoukuZKW5vvOpTxnSeqStETSUaX0QyQtymkXSlKmby3p6ky/VdLoTdkIZmZWjR6DSkS8CLwkaWgvl/08cGREHAgcBEyUNB6YBsyLiLHAvBxH0n7AZGB/YCJwkaRBuayLgVOBsfmamOlTgXURMQY4Hzivl2U0M7MKtfqP+qeBRZLmkleAAUTE3zbLkCf2n87RLfMVwCTgiEyfCdxEcbnyJOCqiHgeeFBSF3CYpIeAHSNiPoCkyyj+0T8n85yTy7oG+Jok5brNzKyPtRpUvpevXsmWxu3AGOA/I+JWSSMi4tGcZSWv3ENsJDC/lH15pv0xh+vTa3mWAUTEBklPAsOAx3pbVjMz23zdBhVJe0bE7yNik+7zlV1nB0naCbhO0gF100NS21sVkk4DTgPYc8892706M7MBq6dzKt+vDUi6dlNXEhFPAD+nOBeyStLuuczdgdU52wpgj1K2UZm2Iofr0zfKI2kwMBRY22D9l0TEuIgYN3z48E2thpmZ9aCnoKLS8Bt7s2BJw7OFgqQhwPuB+yke9DUlZ5sCXJ/Ds4HJeUXX3hQn5BdkV9l6SePzqq+T6vLUlnUccKPPp5iZ9Z+ezqlEk+FW7A7MzPMqWwCzIuIGSb+m+DPlVOBh4ASAiFgsaRZwL7ABOCO7zwBOB2YAQyhO0M/J9EuBy/Ok/uMUV4+ZmVk/6SmoHChpPUWLZUgOk+MRETs2yxgRvwHe2iB9LTChSZ7pwPQG6QuBAxqkPwcc30MdzMysj3QbVCJiUHfTzczMynrzPBUzM7NuOaiYmVllHFTMzKwyDipmZlYZBxUzM6uMg4qZmVXGQcXMzCrjoGJmZpVxUDEzs8o4qJiZWWUcVMzMrDIOKmZmVhkHFTMzq4yDipmZVcZBxczMKuOgYmZmlXFQMTOzyjiomJlZZRxUzMysMm0LKpL2kPRzSfdKWizpM5m+i6S5kpbm+86lPGdJ6pK0RNJRpfRDJC3KaRdKUqZvLenqTL9V0uh21cfMzHrWzpbKBuBzEbEfMB44Q9J+wDRgXkSMBeblODltMrA/MBG4SNKgXNbFwKnA2HxNzPSpwLqIGAOcD5zXxvqYmVkP2hZUIuLRiLgjh58C7gNGApOAmTnbTODYHJ4EXBURz0fEg0AXcJik3YEdI2J+RARwWV2e2rKuASbUWjFmZtb3+uScSnZLvRW4FRgREY/mpJXAiBweCSwrZVueaSNzuD59ozwRsQF4EhjWYP2nSVooaeGaNWsqqJGZmTXS9qAiaXvgWuCzEbG+PC1bHtHuMkTEJRExLiLGDR8+vN2rMzMbsNoaVCRtSRFQ/isivpfJq7JLi3xfnekrgD1K2Udl2oocrk/fKI+kwcBQYG31NTEzs1a08+ovAZcC90XEV0qTZgNTcngKcH0pfXJe0bU3xQn5BdlVtl7S+FzmSXV5ass6DrgxWz9mZtYPBrdx2e8ATgQWSbor084GzgVmSZoKPAycABARiyXNAu6luHLsjIh4MfOdDswAhgBz8gVF0LpcUhfwOMXVY2Zm1k/aFlQi4pdAsyuxJjTJMx2Y3iB9IXBAg/TngOM3o5hmZlYh/6PezMwq46BiZmaVcVAxM7PKOKiYmVllHFTMzKwyDipmZlYZBxUzM6uMg4qZmVXGQcXMzCrjoGJmZpVxUDEzs8o4qJiZWWUcVMzMrDIOKmZmVhkHFTMzq4yDipmZVcZBxczMKuOgYmZmlXFQMTOzyjiomJlZZdoWVCR9W9JqSfeU0naRNFfS0nzfuTTtLEldkpZIOqqUfoikRTntQknK9K0lXZ3pt0oa3a66mJlZa9rZUpkBTKxLmwbMi4ixwLwcR9J+wGRg/8xzkaRBmedi4FRgbL5qy5wKrIuIMcD5wHltq4mZmbWkbUElIm4GHq9LngTMzOGZwLGl9Ksi4vmIeBDoAg6TtDuwY0TMj4gALqvLU1vWNcCEWivGzMz6R1+fUxkREY/m8EpgRA6PBJaV5lueaSNzuD59ozwRsQF4EhjWaKWSTpO0UNLCNWvWVFEPMzNroN9O1GfLI/poXZdExLiIGDd8+PC+WKWZ2YDU10FlVXZpke+rM30FsEdpvlGZtiKH69M3yiNpMDAUWNu2kpuZWY/6OqjMBqbk8BTg+lL65Lyia2+KE/ILsqtsvaTxeb7kpLo8tWUdB9yYrR8zM+sng9u1YElXAkcAu0paDnwROBeYJWkq8DBwAkBELJY0C7gX2ACcEREv5qJOp7iSbAgwJ18AlwKXS+qiuCBgcrvqYmatGz3thy8PP3TuB/uxJNYf2hZUIuKjTSZNaDL/dGB6g/SFwAEN0p8Djt+cMpqZWbX8j3ozM6uMg4qZmVXGQcXMzCrjoGJmZpVxUDEzs8o4qJhZxxo97YcbXcJs/c9BxczMKuOgYmZmlXFQMTOzyjiomJlZZdp2m5bXI9/TyMyse26pmJlZZdxSMbMBx70O7eOWipmZVcYtFTOzBtya2TQOKtaxXm9f+tdbfWxgclAxM9tEzQ4EBvIBgoOKmdlrUKcGJgcVswGuU3+8OkVPN7xs1sLpVA4qZmb9qJVA0ttg058HBx0fVCRNBC4ABgHfiohz+7lIlnwEbL1VxT6zOct4PbQUoH/r0dFBRdIg4D+B9wPLgdskzY6Ie/u3ZNaJHAT7Tqdt61bK+3oJSJuro4MKcBjQFREPAEi6CpgEDNig0tudf3PmqUJ//LhUdST7Wrrap93lavSDWVU9m/0YN0tvtN7eLqO382zO/AONIqK/y7DJJB0HTIyIj+f4icDhEfGpuvlOA07L0X2BJZu4yl2BxzYxb6dynQcG13lg2Jw67xURw3uaqdNbKi2JiEtCDKd6AAAF10lEQVSASzZ3OZIWRsS4CorUMVzngcF1Hhj6os6dfu+vFcAepfFRmWZmZv2g04PKbcBYSXtL2gqYDMzu5zKZmQ1YHd39FREbJH0K+AnFJcXfjojFbVzlZnehdSDXeWBwnQeGtte5o0/Um5nZa0und3+ZmdlriIOKmZlVxkGlAUkTJS2R1CVpWoPpknRhTv+NpIP7o5xVaqHOH8u6LpL0K0kH9kc5q9RTnUvzHSppQ/4vqqO1UmdJR0i6S9JiSb/o6zJWqYX9eqikH0i6O+t7Sn+Us0qSvi1ptaR7mkxv7+9XRPhVelGc8P8d8EZgK+BuYL+6eT4AzAEEjAdu7e9y90Gd3w7snMNHD4Q6l+a7EfgRcFx/l7sPPuedKO5IsWeO79bf5W5zfc8Gzsvh4cDjwFb9XfbNrPe7gYOBe5pMb+vvl1sqr/byrV8i4gWgduuXsknAZVGYD+wkafe+LmiFeqxzRPwqItbl6HyK/wR1slY+Z4BPA9cCq/uycG3SSp3/EvheRPweICI6ud6t1DeAHSQJ2J4iqGzo22JWKyJupqhHM239/XJQebWRwLLS+PJM6+08naS39ZlKcaTTyXqss6SRwJ8DF/dhudqplc/5TcDOkm6SdLukk/qsdNVrpb5fA94CPAIsAj4TES/1TfH6TVt/vzr6fyrW9yS9lyKovLO/y9IHvgqcGREvFQeyA8Jg4BBgAjAE+LWk+RHx2/4tVtscBdwFHAnsA8yVdEtErO/fYnUuB5VXa+XWL6+328O0VB9Jfwp8Czg6Itb2UdnapZU6jwOuyoCyK/ABSRsi4vt9U8TKtVLn5cDaiHgGeEbSzcCBQCcGlVbqewpwbhQnG7okPQi8GVjQN0XsF239/XL316u1cuuX2cBJeRXFeODJiHi0rwtaoR7rLGlP4HvAia+To9Ye6xwRe0fE6IgYDVwDnN7BAQVa27evB94pabCkbYHDgfv6uJxVaaW+v6dolSFpBMVdzB/o01L2vbb+frmlUiea3PpF0idz+tcprgT6ANAFPEtxtNOxWqzzPwPDgIvyyH1DdPAdXlus8+tKK3WOiPsk/Rj4DfASxdNUG16a+lrX4mf8L8AMSYsoroY6MyI6+nb4kq4EjgB2lbQc+CKwJfTN75dv02JmZpVx95eZmVXGQcXMzCrjoGJmZpVxUDEzs8o4qJiZWWUcVMwakPR03fjJkr7WQ54e58n5rsy7w/5dN/McIemGJulP5l2E75P0xZ7WZ9aX/D8Vsz4k6U+AQyNizGYs5paIOEbSdsBdkn4QEXe0sO7BEdHRN0u01z63VMx6SdJwSddKui1f72gwzwxJX5e0UNJvJR2Tk34KjMyWxrvyxo3jMs+ukh5qtRx5K5XbgTGSBkn69yzPbyR9Ipd5hKRbJM2muKU9kk7Kee6WdPnmbQ2zjbmlYtbYEEl3lcZ34ZVbfFwAnB8Rv8zb1/yE4k639UZT3H59H+DnksYAHwZuiIiDADbnRpWShlE8D+NfKG7y+WREHCppa+C/Jf00Zz0YOCAiHpS0P/AF4O0R8ZikXTa5AGYNOKiYNfaH2g8/FOdLKG4wCfA+YL9SQNhR0vYNljErb6O+VNIDFDcqfKKCsr1L0p0Ut1E5N2898iXgT/XK0ymHAmOBF4AFEfFgph8JfLd2K5KI6O65G2a95qBi1ntbAOMj4rlyYoNWR/09kBrdE2kDr3RDb9Pi+m+JiGPq0gR8OiJ+UlemI4BnWlyu2WbzORWz3vspxRMhAZB0UJP5jpe0haR9KB5pu6TBPA9RPL8E4LgG01v1E+BvJG2ZZXpTnsivd2OWa1jO5+4vq5SDilnv/S0wLk923wt8ssl8v6d4Lscc4JP1LZv0ZYpgcCfFM1s21bcoTsTfIeke4Bs06ImIiMXAdOAXku4GvrIZ6zR7Fd+l2KwNJM2gOCF/TX+XxawvuaViZmaVcUvFzMwq45aKmZlVxkHFzMwq46BiZmaVcVAxM7PKOKiYmVll/j8RmscLs/GYqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a41546ad30>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig3 = plt.figure()\n",
    "ax3 = fig3.add_subplot(1, 1, 1)\n",
    "n, bins, patches = ax3.hist(x=df['helpful_perc'], bins='auto')\n",
    "                                 \n",
    "ax3.set_xlabel('Helpful Perc')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('Histogram of Helpful Percentages of Subsetted Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the sampled data visually matches the distribution of the original dataset. We can confirm the distributions are identical with the Kolmogorov-Smirnov statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.0018642270739226974, pvalue=0.9944665853896963)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "df_sampled_helpful_prec = df_sampled['helpful_perc']\n",
    "df_helpful_perc = df['helpful_perc']\n",
    "\n",
    "ks_2samp(df_sampled_helpful_prec, df_helpful_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_sampled becomes our df\n",
    "df = df_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Every Review is Helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic model we can produce is to label each review as being helpful if it meets a certain helpful_perc threshold. We choose 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every Review is Helpful Accuracy Score ->  79.21125\n"
     ]
    }
   ],
   "source": [
    "# calculate total number of reviews\n",
    "total_reviews = len(df)\n",
    "\n",
    "# calculate total number of reviews that are at least 75% helpful\n",
    "helpful_reviews = len(df[df.helpful_perc >= 0.75])\n",
    "\n",
    "# calculate accuracy if we predicted each review is at least 75% helpful\n",
    "accuracy_1 = 100*(helpful_reviews/total_reviews)\n",
    "\n",
    "print(\"Every Review is Helpful Accuracy Score -> \", accuracy_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model would produce an accuracy score of 79.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Naive Bayes Bag of Words with Binary Helpfulness Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more sophisticated model is one where we estimate the hepfulness of a review using its text. We use a Bag of Words model to determine whether a review is helpful or not. We again define a helpful review as one whose helpfulness percentage is at least 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# this nltk download may be needed. download stopwords, punkt\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure there are no missing values in the review or summary text or the overall helpullness percentage\n",
    "len(df) == len(df.dropna(subset=['reviewText', 'summary', 'helpful_perc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our bag of words model, we will combine the reviewText and summary text fields to combine into a single \"document\" with which to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize(text):\n",
    "    return [word for word in word_tokenize(text) if not word in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We should then tokenize and stem the review data before ingesting into our NLP models\n",
    "df['combinedText'] = df['summary'].str.lower() + \". \" +  df['reviewText'].str.lower()\n",
    "\n",
    "# Now tokenize these and remove stop words\n",
    "df['processedText'] = df['combinedText'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new column for helpful reviews (reviews with at least a 75% helpfulness rating)\n",
    "\n",
    "df[\"isHelpful\"] = df[\"helpful_perc\"] > .75\n",
    "df[\"isHelpful\"] = df[\"isHelpful\"].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>helpful_perc</th>\n",
       "      <th>combinedText</th>\n",
       "      <th>processedText</th>\n",
       "      <th>isHelpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106615</th>\n",
       "      <td>A1FNLY02ZH11MW</td>\n",
       "      <td>B00E58P7ME</td>\n",
       "      <td>J. VanGoethem</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>Yes, it costs too much for a $.25 worth of met...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Does the job</td>\n",
       "      <td>1315699200</td>\n",
       "      <td>09 11, 2011</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>does the job. yes, it costs too much for a $.2...</td>\n",
       "      <td>[job, ., yes, ,, costs, much, $, .25, worth, m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61951</th>\n",
       "      <td>A22MANL4US4RMY</td>\n",
       "      <td>B001V4VMRO</td>\n",
       "      <td>Book Carpenter</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>This cover is a nice, tight fit, and it seems ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Good Fit, Good Construction</td>\n",
       "      <td>1314144000</td>\n",
       "      <td>08 24, 2011</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>good fit, good construction. this cover is a n...</td>\n",
       "      <td>[good, fit, ,, good, construction, ., cover, n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119108</th>\n",
       "      <td>A3NT7RAITJZXXT</td>\n",
       "      <td>B000GX4CKA</td>\n",
       "      <td>Linda \"cooking enthusiast\"</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>While this is a good shelf for the price it wo...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No instructions included</td>\n",
       "      <td>1279929600</td>\n",
       "      <td>07 24, 2010</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no instructions included. while this is a good...</td>\n",
       "      <td>[instructions, included, ., good, shelf, price...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15628</th>\n",
       "      <td>A1VB2KE2PR4J4W</td>\n",
       "      <td>B0000CFNQX</td>\n",
       "      <td>J. J. Emmel</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>It's made in China, a tad small, but not bad f...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>not bad for made in China</td>\n",
       "      <td>1329177600</td>\n",
       "      <td>02 14, 2012</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>not bad for made in china. it's made in china,...</td>\n",
       "      <td>[bad, made, china, ., 's, made, china, ,, tad,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99353</th>\n",
       "      <td>A2QFO64UAU5N18</td>\n",
       "      <td>B008R3ER0Q</td>\n",
       "      <td>W. Lucas \"wvl\"</td>\n",
       "      <td>[2, 4]</td>\n",
       "      <td>This thing is very weak on the suction. I read...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Must have gotten a bad one, because</td>\n",
       "      <td>1388361600</td>\n",
       "      <td>12 30, 2013</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>must have gotten a bad one, because. this thin...</td>\n",
       "      <td>[must, gotten, bad, one, ,, ., thing, weak, su...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin                reviewerName helpful  \\\n",
       "106615  A1FNLY02ZH11MW  B00E58P7ME               J. VanGoethem  [3, 4]   \n",
       "61951   A22MANL4US4RMY  B001V4VMRO              Book Carpenter  [2, 3]   \n",
       "119108  A3NT7RAITJZXXT  B000GX4CKA  Linda \"cooking enthusiast\"  [2, 2]   \n",
       "15628   A1VB2KE2PR4J4W  B0000CFNQX                 J. J. Emmel  [3, 4]   \n",
       "99353   A2QFO64UAU5N18  B008R3ER0Q              W. Lucas \"wvl\"  [2, 4]   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "106615  Yes, it costs too much for a $.25 worth of met...      4.0   \n",
       "61951   This cover is a nice, tight fit, and it seems ...      5.0   \n",
       "119108  While this is a good shelf for the price it wo...      3.0   \n",
       "15628   It's made in China, a tad small, but not bad f...      3.0   \n",
       "99353   This thing is very weak on the suction. I read...      1.0   \n",
       "\n",
       "                                    summary  unixReviewTime   reviewTime  \\\n",
       "106615                         Does the job      1315699200  09 11, 2011   \n",
       "61951           Good Fit, Good Construction      1314144000  08 24, 2011   \n",
       "119108             No instructions included      1279929600  07 24, 2010   \n",
       "15628             not bad for made in China      1329177600  02 14, 2012   \n",
       "99353   Must have gotten a bad one, because      1388361600  12 30, 2013   \n",
       "\n",
       "        helpful_votes  total_votes  helpful_perc  \\\n",
       "106615              3            4      0.750000   \n",
       "61951               2            3      0.666667   \n",
       "119108              2            2      1.000000   \n",
       "15628               3            4      0.750000   \n",
       "99353               2            4      0.500000   \n",
       "\n",
       "                                             combinedText  \\\n",
       "106615  does the job. yes, it costs too much for a $.2...   \n",
       "61951   good fit, good construction. this cover is a n...   \n",
       "119108  no instructions included. while this is a good...   \n",
       "15628   not bad for made in china. it's made in china,...   \n",
       "99353   must have gotten a bad one, because. this thin...   \n",
       "\n",
       "                                            processedText  isHelpful  \n",
       "106615  [job, ., yes, ,, costs, much, $, .25, worth, m...          0  \n",
       "61951   [good, fit, ,, good, construction, ., cover, n...          0  \n",
       "119108  [instructions, included, ., good, shelf, price...          1  \n",
       "15628   [bad, made, china, ., 's, made, china, ,, tad,...          0  \n",
       "99353   [must, gotten, bad, one, ,, ., thing, weak, su...          0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's make sure everything looks ok\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram of Helpful/Not Helpful Reviews')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAETCAYAAADKy1riAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAcCklEQVR4nO3de5QkZZnn8W91VwOiBTZDeQcZb8/M\nQQUBBUSkUQRR2HbUGREZBcbb2MigqAyKgLNeUGkcWXFQFBCPzq6CqKgNuHKx5SJyaRXBhwVF58zo\nWLSNFIJAd9f+EVGSFFlZb1ZVZN2+n3P6dGbkG5HvW5EZv3gjIt/oGxkZQZKkEotmugKSpLnD0JAk\nFTM0JEnFDA1JUjFDQ5JUzNCQJBXrn+kKaHpExAgwmJl3tEw7FHh1Zh4QEf8C3JqZ53RYxvHAjzPz\nG41XeJpFxI7AecCdwKsy8/aW1y4DPpWZ57ZM2w64MTMfNcFyz67LndyhzGLga8BfA6dm5qfGKbes\nrscz6+ePBr4DHAz8EnhjZn6+pfy7gGdm5qET1HHc9TbR52KC5d5el7u2Q5ltgFXAeuAfM/Oqccqd\nCGydmUeMmb6snj9bJg8ANwGHZubaTnXsUK81wLLMvHMy82t8hsYCkZnHFxR7EdWXdS76H8ClmfnG\nGXjvJwL7AY/MzA1dzHcAVWgAbARWRsQPMjM7zNPOTK63vYHfZuY+U1jGbZm54+iTOoTPA94FHDuZ\nBbYuT9PL0FggWveYI+IDwN8A9wNrgUOBVwK7AB+PiA3AJcBpwI7ACNXe4Hszc31EvAz4KLABWAPs\nA7wAWAb8A/BI4A9UG8V/A54O/AUwDBycmVnv/V8H7AY8Bvgs8Dhgr3r+v8vMn7Zpx/uB11Lt2d4C\nHAG8GHgbsDgiHpGZr5vE3+cf6mUsqv8mR2Tmz8eUWQ+cBOxf1/G9wHeBC4ElwHUR8SrgVlr27kf3\n9tu87XLgA/Xje4GVwJcjYvfMvH/Me29Jm/UBvIWW9ZaZ53fZ7k2o1uVewGLgBuDIzLyrpcyyusyv\ngL+q63oo1fr6ILBlRFxat6W1J7Ws9XkXtqD6e13R0vZPAs+i+jt/D3g3cDhwYGYeWJf7q/q1bak+\nH4OZeUe7dQtsBlyQmdvU815EFX5viIhNgf8CngK8kzHflcz8TZftmVc8pzG/XBoRa0b/Af8ytkB9\nOOEo4LmZuQtwMbBrZp4GXAu8u97wnEr1JXkW1UZpB+BdEfEXwBeBQ+q9uUup9rRHbU91WGBvqo3r\nnZm5e2Y+A/gR1Rd21HaZuQdwCPAx4LK6ThcCb29T98PqZT43M58N3AicnZlfAk4H/k+HwPj4mL/N\n6B4+EbEX8AZgz8x8Tl2XdhvfxcA9mbkz8HfAmVQbn5cB92bmjpl52zjvP7YtmwJPz8wbWyZ/CLgb\n+HCbWdqujzbrrZ1On4t/ptrA7pyZO1BtLE9qs4xdgP9V/93PAr6YmZcCxwOr6/U9WU+t6/aziPgd\n1Yb/m8C/1q9/Ariu/rs/B9iaamP+78ALIuJxdbnDgLNae3vjrdvMXAM8EBHPjIhHUIXhi+rZXgz8\nkCq8HvZdmUI75wV7GvPL3u2OXY8p85/Aj4HrI2IVsCozv9dmWfsDe2TmCHBfRJxO9QVK4KbM/DFA\nZn4hIk5tme8no3upmXluRPwiIt4OPI2qJ9J6zPtr9f+jG9oLW54vG6dOZ2XmH+vnnwTeV+8tT+Td\n7c5p1E9fXtfvyogYLbI0IrZqs5xP1W37SUT8FHghVY+pWy+m2jj+WWZujIhDgDX1nm+r8dZHuw38\nWJ0+FwcAjwZeUrd9E+B3bZbx48xcXT8+Ezit3oGYDn8+PFXvGHwY+GpmPtBSx+fVPQaARwBk5nBE\nfA04JCI+AbwO2HPMsjut2/Op/q43Uq2LHSJie6oe4HmUf1cWFHsaC0xmbqQ6FHEo1Z7rJyLiY22K\nLqI6DNL6fAnVXmnfmLIbWx7fPfogIv4R+DxwD/Blqj3D1nnvG1O3B+hscZs69bepT7cWU+0571hv\nvHai2rNe16bs+jHvP945jD748+Gfdl4BPOzEdWb+B9Uhpy9Q7VG3vle79TFVi4F/amn783j4jgY8\ntN2jf++xbR/hoeuiJMwfIjPPouplfDUiRndqFwN/21LHXXmwx3oG8HrgpcDNmfnLMYvstG7Pp+ol\n7kt1mPG7VOem9ge+3sV3ZUExNBaYiNiBas/q5sz8CFXX/7n1y+t5cEN0EXBERPTVh1LeTPWlugJ4\nRkQ8u17eq6j2VNuNfLkf1eGjz1P1UA6k+hJP1oXA4RHxyPr5kcD3M/O+DvOUuAh4bUQ8vn7+Vsb0\nAlq8HiAidqI6pHF5mzJDVBsmqK6MeoiI6AN2pz5mP1bdI1pF1ZNorWO79QEPXW/dGl3uJhGxiGoj\n/JE25XYcXef1e1/Z5sqkIWDbiHhM3caDJlmnY4BtgBUtdXxHS9u/SR0amXk1VVAdX9e9XfvGW7dX\nAk+l6sn8X6rDT0cBt2Tm2gm+KwuWobHA1IeVvgJcGxHXUp1MfGf98jeBj0TEG6g2yI8Bflr/S+BD\nmfl7qhPR50TE9VTBsJ6qNzHWycBbIuInwGrgeqpDBZP1eaov9zURcTPVXmPXJ73HysyLqU70freu\n68HAK+tDQWPtUbf7TOA1mdmuN3Ik1eGb66kuwx174nRX4NoJrrQ6kurEc+vzh62P+rXW9dat/wnc\nTnUC/CaqDfDRbcr9FvhQfUjuFcDfjy2QmTcBn6E6x3I11WXEXavD6BjgAxHxWKq2P5Kq3T+p/2/d\n4z+D6qT119ssa9x1W/ckVgHDmTkE/ADYiurQ1ETflQWrz6HR1Y2I2AI4DjgxM++p97i/DTxhnI3s\nvNHuNw8LwRSugtI85IlwdSUz74qI+4EfRcQDwANUl8fO68CQVLGnIUkq5jkNSVIxQ0OSVGzen9MY\nGhqe9PG3pUs3Z926dhcFzV+2eWGwzfPfVNs7ODjQ9vdP9jQ66O+fyk8K5ibbvDDY5vmvqfYaGpKk\nYoaGJKmYoSFJKmZoSJKKGRqSpGKNXnIbEcdS3YZzE+DTVCOCnk01IuqNwIr6HgInUI17vx44KjOv\niYinlZZtsg2SpAc11tOoBzl7PrAH1Zj02wCnAMdl5p5Uo2kurwe824tq5M+DqG5pSZdlJUk90OTh\nqf2ohjA+H7gA+BawMw/ef2AVD95b+uJ6qOJfA/0RMdhlWUlSDzR5eGpr4MlUNzj5S6ox/xe1jIY6\nDGxJdR/etS3zjU7v66Ls0HiVWLp08yn9yGVwcGDS885VtnlhsM3zXxPtbTI01gI/z8z7gYyIP1Ed\noho1ANwJ3FU/Hjt9YxdlxzXFn9EzNDQ86fnnItvcO4efdEnP31MLxwUrl0/pcz1e4DR5eOoHwEvr\nWzQ+gerOW9+rz3VAdR/e1VS3vNwvIhZFxLZUvZE7gBu6KCtJ6oHGehqZ+a2IeCFwDVU4raC6/eMZ\nEbEJcDNwbmZuiIjVwFUt5aC65WRpWUlSD8z7mzBNZZRbD9UsDB6e0nw0DYenHOVWkjQ1hoYkqZih\nIUkqZmhIkooZGpKkYoaGJKmYoSFJKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRihoYkqZih\nIUkqZmhIkooZGpKkYoaGJKmYoSFJKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRihoYkqZih\nIUkq1t/kwiPiBuAP9dNfAp8BPgmsBy7OzA9ExCLg08AOwH3AGzPz1ojYrbRsk22QJD2osdCIiM0A\nMnNZy7Q1wKuAXwDfjoidgO2AzTJz9zooVgLLgdO7KCtJ6oEmexo7AJtHxMX1+5wIbJqZtwFExEXA\ni4HHAxcCZObVEbFLRGxRWrbB+kuSxmgyNO4BTgY+BzwdWAXc2fL6MPAUYAsePIQFsKGedldJ2Yjo\nz8z141Vi6dLN6e9fPOlGDA4OTHreuco2S/NDE5/rJkPjFuDWzBwBbomIPwBbtbw+QBUim9ePRy2i\nCoyBkrKdAgNg3bp7Jt2AwcEBhoaGJz3/XGSbpfljKp/r8QKnyaunDqc650BEPIFqg//HiHhqRPQB\n+wGrgSuAl9XldgN+mpl3AfeXlG2w/pKkMZrsaXweODsifgCMUIXIRuBLwGKqK6J+GBE/Al4SEVcC\nfcBh9fxv7aKsJKkHGguNzLwfOLjNS7uNKbeRKiDGzn91aVlJUm/44z5JUjFDQ5JUzNCQJBUzNCRJ\nxQwNSVIxQ0OSVMzQkCQVMzQkScUMDUlSMUNDklTM0JAkFTM0JEnFDA1JUjFDQ5JUzNCQJBUzNCRJ\nxQwNSVIxQ0OSVMzQkCQVMzQkScUMDUlSMUNDklTM0JAkFTM0JEnFDA1JUjFDQ5JUzNCQJBXrb3Lh\nEfEY4DrgJcB64GxgBLgRWJGZGyPiBODl9etHZeY1EfG00rJN1l+S9FCN9TQiYgnwGeDeetIpwHGZ\nuSfQByyPiJ2AvYBdgYOA0yZRVpLUI032NE4GTgeOrZ/vDFxeP14F7AskcHFmjgC/joj+iBjspmxm\nDnWqxNKlm9Pfv3jSjRgcHJj0vHOVbZbmhyY+142ERkQcCgxl5kURMRoaffUGH2AY2BLYAljbMuvo\n9G7KdgyNdevumXQ7BgcHGBoanvT8c5FtluaPqXyuxwucpnoahwMjEbEPsCNwDvCYltcHgDuBu+rH\nY6dv7KKsJKlHGjmnkZkvzMy9MnMZsAZ4PbAqIpbVRfYHVgNXAPtFxKKI2BZYlJl3ADd0UVaS1CON\nXj01xtHAGRGxCXAzcG5mboiI1cBVVAG2YhJlJUk90jcyMjJxqTlsaGh40g1ciMe6bXPvHH7SJT1/\nTy0cF6xcPtVzGn3tpvvjPklSsaLDUxHxHeAs4BuZeX+zVZIkzValPY2PAi8FbomI0yLiuQ3WSZI0\nSxX1NDLzcuDyiHgE8GrgvIi4C/gc8G+ZeV+DdZQkzRLF5zTqS2A/BXwYuBA4Engs8M1GaiZJmnVK\nz2n8CvgF1XmNIzLz3nr6ZcC1jdVOkjSrlPY0XgS8JjPPAahHoSUzN2bmTk1VTpI0u5SGxsupDklB\nNRzIBRHx5maqJEmarUpD483AngCZ+SuqUWjf3lSlJEmzU2loLAFar5C6n+oGSZKkBaR07KmvA5dE\nxFeowuJVeNWUJC04RT2NzDwGOBUI4KnAqZl5XJMVkyTNPt2MPXUz8BWqXsfvI+KFzVRJkjRblf5O\n4zTgQOC2lskjVJfiSpIWiNJzGvsCMfqjPknSwlR6eOoXQNux1SVJC0dpT+P3wE0RcSXwp9GJmXl4\nI7WSJM1KpaFxIQ/+IlyStECVDo3+hYjYDtgeuAjYJjN/2WTFJEmzT9E5jYh4DXAB8ElgK+CqiDik\nyYpJkmaf0hPhxwDPB4Yz83fAc4BjG6uVJGlWKg2NDZk5PPokM38DbGymSpKk2ar0RPjPIuIIYElE\n7Ai8DVjTXLUkSbNRaU9jBfBE4F7gTOAuquCQJC0gpVdP/ZHqHIbnMSRpASsde2ojD79/xm8y80nT\nXyVJ0mxV2tP482GsiFgCvALYvdM8EbEYOINqOPUNwGFUQ5GcTRVANwIrMnNjRJxAdUvZ9cBRmXlN\nfR/yorLFrZUkTUk3Q6MDkJkPZOZXmXiE2wPr8nsAxwOn1P+Oy8w9qQJkeUTsBOwF7AocBJxWz99N\nWUlSD5Qennp9y9M+ql+GP9Bpnsz8ekR8q376ZOC/qXoIl9fTVlGNnpvAxZk5Avw6IvojYpDqPuRF\nZTNzqKQdkqSpKb3kdu+WxyPAHcBrJpopM9dHxBeAvwFeDRxQb/ABhoEtgS2AtS2zjU7v66LsuKGx\ndOnm9Pcvnqiq4xocHJj0vHOVbZbmhyY+16XnNA6b7Btk5hsi4hjgh8AjWl4aAO6kunx3oM30jV2U\nHde6dfdMtuoMDg4wNDQ8ccF5xDZL88dUPtfjBU7p4alf8vCrp6A6VDWSmU9pM8/fA0/KzI8A91CF\nwLURsSwzLwP2By4FbgU+FhEnA08CFmXmHRFxQ2nZkjZIkqau9PDUl4H7qK6GegB4HfBc4H0d5vka\ncFZEfB9YAhxFdZ/xMyJik/rxuZm5ISJWA1dRnZhfUc9/dBdlJUk90Dcy0q4D8VARcW1m7jJm2nWZ\nuXNjNZsmQ0PDEzdwHAvxsIVt7p3DT7qk5++pheOClcuneniq7d1aSy+57YuIfUafRMQBVOcXJEkL\nSOnhqTcD50TE46jObfwceENjtZIkzUqlV09dB2wfEVsD99ZjUUmSFpjSO/c9OSK+S3UCeiAiLqlv\n/ypJWkBKz2l8Bvg4cDfVL7v/HTinqUpJkman0tDYOjMvBsjMkcw8g+rX2ZKkBaQ0NO6NiCdR/8Av\nIl5A9bsNSdICUnr11DuAbwFPjYg1wFbA3zZWK0nSrFQaGo+l+gX4M4DFwM8z8/7GaiVJmpVKQ+Nj\nmflt4GdNVkaSNLuVhsZtEXEm1Ui1945OzEyvoJKkBaTjifCIeGL9cC3ViLa7Ud1bY29gWaM1kyTN\nOhP1NC4AdsrMwyLi6Mxc2YtKSZJmp4kuuW0d5fB1TVZEkjT7TRQarcOKtx0mV5K0cJT+uA/a37lP\nkrSATHROY/uI+EX9+Iktj8e9zaskaf6aKDSe0ZNaSJLmhI6hkZm/6lVFJEmzXzfnNCRJC5yhIUkq\nZmhIkooZGpKkYoaGJKmYoSFJKmZoSJKKGRqSpGKlN2HqSkQsAc4EtgM2BT4I3AScTTWG1Y3Aiszc\nGBEnAC8H1gNHZeY1EfG00rJN1F+S1F5TPY1DgLWZuSewP/Ap4BTguHpaH7A8InYC9gJ2BQ4CTqvn\n76asJKlHGulpAF8Fzm15vh7YGbi8fr4K2BdI4OLMHAF+HRH9ETHYTdnMHGqoDRx49DeaWrQkzUmN\nhEZm3g0QEQNU4XEccHK9wQcYBrYEtqC6lSxjpvd1UbZjaCxdujn9/Yun1B5JmosGBwemfZlN9TSI\niG2A84FPZ+aXI+JjLS8PAHcCd9WPx07f2EXZjtatu2dS9ZekuW5oaHjS844XOI2c04iIxwIXA8dk\n5pn15BsiYln9eH9gNXAFsF9ELIqIbYFFmXlHl2UlST3SVE/jvcBS4P0R8f562j8Bp0bEJsDNwLmZ\nuSEiVgNXUQXYirrs0cAZhWUlST3SNzIyv+/iOjQ0POkGHn7SJdNZFUnqmQtWLp/q4am+dtP9cZ8k\nqZihIUkqZmhIkooZGpKkYoaGJKmYoSFJKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRihoYk\nqZihIUkqZmhIkooZGpKkYoaGJKmYoSFJKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRihoYk\nqZihIUkqZmhIkor1N7nwiNgV+GhmLouIpwFnAyPAjcCKzNwYEScALwfWA0dl5jXdlG2y/pKkh2qs\npxER7wE+B2xWTzoFOC4z9wT6gOURsROwF7ArcBBw2iTKSpJ6pMmexm3AK4Ev1s93Bi6vH68C9gUS\nuDgzR4BfR0R/RAx2UzYzhzpVYunSzenvXzyd7ZKkOWFwcGDal9lYaGTmeRGxXcukvnqDDzAMbAls\nAaxtKTM6vZuyHUNj3bp7JtsESZrThoaGJz3veIHTyxPhG1seDwB3AnfVj8dO76asJKlHehkaN0TE\nsvrx/sBq4Apgv4hYFBHbAosy844uy0qSeqTRq6fGOBo4IyI2AW4Gzs3MDRGxGriKKsBWTKKsJKlH\n+kZGRiYuNYcNDQ1PuoGHn3TJdFZFknrmgpXLp3pOo6/ddH/cJ0kqZmhIkooZGpKkYoaGJKmYoSFJ\nKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRihoYkqZihIUkqZmhIkooZGpKkYoaGJKmYoSFJ\nKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRihoYkqZihIUkqZmhIkor1z3QFuhURi4BPAzsA\n9wFvzMxbZ7ZWkrQwzMWexiuAzTJzd+CfgZUzXB9JWjDmYmi8ALgQIDOvBnaZ2epI0sIx5w5PAVsA\nf2h5viEi+jNzfbvCg4MDfZN9owtWLp/srJI04wYHB6Z9mXOxp3EX0PqXWDReYEiSptdcDI0rgJcB\nRMRuwE9ntjqStHDMxcNT5wMviYgrgT7gsBmujyQtGH0jIyMzXQdJ0hwxFw9PSZJmiKEhSSpmaEiS\nis3FE+HTbqKhSSLiTcBbgPXABzPzWzNS0WlS0N53AAfVT7+TmR/ofS2nV8nwM3WZbwPfyMzTe1/L\n6VWwnvcHTqifXg+syMw5fZKzoM3vAl4LbAQ+nJnnz0hFGxARuwIfzcxlY6YfCBxPtf06MzPPmMr7\n2NOojDs0SUQ8DjgS2APYD/hIRGw6I7WcPp3a+xTgdcDzgd2BfSPi2TNSy+lVMvzMB4GtelqrZnVa\nzwPAx4EDMnM34HZg65mo5DTr1OZHU32Xdwf2Bf51RmrYgIh4D/A5YLMx05cAn6Bq717Am+tt2qQZ\nGpVOQ5M8D7giM+/LzD8AtwJzfSPaqb3/Abw0Mzdk5kZgCfCn3ldx2nUcfiYiXk2197mq91VrTKc2\nP5/qN04rI2I18N+ZOdT7Kk67Tm3+I/Ar4JH1v409r11zbgNe2Wb6XwO3Zua6zLwf+AGw51TeyNCo\ntB2aZJzXhoEte1Wxhozb3sx8IDPviIi+iDgZuCEzb5mRWk6vcdscEc8EDqbqws8nnT7XWwN7A8cA\n+wNHRcQzely/JnRqM1Q7RTdRHY47tZcVa1Jmngc80Oalad9+GRqVTkOTjH1tALizVxVrSMehWCJi\nM+BLdZm39bhuTenU5tcDTwQuAQ4F3hkRL+1t9RrRqc1rgR9l5m8z827g+8COva5gAzq1eX/g8cBf\nAtsCr4iI5/W4fr027dsvQ6PSaWiSa4A9I2KziNiSqrt3Y++rOK3GbW9E9AHfAH6cmW/JzA0zU8Vp\nN26bM/M9mblrfQLxbOCUzLxwJio5zTp9rq8DnhkRW9d74rtR7YHPdZ3avA64F7gvM/9EtfF8dM9r\n2Fs3A0+PiK0iYhPghcBVU1mgV09VHjY0SUS8k+pY4Dcj4lRgNVXIvq/+wM1l47YXWEx1wmzT+uoa\ngGMzc0oftFmg4zqe2ao1ZqLP9bHARXXZr2TmXN8ZgonbvA9wdURspDq+/90ZrGtjIuJg4FGZ+dm6\n/RdRbb/OzMz/nMqyHUZEklTMw1OSpGKGhiSpmKEhSSpmaEiSihkakqRihoY0SRGxXUTc3mb6uJck\nRsSyiLhsguVuGxEZEWvqMaLalTk0Is7ursbS1Pk7DWn2WQZcl5kHz3RFpLEMDakBEbGYahTZZVQ/\nmDw7Mz8xpsxlwBqqX+luBhwF/I5qtN1HRcTpwG8BMvPEep7b62VKM8LQkKbmCRGxps30NwFk5k71\nUPoXRcS1bcptUZfZkWqE3SdTDZy4LDPfGhEnNlVxaTIMDWlq/iszHzLQX31OYx9gx4h4UT35UcCz\nePj4TmcAZOaaiPgNc3/Yfc1zhobUjMXAezLzawARsTVwN9XAgK3WtzxeNOY5wAgPvWBlyTTXU+qK\nV09JzbgEeFNELImIR1ENjjc2MKC+rW5E7AIs5aGjsgLcAWxfl3ke1dDe0owxNKRmnA78P+AG4Frg\nrMy8rE25p0TE9cBngde0GYr+fwNbRcRNwNvr5UkzxlFupRlSXz114jhhIs1K9jQkScXsaUiSitnT\nkCQVMzQkScUMDUlSMUNDklTM0JAkFfv/S/1T7Rt/GsAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take a look at distribution of Helpful/Not Helpful\n",
    "\n",
    "fig4 = plt.figure()\n",
    "ax4 = fig4.add_subplot(1, 1, 1)\n",
    "n, bins, patches = ax4.hist(x=df['isHelpful'], bins=2)\n",
    "                                 \n",
    "ax4.set_xlabel('Helpful')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title('Histogram of Helpful/Not Helpful Reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "data = df[['combinedText', 'isHelpful']]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "preprocessed_data = data.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-33ae99ce0175>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m Train_X, Test_X, Train_Y, Test_Y = train_test_split(preprocessed_data['combinedText'], \n\u001b[0m\u001b[0;32m      4\u001b[0m                                                     \u001b[0mpreprocessed_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'isHelpful'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                     test_size=0.2)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessed_data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(preprocessed_data['combinedText'], \n",
    "                                                    preprocessed_data['isHelpful'],\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Accuracy Score ->  74.76875\n"
     ]
    }
   ],
   "source": [
    "# and train our classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "g_classifier = GaussianNB().fit(np.array(Train_X.values.tolist()).reshape(-1, 1), Train_Y)\n",
    "accuracy_2 = accuracy_score(Test_Y, g_classifier.predict(np.array(Test_X.values.tolist()).reshape(-1, 1)))*100\n",
    "\n",
    "print(\"Gaussian Naive Bayes Accuracy Score -> \", accuracy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Naive Bayes Bag of Words model performs worse than our previous \"every review is helpful\" baseline model. It produces an accuracy score of 75.3%, down from 79.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: TF-IDF and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import sklearn\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into train/validation/test sets\n",
    "data = df[['combinedText', 'isHelpful']]\n",
    "\n",
    "df_train, df_test = train_test_split(data, test_size = 0.2)\n",
    "df_train, df_val = train_test_split(df_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stem combinedText to reduce size of corpus\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter=PorterStemmer()\n",
    "\n",
    "def stem_text(df):\n",
    "    text_list = df['combinedText'].tolist()\n",
    "    text_list_stem = [None] * len(text_list)\n",
    "\n",
    "    for i in range(len(text_list)):\n",
    "        text_list_stem[i] = ' '.join([porter.stem(w) for w in text_list[i].split()])\n",
    "    \n",
    "    return text_list_stem\n",
    "\n",
    "text_list_stem = stem_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03389221, 0.07340804, 0.03054271, ..., 0.03196743, 0.099017  ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.19454242, 0.        , 0.        , ..., 0.        , 0.14209024,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.26798256,\n",
       "        0.        ],\n",
       "       [0.03311168, 0.07171747, 0.08951795, ..., 0.        , 0.145105  ,\n",
       "        0.14716066],\n",
       "       [0.        , 0.        , 0.18267261, ..., 0.        , 0.14805248,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "                max_features=100,\n",
    "                ngram_range=(1,1)\n",
    "                )\n",
    "\n",
    "vectorizer.fit_transform(text_list_stem).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (51200, 100)\n"
     ]
    }
   ],
   "source": [
    "# vectorize train dataset\n",
    "train_text_stem = stem_text(df_train)\n",
    "train_vectorized = vectorizer.transform(train_text_stem).toarray()\n",
    "\n",
    "print('Shape:', train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (12800, 100)\n"
     ]
    }
   ],
   "source": [
    "# vectorize val dataset\n",
    "val_text_stem = stem_text(df_val)\n",
    "val_vectorized = vectorizer.transform(val_text_stem).toarray()\n",
    "\n",
    "print('Shape:', val_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (16000, 100)\n"
     ]
    }
   ],
   "source": [
    "# vectorize test dataset\n",
    "test_text_stem = stem_text(df_test)\n",
    "test_vectorized = vectorizer.transform(test_text_stem).toarray()\n",
    "\n",
    "print('Shape:', test_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create array of labels to use in logistic regression\n",
    "df_train_labels = np.array(df_train['isHelpful'])\n",
    "df_test_labels = np.array(df_test['isHelpful'])\n",
    "df_val_labels = np.array(df_val['isHelpful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train logistic regression\n",
    "lr = LogisticRegression(penalty='l2')\n",
    "lr.fit(train_vectorized, df_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 0.01   validation set accuracy: 0.745546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 0.1   validation set accuracy: 0.746796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 1.0   validation set accuracy: 0.747265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 10   validation set accuracy: 0.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 100   validation set accuracy: 0.74765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength: 1000   validation set accuracy: 0.74765625\n"
     ]
    }
   ],
   "source": [
    "# tune hyperparameters\n",
    "reg_str = [0.01, 0.1, 1.0, 10, 100, 1000]\n",
    "\n",
    "best_acc = -1\n",
    "best_c = None\n",
    "\n",
    "for r in reg_str:\n",
    "    lr = LogisticRegression(penalty='l2', C=r)\n",
    "    lr.fit(train_vectorized, df_train_labels)\n",
    "    preds = lr.predict(val_vectorized)\n",
    "    acc = np.mean(preds == df_val_labels)\n",
    "    print('regularization strength:', r, ' ', 'validation set accuracy:', acc)\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_c = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF and Logistic Regression Accuracy Score -> 74.99375\n"
     ]
    }
   ],
   "source": [
    "# test accuracy\n",
    "lr_final = LogisticRegression(penalty='l2', C = best_c)\n",
    "lr_final.fit(train_vectorized, df_train_labels)\n",
    "\n",
    "preds = lr_final.predict(test_vectorized)\n",
    "accuracy_3 = 100*np.mean(preds == df_test_labels)\n",
    "\n",
    "print(\"TF-IDF and Logistic Regression Accuracy Score ->\", accuracy_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with term frequency–inverse document frequency and logistic regression produces a marginally higher accuracy than the Naive Bayes Bag of Words model, but it is still not higher than the rudimentary Every Review is Helpful model. This motivates the need for a more robust representation of the language in the reviews. Enter BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code built around Strongio's notebook here https://github.com/strongio/keras-bert/blob/master/keras-bert.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "# if this doesnt work, ensure tensorflow is version <2.0\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Tensorflow hub path to BERT module of choice\n",
    "BERT_DIR =  \"./bert\"\n",
    "BERT_PATH = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "sys.path.insert(0,BERT_DIR)\n",
    "\n",
    "# Initialize session, may need to remove config if no GPU\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "  When running eval/predict on the TPU, we need to pad the number of examples\n",
    "  to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "  size. The alternative is to drop the last batch, which is bad because it means\n",
    "  the entire output data won't be generated.\n",
    "  We use this class instead of `None` because treating `None` as padding\n",
    "  battches could cause silent errors.\n",
    "  \"\"\"\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.text_a)\n",
    "\n",
    "def create_tokenizer_from_hub_module(path):\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module =  hub.Module(path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    tokens_b = tokenizer.tokenize(example.text_b)\n",
    "    \n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    elif (len(tokens_a)+len(tokens_b)) > max_seq_length - 3:\n",
    "        tokens_b = tokens_b[0 : (max_seq_length - 3 - len(tokens_a))]\n",
    "        \n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    \n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    if len(tokens) < max_seq_length:\n",
    "        for token in tokens_b:\n",
    "            tokens.append(token)\n",
    "            segment_ids.append(1)\n",
    "        tokens.append(\"[SEP]\")\n",
    "        segment_ids.append(1)\n",
    "    \n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "def convert_text_to_examples(titles, texts, labels, max_examples=None):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for title, text, label in zip(titles, texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=title, text_b=text, label=label)\n",
    "        )\n",
    "    return InputExamples[:max_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module(BERT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n",
      "23257\n"
     ]
    }
   ],
   "source": [
    "# create dataframe\n",
    "df = get_dataframe(file_name)\n",
    "\n",
    "# parse helpful column into new columns of helpful_votes, total_votes, helpful_perc\n",
    "df['helpful_votes'] = df['helpful'].apply(get_helpful_votes)\n",
    "df['total_votes'] = df['helpful'].apply(get_total_votes)\n",
    "df['helpful_perc'] = df['helpful'].apply(calculate_helpful_perc)\n",
    "\n",
    "\n",
    "# Now create the combinedText with casing and no longer than 512 characters (max of BERT embedding input)\n",
    "df['combinedText'] = df['summary'] + \". \" + df['reviewText']\n",
    "\n",
    "#drop rows where not enough votes exist to discern helpfullness\n",
    "kitchen_df = df.drop(df[df.total_votes < 5].index)\n",
    "balanced_kitchen_df = balance_df(kitchen_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(balanced_kitchen_df, test_size = 0.2)\n",
    "df_train, df_val = train_test_split(df_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:105: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5ba1f6f0fd48d494b87719044e9c2e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd9cd7dbba44b108f41954d8fc37d24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6867521fb3ac4a068d39ae0f6be7f3b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert data to InputExample format, ensure we don't have too many examples to encounter memory issues\n",
    "train_examples = convert_text_to_examples(df_train['summary'], df_train['reviewText'], df_train['helpful_perc'], max_examples=10000)\n",
    "val_examples = convert_text_to_examples(df_val['summary'], df_val['reviewText'], df_val['helpful_perc'], max_examples=2000)\n",
    "test_examples = convert_text_to_examples(df_test['summary'], df_test['reviewText'], df_test['helpful_perc'], max_examples=2000)\n",
    "\n",
    "#make sure the test Y is the same format\n",
    "test_actual = np.array(df_test['helpful_perc'][:2000])\n",
    "test_actual = test_actual.reshape(-1,1)\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
    ") = convert_examples_to_features(tokenizer, train_examples, max_seq_length=MAX_SEQ_LENGTH)\n",
    "(val_input_ids, val_input_masks, val_segment_ids, val_labels \n",
    ") = convert_examples_to_features(tokenizer, val_examples, max_seq_length=MAX_SEQ_LENGTH)\n",
    "(test_input_ids, test_input_masks, test_segment_ids, test_labels\n",
    ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"first\",\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_path = bert_path\n",
    "        if self.pooling not in [\"first\", \"mean\"]:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "\n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'n_fine_tune_layers': self.n_fine_tune_layers,\n",
    "                  'pooling': self.pooling,\n",
    "                  'bert_path': self.bert_path}\n",
    "        base_config = super(MyMeanPooling, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Build model\n",
    "def build_model(max_seq_length, model_loss, reg=False): \n",
    "\n",
    "    in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "\n",
    "    bert_output = BertLayer(n_fine_tune_layers=3, pooling=\"first\")(bert_inputs)\n",
    "    if reg:\n",
    "        dense = tf.keras.layers.Dense(max_seq_length, activation='relu', kernel_regularizer=regularizers.l2(0.01))(bert_output)\n",
    "    else:\n",
    "        dense = tf.keras.layers.Dense(max_seq_length, activation='relu')(bert_output)\n",
    "    pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss=model_loss, optimizer='adam')\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_11 (BertLayer)       (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 256)          196864      bert_layer_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            257         dense_16[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 22,051,329\n",
      "Non-trainable params: 88,250,682\n",
      "__________________________________________________________________________________________________\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_12 (BertLayer)       (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 256)          196864      bert_layer_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            257         dense_18[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 22,051,329\n",
      "Non-trainable params: 88,250,682\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# let's define some models!\n",
    "\n",
    "#BCE Model: using BCE in regression https://stats.stackexchange.com/questions/370179/why-binary-crossentropy-can-be-used-as-the-loss-function-in-autoencoders/370180#370180\n",
    "model_BCE = build_model(MAX_SEQ_LENGTH, 'binary_crossentropy')\n",
    "model_RMSE = build_model(MAX_SEQ_LENGTH, 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BCE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [768,3072] and type float\n\t [[node training/Adam/bert_layer_module/bert/encoder/layer_10/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training/Adam/bert_layer_module/bert/encoder/layer_11/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training/Adam/bert_layer_module/bert/encoder/layer_9/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_2/Adam/bert_layer_1_module/bert/encoder/layer_10/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_2/Adam/bert_layer_1_module/bert/encoder/layer_11/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_2/Adam/bert_layer_1_module/bert/encoder/layer_9/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_4/Adam/bert_layer_5_module/bert/encoder/layer_10/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_4/Adam/bert_layer_5_module/bert/encoder/layer_11/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_4/Adam/bert_layer_5_module/bert/encoder/layer_9/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_6/Adam/bert_layer_6_module/bert/encoder/layer_10/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_6/Adam/bert_layer_6_module/bert/encoder/layer_11/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_6/Adam/bert_layer_6_module/bert/encoder/layer_9/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n\nOriginal stack trace for 'training/Adam/bert_layer_module/bert/encoder/layer_10/intermediate/dense/kernel/m/Initializer/zeros':\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-fe3b1540172f>\", line 10, in <module>\n    batch_size=8\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n    use_multiprocessing=use_multiprocessing)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n    steps_name='steps_per_epoch')\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 189, in model_iteration\n    f = _make_execution_function(model, mode)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 566, in _make_execution_function\n    return model._make_execution_function(mode)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 2183, in _make_execution_function\n    self._make_train_function()\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 2115, in _make_train_function\n    params=self._collected_trainable_weights, loss=self.total_loss)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 504, in get_updates\n    return [self.apply_gradients(grads_and_vars)]\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 433, in apply_gradients\n    self._create_slots(var_list)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\adam.py\", line 149, in _create_slots\n    self.add_slot(var, 'm')\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 585, in add_slot\n    initial_value=initial_value)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 260, in __call__\n    return cls._variable_v2_call(*args, **kwargs)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 254, in _variable_v2_call\n    shape=shape)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 235, in <lambda>\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 2552, in default_variable_creator_v2\n    shape=shape)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\", line 1406, in __init__\n    distribute_strategy=distribute_strategy)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\", line 1537, in _init_from_args\n    initial_value() if init_from_fn else initial_value,\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py\", line 114, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 2350, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 171, in fill\n    result = gen_array_ops.fill(dims, value, name=name)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\", line 3602, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [768,3072] and type float\n\t [[{{node training/Adam/bert_layer_module/bert/encoder/layer_10/intermediate/dense/kernel/m/Initializer/zeros}}, {{node training/Adam/bert_layer_module/bert/encoder/layer_11/intermediate/dense/kernel/m/Initializer/zeros}}, {{node training/Adam/bert_layer_module/bert/encoder/layer_9/intermediate/dense/kernel/m/Initializer/zeros}}, {{node training_2/Adam/bert_layer_1_module/bert/encoder/layer_10/intermediate/dense/kernel/m/Initializer/zeros}}, {{node training_2/Adam/bert_layer_1_module/bert/encoder/layer_11/intermediate/dense/kernel/m/Initializer/zeros}}, {{node training_2/Adam/bert_layer_1_module/bert/encoder/layer_9/intermediate/dense/kernel/m/Initializer/zeros}}, {{node training_4/Adam/bert_layer_5_module/bert/encoder/layer_10/intermediate/dense/kernel/m/Initializer/zeros}}, {{node training_4/Adam/bert_layer_5_module/bert/encoder/layer_11/intermediate/dense/kernel/m/Initializer/zeros}}, {{node training_4/Adam/bert_layer_5_module/bert/encoder/layer_9/intermediate/dense/kernel/m/Initializer/zeros}}, {{node training_6/Adam/bert_layer_6_module/bert/encoder/layer_10/intermediate/dense/kernel/m/Initializer/zeros}}, {{node training_6/Adam/bert_layer_6_module/bert/encoder/layer_11/intermediate/dense/kernel/m/Initializer/zeros}}, {{node training_6/Adam/bert_layer_6_module/bert/encoder/layer_9/intermediate/dense/kernel/m/Initializer/zeros}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-173-09bcbabb2053>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#we can now finally build a model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Instantiate variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0minitialize_vars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m model_BCE.fit(\n",
      "\u001b[1;32m<ipython-input-170-97183b97af36>\u001b[0m in \u001b[0;36minitialize_vars\u001b[1;34m(sess)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minitialize_vars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [768,3072] and type float\n\t [[node training/Adam/bert_layer_module/bert/encoder/layer_10/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training/Adam/bert_layer_module/bert/encoder/layer_11/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training/Adam/bert_layer_module/bert/encoder/layer_9/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_2/Adam/bert_layer_1_module/bert/encoder/layer_10/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_2/Adam/bert_layer_1_module/bert/encoder/layer_11/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_2/Adam/bert_layer_1_module/bert/encoder/layer_9/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_4/Adam/bert_layer_5_module/bert/encoder/layer_10/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_4/Adam/bert_layer_5_module/bert/encoder/layer_11/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_4/Adam/bert_layer_5_module/bert/encoder/layer_9/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_6/Adam/bert_layer_6_module/bert/encoder/layer_10/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_6/Adam/bert_layer_6_module/bert/encoder/layer_11/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) , node training_6/Adam/bert_layer_6_module/bert/encoder/layer_9/intermediate/dense/kernel/m/Initializer/zeros (defined at C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n\nOriginal stack trace for 'training/Adam/bert_layer_module/bert/encoder/layer_10/intermediate/dense/kernel/m/Initializer/zeros':\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-fe3b1540172f>\", line 10, in <module>\n    batch_size=8\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n    use_multiprocessing=use_multiprocessing)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n    steps_name='steps_per_epoch')\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 189, in model_iteration\n    f = _make_execution_function(model, mode)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 566, in _make_execution_function\n    return model._make_execution_function(mode)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 2183, in _make_execution_function\n    self._make_train_function()\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 2115, in _make_train_function\n    params=self._collected_trainable_weights, loss=self.total_loss)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 504, in get_updates\n    return [self.apply_gradients(grads_and_vars)]\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 433, in apply_gradients\n    self._create_slots(var_list)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\adam.py\", line 149, in _create_slots\n    self.add_slot(var, 'm')\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 585, in add_slot\n    initial_value=initial_value)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 260, in __call__\n    return cls._variable_v2_call(*args, **kwargs)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 254, in _variable_v2_call\n    shape=shape)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 235, in <lambda>\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 2552, in default_variable_creator_v2\n    shape=shape)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\", line 1406, in __init__\n    distribute_strategy=distribute_strategy)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\", line 1537, in _init_from_args\n    initial_value() if init_from_fn else initial_value,\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py\", line 114, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 2350, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 171, in fill\n    result = gen_array_ops.fill(dims, value, name=name)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\", line 3602, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "#we can now finally build a model\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "model_BCE.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data=([val_input_ids, val_input_masks, val_segment_ids], val_labels),\n",
    "    epochs=1,\n",
    "    batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save weights\n",
    "model_BCE.save_weights('./models/model_BCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let's test the correlation coefficient\n",
    "preds_BCE = model_BCE.predict([test_input_ids, test_input_masks, test_segment_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.corrcoef(preds_BCE.T, test_actual.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's try RMSE\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "model_RMSE.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data=([val_input_ids, val_input_masks, val_segment_ids], val_labels),\n",
    "    epochs=1,\n",
    "    batch_size=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save weights\n",
    "model_RMSE.save_weights('./models/model_RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let's test the correlation coefficient\n",
    "preds_RMSE = model_RMSE.predict([test_input_ids, test_input_masks, test_segment_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\lib\\function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\lib\\function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan],\n",
       "       [nan,  1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(preds_RMSE.T, test_actual.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_6 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          196864      bert_layer_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            257         dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 22,051,329\n",
      "Non-trainable params: 88,250,682\n",
      "__________________________________________________________________________________________________\n",
      "Train on 10000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "10000/10000 [==============================] - 1404s 140ms/sample - loss: 0.2731 - val_loss: 0.1117\n",
      "Epoch 2/5\n",
      "10000/10000 [==============================] - 387s 39ms/sample - loss: 0.0999 - val_loss: 0.0937\n",
      "Epoch 3/5\n",
      "10000/10000 [==============================] - 387s 39ms/sample - loss: 0.0978 - val_loss: 0.0990\n",
      "Epoch 4/5\n",
      "10000/10000 [==============================] - 387s 39ms/sample - loss: 0.0970 - val_loss: 0.0932\n",
      "Epoch 5/5\n",
      "10000/10000 [==============================] - 387s 39ms/sample - loss: 0.0974 - val_loss: 0.0931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2076f961860>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's retry with some regularization\n",
    "model_RMSE_reg = build_model(MAX_SEQ_LENGTH, 'mean_squared_error', reg=True)\n",
    "\n",
    "# let's try RMSE\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "model_RMSE_reg.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data=([val_input_ids, val_input_masks, val_segment_ids], val_labels),\n",
    "    epochs=5,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save weights\n",
    "model_RMSE_reg.save_weights('./models/model_RMSE_reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let's test the correlation coefficient\n",
    "preds_RMSE_reg = model_RMSE_reg.predict([test_input_ids, test_input_masks, test_segment_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8183431],\n",
       "       [0.8183431],\n",
       "       [0.8183431],\n",
       "       ...,\n",
       "       [0.8183431],\n",
       "       [0.8183431],\n",
       "       [0.8183431]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_RMSE_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\lib\\function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\Tucker\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\lib\\function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan],\n",
       "       [nan,  1.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(preds_RMSE_reg.T, test_actual.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Model\n",
    "We'll now try and implement review from other domains, not just the home and kitchen reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load extra datasets - download directly from source, save to data directory\n",
    "\n",
    "output_dir = \"data/\"\n",
    "url = \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/\"\n",
    "\n",
    "kitchen_file_name = \"reviews_Home_and_Kitchen_5.json.gz\"\n",
    "cell_file_name = \"reviews_Cell_Phones_and_Accessories_5.json.gz\"\n",
    "clothing_file_name = \"reviews_Clothing_Shoes_and_Jewelry_5.json.gz\"\n",
    "outdoor_file_name = \"reviews_Sports_and_Outdoors_5.json.gz\"\n",
    "electronics_file_name = \"reviews_Electronics_5.json.gz\"\n",
    "\n",
    "file_names = [kitchen_file_name, cell_file_name, clothing_file_name, outdoor_file_name, electronics_file_name]\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for file in file_names:\n",
    "    if not os.path.isfile(output_dir + file):\n",
    "        file_name = wget.download(url + file, out=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df_kitchen = get_dataframe(output_dir + kitchen_file_name)\n",
    "df_cell = get_dataframe(output_dir + cell_file_name)\n",
    "df_clothing = get_dataframe(output_dir + clothing_file_name)\n",
    "df_outdoor = get_dataframe(output_dir + outdoor_file_name)\n",
    "df_electronics = get_dataframe(output_dir + electronics_file_name)\n",
    "\n",
    "dfs = [df_kitchen, df_cell, df_clothing, df_outdoor, df_electronics]\n",
    "\n",
    "# parse helpful column into new columns of helpful_votes, total_votes, helpful_perc\n",
    "for i, df in enumerate(dfs):\n",
    "    df['helpful_votes'] = df['helpful'].apply(get_helpful_votes)\n",
    "    df['total_votes'] = df['helpful'].apply(get_total_votes)\n",
    "    df['helpful_perc'] = df['helpful'].apply(calculate_helpful_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "W266_Final_AmazonReviews.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
